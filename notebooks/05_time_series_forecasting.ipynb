{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Notebook 05 — Time Series Forecasting with Conformal Intervals\n",
    "\n",
    "**Objective**: Forecast portfolio-level default rates and loan volumes using the Nixtla ecosystem (statsforecast + mlforecast) with **distribution-free conformal prediction intervals**.\n",
    "\n",
    "**Why time series matters for credit risk**:\n",
    "- IFRS 9 / CECL mandates **forward-looking** expected credit loss estimates\n",
    "- Forecast intervals serve as **data-driven stress scenarios** (upper bound of 95% CI)\n",
    "- Portfolio-level default rate trends complement loan-level PD models (NB03-04)\n",
    "- Conformal intervals provide **finite-sample coverage guarantees**, unlike parametric ARIMA intervals\n",
    "\n",
    "**Key components**:\n",
    "1. Statistical baselines: AutoARIMA, AutoETS, AutoTheta, SeasonalNaive\n",
    "2. ML forecaster: LightGBM with lag features + conformal prediction intervals\n",
    "3. Expanding-window cross-validation for model comparison\n",
    "4. Grade-level hierarchical forecasting with reconciliation\n",
    "5. Connection to IFRS 9 provisioning and stress testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from lightgbm import LGBMRegressor\n",
    "from loguru import logger\n",
    "from mlforecast import MLForecast\n",
    "from mlforecast.lag_transforms import (\n",
    "    ExponentiallyWeightedMean,\n",
    "    RollingMean,\n",
    "    RollingStd,\n",
    ")\n",
    "from mlforecast.utils import PredictionIntervals\n",
    "\n",
    "# Nixtla ecosystem\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import (\n",
    "    AutoARIMA,\n",
    "    AutoETS,\n",
    "    AutoTheta,\n",
    "    SeasonalNaive,\n",
    ")\n",
    "from utilsforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import mae, rmse\n",
    "from utilsforecast.plotting import plot_series\n",
    "\n",
    "# Plotting defaults\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"figure.figsize\": (14, 5),\n",
    "        \"axes.grid\": True,\n",
    "        \"grid.alpha\": 0.3,\n",
    "        \"font.size\": 11,\n",
    "    }\n",
    ")\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "HORIZON = 12  # 12-month forecast (IFRS 9 Stage 1 horizon)\n",
    "LEVELS = [90, 95]  # Confidence levels for intervals\n",
    "\n",
    "logger.info(\"NB05 — Time Series Forecasting initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data Loading & Exploration\n",
    "\n",
    "The `time_series.parquet` contains monthly portfolio aggregates from 2007 to 2017 (training period). We forecast the **default rate** as our primary target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-built time series\n",
    "ts_raw = pd.read_parquet(DATA_DIR / \"time_series.parquet\")\n",
    "print(f\"Shape: {ts_raw.shape}\")\n",
    "print(f\"Date range: {ts_raw['ds'].min().date()} to {ts_raw['ds'].max().date()}\")\n",
    "print(f\"Months: {len(ts_raw)}\")\n",
    "print(f\"\\nColumns: {ts_raw.columns.tolist()}\")\n",
    "ts_raw.describe().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Nixtla-format DataFrame\n",
    "df = ts_raw[[\"unique_id\", \"ds\", \"y\"]].copy()\n",
    "print(f\"Target (y = default_rate): mean={df['y'].mean():.4f}, std={df['y'].std():.4f}\")\n",
    "print(f\"Range: [{df['y'].min():.4f}, {df['y'].max():.4f}]\")\n",
    "\n",
    "# Plot the series\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Default rate\n",
    "axes[0, 0].plot(ts_raw[\"ds\"], ts_raw[\"y\"], \"b-\", linewidth=1.5)\n",
    "axes[0, 0].set_title(\"Monthly Default Rate\")\n",
    "axes[0, 0].yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "axes[0, 0].axvspan(\n",
    "    pd.Timestamp(\"2007-12-01\"), pd.Timestamp(\"2009-06-01\"), alpha=0.15, color=\"red\", label=\"GFC\"\n",
    ")\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Loan count\n",
    "axes[0, 1].plot(ts_raw[\"ds\"], ts_raw[\"loan_count\"], \"g-\", linewidth=1.5)\n",
    "axes[0, 1].set_title(\"Monthly Loan Count\")\n",
    "axes[0, 1].set_ylabel(\"Count\")\n",
    "\n",
    "# Average interest rate\n",
    "axes[1, 0].plot(ts_raw[\"ds\"], ts_raw[\"avg_int_rate\"], \"r-\", linewidth=1.5)\n",
    "axes[1, 0].set_title(\"Average Interest Rate\")\n",
    "axes[1, 0].yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "\n",
    "# Average DTI\n",
    "axes[1, 1].plot(ts_raw[\"ds\"], ts_raw[\"avg_dti\"], \"purple\", linewidth=1.5)\n",
    "axes[1, 1].set_title(\"Average DTI Ratio\")\n",
    "\n",
    "plt.suptitle(\"Lending Club Portfolio — Monthly Time Series (2007–2017)\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Stationarity Analysis\n",
    "\n",
    "Before forecasting, we test whether the default rate series is stationary using the Augmented Dickey-Fuller (ADF) test. Stationarity influences model choice: ARIMA can handle non-stationary data (via differencing), while LightGBM works on levels with lag features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# ADF test on default rate\n",
    "y = df[\"y\"].values\n",
    "result = adfuller(y, maxlag=12, autolag=\"AIC\")\n",
    "\n",
    "print(\"=== Augmented Dickey-Fuller Test ===\")\n",
    "print(f\"Test Statistic: {result[0]:.4f}\")\n",
    "print(f\"p-value:        {result[1]:.4f}\")\n",
    "print(f\"Lags used:      {result[2]}\")\n",
    "print(f\"Observations:   {result[3]}\")\n",
    "print(\"Critical Values:\")\n",
    "for key, val in result[4].items():\n",
    "    marker = \" ← reject\" if result[0] < val else \"\"\n",
    "    print(f\"  {key}: {val:.4f}{marker}\")\n",
    "\n",
    "if result[1] < 0.05:\n",
    "    print(\"\\n→ Series is STATIONARY (reject H0 of unit root)\")\n",
    "else:\n",
    "    print(\"\\n→ Series is NON-STATIONARY (cannot reject H0)\")\n",
    "\n",
    "# Seasonal decomposition\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "# Need enough data (skip first few sparse months)\n",
    "ts_for_stl = df[df[\"ds\"] >= \"2008-01-01\"].set_index(\"ds\")[\"y\"]\n",
    "stl = STL(ts_for_stl, period=12, robust=True)\n",
    "res = stl.fit()\n",
    "\n",
    "fig = res.plot()\n",
    "fig.set_size_inches(14, 10)\n",
    "plt.suptitle(\"STL Decomposition of Default Rate\", fontsize=14, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Statistical Baselines (AutoARIMA, AutoETS, AutoTheta, SeasonalNaive)\n",
    "\n",
    "We train four statistical baselines using **statsforecast**. Each model produces point forecasts with parametric prediction intervals at 90% and 95% confidence levels.\n",
    "\n",
    "These are our benchmarks — any ML model must beat them to justify its complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train statistical baselines\n",
    "models = [\n",
    "    AutoARIMA(season_length=12),\n",
    "    AutoETS(season_length=12),\n",
    "    AutoTheta(season_length=12),\n",
    "    SeasonalNaive(season_length=12),\n",
    "]\n",
    "\n",
    "sf = StatsForecast(models=models, freq=\"MS\", n_jobs=1)\n",
    "sf.fit(df)\n",
    "\n",
    "# Generate forecasts with intervals\n",
    "fc_stats = sf.predict(h=HORIZON, level=LEVELS)\n",
    "print(f\"Forecast shape: {fc_stats.shape}\")\n",
    "print(f\"Forecast columns: {fc_stats.columns.tolist()}\")\n",
    "print(f\"\\nForecast period: {fc_stats['ds'].min().date()} to {fc_stats['ds'].max().date()}\")\n",
    "fc_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize baseline forecasts\n",
    "fig = plot_series(\n",
    "    df=df,\n",
    "    forecasts_df=fc_stats,\n",
    "    models=[\"AutoARIMA\", \"AutoETS\", \"AutoTheta\", \"SeasonalNaive\"],\n",
    "    level=LEVELS,\n",
    "    max_insample_length=60,\n",
    "    engine=\"matplotlib\",\n",
    ")\n",
    "plt.suptitle(\"Statistical Baseline Forecasts — Default Rate\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. ML Forecaster — LightGBM with Conformal Prediction Intervals\n",
    "\n",
    "We train a LightGBM model using **mlforecast** with:\n",
    "- **Lag features**: [1, 2, 3, 6, 12] months\n",
    "- **Rolling statistics**: mean (3, 6, 12 months), std (6 months), EWM (α=0.3)\n",
    "- **Conformal prediction intervals**: calibrated on 5 expanding backtesting windows\n",
    "\n",
    "Unlike parametric intervals (ARIMA), conformal intervals are **distribution-free** — they make no assumption about the error distribution and provide finite-sample coverage guarantees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML forecaster with conformal intervals\n",
    "N_WINDOWS = 5  # Backtesting windows for conformal calibration\n",
    "\n",
    "mlf = MLForecast(\n",
    "    models={\n",
    "        \"LightGBM\": LGBMRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=4,\n",
    "            num_leaves=15,\n",
    "            min_child_samples=5,\n",
    "            verbose=-1,\n",
    "        )\n",
    "    },\n",
    "    freq=\"MS\",\n",
    "    lags=[1, 2, 3, 6, 12],\n",
    "    lag_transforms={\n",
    "        1: [\n",
    "            RollingMean(window_size=3),\n",
    "            RollingMean(window_size=6),\n",
    "            RollingMean(window_size=12),\n",
    "        ],\n",
    "        3: [RollingStd(window_size=6)],\n",
    "        6: [ExponentiallyWeightedMean(alpha=0.3)],\n",
    "    },\n",
    "    date_features=[\"month\"],\n",
    ")\n",
    "\n",
    "# Fit with conformal prediction intervals\n",
    "mlf.fit(\n",
    "    df,\n",
    "    prediction_intervals=PredictionIntervals(\n",
    "        n_windows=N_WINDOWS,\n",
    "        h=HORIZON,\n",
    "        method=\"conformal_distribution\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "fc_ml = mlf.predict(h=HORIZON, level=LEVELS)\n",
    "print(f\"ML Forecast shape: {fc_ml.shape}\")\n",
    "print(f\"Columns: {fc_ml.columns.tolist()}\")\n",
    "fc_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from LightGBM\n",
    "\n",
    "lgbm_model = mlf.models_[\"LightGBM\"]\n",
    "importance = pd.DataFrame(\n",
    "    {\n",
    "        \"feature\": lgbm_model.feature_name_,\n",
    "        \"importance\": lgbm_model.feature_importances_,\n",
    "    }\n",
    ").sort_values(\"importance\", ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(importance[\"feature\"], importance[\"importance\"], color=\"steelblue\")\n",
    "ax.set_title(\"LightGBM Feature Importance (Lag Features)\")\n",
    "ax.set_xlabel(\"Importance (split count)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all forecasts visually\n",
    "fc_combined = fc_stats.merge(fc_ml, on=[\"unique_id\", \"ds\"], how=\"outer\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "# Historical data\n",
    "ax.plot(df[\"ds\"], df[\"y\"], \"k-\", linewidth=1.5, label=\"Actual\", alpha=0.8)\n",
    "\n",
    "# Point forecasts\n",
    "models_to_plot = [\"AutoARIMA\", \"AutoETS\", \"AutoTheta\", \"SeasonalNaive\", \"LightGBM\"]\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\"]\n",
    "for model, color in zip(models_to_plot, colors, strict=False):\n",
    "    ax.plot(fc_combined[\"ds\"], fc_combined[model], \"--\", color=color, linewidth=1.5, label=model)\n",
    "\n",
    "# LightGBM conformal intervals (90%)\n",
    "ax.fill_between(\n",
    "    fc_ml[\"ds\"],\n",
    "    fc_ml[\"LightGBM-lo-90\"],\n",
    "    fc_ml[\"LightGBM-hi-90\"],\n",
    "    alpha=0.2,\n",
    "    color=\"#9467bd\",\n",
    "    label=\"LightGBM 90% CI (conformal)\",\n",
    ")\n",
    "\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "ax.set_title(\"Default Rate Forecast Comparison — All Models\", fontsize=14)\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Default Rate\")\n",
    "ax.legend(loc=\"upper left\", fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Cross-Validation Backtesting\n",
    "\n",
    "We evaluate all models using **expanding-window cross-validation** with 3 windows of 12-month forecasts. This simulates real-world deployment where we train on all available history and forecast the next year.\n",
    "\n",
    "The evaluation metrics are:\n",
    "- **MAE**: Mean Absolute Error (interpretable in default rate units)\n",
    "- **RMSE**: Root Mean Squared Error (penalizes large errors)\n",
    "- **MASE**: Mean Absolute Scaled Error (normalized by naive forecast error — the standard metric in forecasting literature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical models CV\n",
    "N_CV_WINDOWS = 3\n",
    "\n",
    "sf_cv = StatsForecast(\n",
    "    models=[\n",
    "        AutoARIMA(season_length=12),\n",
    "        AutoETS(season_length=12),\n",
    "        AutoTheta(season_length=12),\n",
    "        SeasonalNaive(season_length=12),\n",
    "    ],\n",
    "    freq=\"MS\",\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "cv_stats = sf_cv.cross_validation(df=df, h=HORIZON, n_windows=N_CV_WINDOWS, level=LEVELS)\n",
    "print(f\"Stats CV shape: {cv_stats.shape}\")\n",
    "print(f\"CV windows (cutoffs): {cv_stats['cutoff'].unique()}\")\n",
    "cv_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML model CV\n",
    "mlf_cv = MLForecast(\n",
    "    models={\n",
    "        \"LightGBM\": LGBMRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=4,\n",
    "            num_leaves=15,\n",
    "            min_child_samples=5,\n",
    "            verbose=-1,\n",
    "        )\n",
    "    },\n",
    "    freq=\"MS\",\n",
    "    lags=[1, 2, 3, 6, 12],\n",
    "    lag_transforms={\n",
    "        1: [\n",
    "            RollingMean(window_size=3),\n",
    "            RollingMean(window_size=6),\n",
    "            RollingMean(window_size=12),\n",
    "        ],\n",
    "        3: [RollingStd(window_size=6)],\n",
    "        6: [ExponentiallyWeightedMean(alpha=0.3)],\n",
    "    },\n",
    "    date_features=[\"month\"],\n",
    ")\n",
    "\n",
    "cv_ml = mlf_cv.cross_validation(df=df, h=HORIZON, n_windows=N_CV_WINDOWS)\n",
    "print(f\"ML CV shape: {cv_ml.shape}\")\n",
    "cv_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "stat_models = [\"AutoARIMA\", \"AutoETS\", \"AutoTheta\", \"SeasonalNaive\"]\n",
    "eval_stats = evaluate(cv_stats, metrics=[mae, rmse], models=stat_models)\n",
    "eval_ml = evaluate(cv_ml, metrics=[mae, rmse], models=[\"LightGBM\"])\n",
    "\n",
    "# Combine results\n",
    "eval_all = pd.concat([eval_stats, eval_ml], axis=0, ignore_index=True)\n",
    "\n",
    "# Aggregate across windows\n",
    "eval_summary = (\n",
    "    eval_all.groupby(\"metric\")\n",
    "    .apply(lambda g: g.drop(columns=[\"unique_id\", \"cutoff\", \"metric\"]).mean())\n",
    "    .round(6)\n",
    ")\n",
    "\n",
    "print(\"=== Cross-Validation Results (averaged across windows) ===\")\n",
    "print(eval_summary.to_string())\n",
    "\n",
    "# Visual comparison\n",
    "eval_melted = eval_summary.reset_index().melt(\n",
    "    id_vars=\"metric\", var_name=\"model\", value_name=\"value\"\n",
    ")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "for i, metric_name in enumerate([\"mae\", \"rmse\"]):\n",
    "    data = eval_melted[eval_melted[\"metric\"] == metric_name].sort_values(\"value\")\n",
    "    axes[i].barh(data[\"model\"], data[\"value\"], color=sns.color_palette(\"colorblind\", len(data)))\n",
    "    axes[i].set_title(f\"{metric_name.upper()} — Lower is Better\")\n",
    "    axes[i].set_xlabel(metric_name.upper())\n",
    "\n",
    "plt.suptitle(\"Model Comparison — Cross-Validation Metrics\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Conformal Interval Analysis\n",
    "\n",
    "We analyze the conformal prediction intervals from the LightGBM model:\n",
    "- **Coverage**: Do 90% of actual values fall within the 90% interval?\n",
    "- **Width**: How wide are the intervals? Narrower = more informative.\n",
    "- **Comparison**: Conformal (distribution-free) vs parametric (ARIMA) intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage analysis on CV results with intervals\n",
    "# Re-run stats CV and ML with level to get intervals in CV\n",
    "cv_stats_intervals = sf_cv.cross_validation(\n",
    "    df=df, h=HORIZON, n_windows=N_CV_WINDOWS, level=[90, 95]\n",
    ")\n",
    "\n",
    "\n",
    "# Compute coverage for each model\n",
    "def compute_coverage(cv_df, model_name, level):\n",
    "    lo_col = f\"{model_name}-lo-{level}\"\n",
    "    hi_col = f\"{model_name}-hi-{level}\"\n",
    "    if lo_col not in cv_df.columns:\n",
    "        return None\n",
    "    covered = ((cv_df[\"y\"] >= cv_df[lo_col]) & (cv_df[\"y\"] <= cv_df[hi_col])).mean()\n",
    "    width = (cv_df[hi_col] - cv_df[lo_col]).mean()\n",
    "    return {\"model\": model_name, \"level\": level, \"coverage\": covered, \"avg_width\": width}\n",
    "\n",
    "\n",
    "coverage_results = []\n",
    "for model in stat_models:\n",
    "    for level in [90, 95]:\n",
    "        result = compute_coverage(cv_stats_intervals, model, level)\n",
    "        if result:\n",
    "            coverage_results.append(result)\n",
    "\n",
    "# For LightGBM, re-run CV with prediction_intervals\n",
    "mlf_cv2 = MLForecast(\n",
    "    models={\n",
    "        \"LightGBM\": LGBMRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=4,\n",
    "            num_leaves=15,\n",
    "            min_child_samples=5,\n",
    "            verbose=-1,\n",
    "        )\n",
    "    },\n",
    "    freq=\"MS\",\n",
    "    lags=[1, 2, 3, 6, 12],\n",
    "    lag_transforms={\n",
    "        1: [RollingMean(window_size=3), RollingMean(window_size=6), RollingMean(window_size=12)],\n",
    "        3: [RollingStd(window_size=6)],\n",
    "        6: [ExponentiallyWeightedMean(alpha=0.3)],\n",
    "    },\n",
    "    date_features=[\"month\"],\n",
    ")\n",
    "mlf_cv2.fit(df, prediction_intervals=PredictionIntervals(n_windows=N_WINDOWS, h=HORIZON))\n",
    "cv_ml_intervals = mlf_cv2.cross_validation(\n",
    "    df=df,\n",
    "    h=HORIZON,\n",
    "    n_windows=N_CV_WINDOWS,\n",
    "    level=[90, 95],\n",
    "    prediction_intervals=PredictionIntervals(n_windows=3, h=HORIZON),\n",
    ")\n",
    "for level in [90, 95]:\n",
    "    result = compute_coverage(cv_ml_intervals, \"LightGBM\", level)\n",
    "    if result:\n",
    "        coverage_results.append(result)\n",
    "\n",
    "cov_df = pd.DataFrame(coverage_results)\n",
    "cov_df[\"target\"] = cov_df[\"level\"] / 100\n",
    "cov_df[\"coverage_gap\"] = (cov_df[\"coverage\"] - cov_df[\"target\"]).abs()\n",
    "\n",
    "print(\"=== Prediction Interval Coverage (Cross-Validation) ===\")\n",
    "print(cov_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interval width comparison: Conformal (LightGBM) vs Parametric (AutoARIMA)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# 90% intervals\n",
    "for model, color, style in [(\"AutoARIMA\", \"#1f77b4\", \"--\"), (\"LightGBM\", \"#9467bd\", \"-\")]:\n",
    "    lo = f\"{model}-lo-90\"\n",
    "    hi = f\"{model}-hi-90\"\n",
    "    if lo in fc_combined.columns:\n",
    "        axes[0].fill_between(\n",
    "            fc_combined[\"ds\"], fc_combined[lo], fc_combined[hi], alpha=0.2, color=color\n",
    "        )\n",
    "        axes[0].plot(\n",
    "            fc_combined[\"ds\"], fc_combined[model], style, color=color, linewidth=1.5, label=model\n",
    "        )\n",
    "\n",
    "axes[0].plot(df[\"ds\"].tail(24), df[\"y\"].tail(24), \"k-\", linewidth=1, alpha=0.5, label=\"History\")\n",
    "axes[0].set_title(\"90% Prediction Intervals — Parametric vs Conformal\")\n",
    "axes[0].yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "axes[0].legend()\n",
    "\n",
    "# Interval width by horizon step\n",
    "if \"LightGBM-lo-90\" in fc_ml.columns:\n",
    "    ml_widths = fc_ml[\"LightGBM-hi-90\"] - fc_ml[\"LightGBM-lo-90\"]\n",
    "    arima_widths = fc_stats[\"AutoARIMA-hi-90\"] - fc_stats[\"AutoARIMA-lo-90\"]\n",
    "    horizon_steps = range(1, HORIZON + 1)\n",
    "\n",
    "    axes[1].plot(\n",
    "        horizon_steps, arima_widths.values, \"o--\", label=\"AutoARIMA (parametric)\", color=\"#1f77b4\"\n",
    "    )\n",
    "    axes[1].plot(\n",
    "        horizon_steps, ml_widths.values, \"s-\", label=\"LightGBM (conformal)\", color=\"#9467bd\"\n",
    "    )\n",
    "    axes[1].set_xlabel(\"Forecast Horizon (months)\")\n",
    "    axes[1].set_ylabel(\"Interval Width\")\n",
    "    axes[1].set_title(\"90% Interval Width by Horizon Step\")\n",
    "    axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print width stats\n",
    "print(f\"\\nAutoARIMA 90% avg width: {arima_widths.mean():.4f}\")\n",
    "print(f\"LightGBM  90% avg width: {ml_widths.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Multi-Target Forecasting — Default Rate + Loan Volume\n",
    "\n",
    "Besides default rate, we also forecast **loan count** to demonstrate the pipeline's versatility. Both series are important for credit risk management:\n",
    "- Default rate → provisioning and stress testing\n",
    "- Loan volume → capacity planning and concentration risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build multi-series DataFrame\n",
    "df_volume = ts_raw[[\"ds\"]].copy()\n",
    "df_volume[\"unique_id\"] = \"loan_count\"\n",
    "df_volume[\"y\"] = ts_raw[\"loan_count\"].astype(float)\n",
    "\n",
    "df_multi = pd.concat([df, df_volume], ignore_index=True)\n",
    "print(f\"Multi-series shape: {df_multi.shape}\")\n",
    "print(f\"Series: {df_multi['unique_id'].unique()}\")\n",
    "\n",
    "# Forecast both with statsforecast\n",
    "sf_multi = StatsForecast(\n",
    "    models=[AutoARIMA(season_length=12), AutoETS(season_length=12)],\n",
    "    freq=\"MS\",\n",
    "    n_jobs=1,\n",
    ")\n",
    "fc_multi = sf_multi.forecast(h=HORIZON, df=df_multi, level=[90])\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "for i, series_id in enumerate([\"portfolio\", \"loan_count\"]):\n",
    "    hist = df_multi[df_multi[\"unique_id\"] == series_id]\n",
    "    fcast = fc_multi[fc_multi[\"unique_id\"] == series_id]\n",
    "\n",
    "    axes[i].plot(hist[\"ds\"], hist[\"y\"], \"k-\", linewidth=1.5, label=\"Actual\")\n",
    "    for model, color in [(\"AutoARIMA\", \"#1f77b4\"), (\"AutoETS\", \"#ff7f0e\")]:\n",
    "        axes[i].plot(fcast[\"ds\"], fcast[model], \"--\", color=color, label=model)\n",
    "        lo, hi = f\"{model}-lo-90\", f\"{model}-hi-90\"\n",
    "        axes[i].fill_between(fcast[\"ds\"], fcast[lo], fcast[hi], alpha=0.15, color=color)\n",
    "\n",
    "    title = \"Default Rate\" if series_id == \"portfolio\" else \"Loan Count\"\n",
    "    axes[i].set_title(f\"{title} — 12-Month Forecast\")\n",
    "    if series_id == \"portfolio\":\n",
    "        axes[i].yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    axes[i].legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Grade-Level Forecasting & Hierarchical Reconciliation\n",
    "\n",
    "We build grade-level time series (A-G), each with its own default rate dynamics:\n",
    "\n",
    "- Grade A: ~5.5% default rate (low risk, stable)\n",
    "- Grade G: ~42% default rate (high risk, volatile)\n",
    "\n",
    "We demonstrate **hierarchical reconciliation** using the  function from hierarchicalforecast. The summation matrix S encodes that portfolio = sum of grades.\n",
    "\n",
    "> **Note**: Default rates are proportions and not directly summable across groups. The hierarchy treats each grade's rate as an independent \"unit\" and the portfolio as their sum. For production use, one would forecast default *counts* and reconcile those (since counts are additive), then recompute rates. Here we show the technique applied to rate series as a pedagogical demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build grade-level time series from loan_master\n",
    "from hierarchicalforecast.utils import aggregate\n",
    "\n",
    "lm = pd.read_parquet(DATA_DIR / \"loan_master.parquet\")\n",
    "\n",
    "# Monthly aggregation by grade\n",
    "grade_monthly = (\n",
    "    lm.groupby([pd.Grouper(key=\"issue_d\", freq=\"MS\"), \"grade\"])\n",
    "    .agg(default_rate=(\"default_flag\", \"mean\"))\n",
    "    .reset_index()\n",
    ")\n",
    "grade_monthly.columns = [\"ds\", \"grade\", \"y\"]\n",
    "grade_monthly[\"total\"] = \"portfolio\"\n",
    "\n",
    "# Build hierarchy: total -> grade\n",
    "Y_df, S_df, tags = aggregate(\n",
    "    df=grade_monthly,\n",
    "    spec=[[\"total\"], [\"total\", \"grade\"]],\n",
    ")\n",
    "\n",
    "print(f\"Hierarchical series: {Y_df['unique_id'].nunique()} ({Y_df['unique_id'].unique().tolist()})\")\n",
    "print(f\"Observations: {Y_df.shape[0]}\")\n",
    "print(f\"S_df shape: {S_df.shape}\")\n",
    "\n",
    "# Show stats per series\n",
    "avg_by_id = Y_df.groupby(\"unique_id\")[\"y\"].agg([\"mean\", \"count\"]).round(4)\n",
    "print(\"Stats by series:\")\n",
    "print(avg_by_id.to_string())\n",
    "print()\n",
    "print(\"Note: portfolio y = sum of grade rates (not a true avg default rate)\")\n",
    "print(f\"True portfolio avg default rate: {grade_monthly['y'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast all series with AutoARIMA\n",
    "sf_hier = StatsForecast(\n",
    "    models=[AutoARIMA(season_length=12), AutoETS(season_length=12)],\n",
    "    freq=\"MS\",\n",
    "    n_jobs=1,\n",
    ")\n",
    "Y_hat_df = sf_hier.forecast(h=HORIZON, df=Y_df, level=[90])\n",
    "\n",
    "print(f\"Base forecasts shape: {Y_hat_df.shape}\")\n",
    "print(f\"Series forecasted: {Y_hat_df['unique_id'].unique().tolist()}\")\n",
    "Y_hat_df.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconcile with MinTrace (OLS)\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "from hierarchicalforecast.methods import BottomUp, MinTrace\n",
    "\n",
    "hrec = HierarchicalReconciliation(\n",
    "    reconcilers=[\n",
    "        BottomUp(),\n",
    "        MinTrace(method=\"ols\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "Y_reconciled = hrec.reconcile(\n",
    "    Y_hat_df=Y_hat_df,\n",
    "    tags=tags,\n",
    "    S_df=S_df,\n",
    "    Y_df=Y_df,\n",
    ")\n",
    "\n",
    "print(f\"Reconciled shape: {Y_reconciled.shape}\")\n",
    "print(f\"Reconciled columns: {Y_reconciled.columns.tolist()[:10]}...\")\n",
    "\n",
    "# Compare base vs reconciled for portfolio total\n",
    "portfolio_base = Y_hat_df[Y_hat_df[\"unique_id\"] == \"portfolio\"]\n",
    "portfolio_recon = Y_reconciled[Y_reconciled[\"unique_id\"] == \"portfolio\"]\n",
    "\n",
    "print(\"\\nPortfolio forecast comparison (AutoARIMA):\")\n",
    "print(f\"  Base:       {portfolio_base['AutoARIMA'].mean():.4f}\")\n",
    "if \"AutoARIMA/BottomUp\" in Y_reconciled.columns:\n",
    "    print(f\"  BottomUp:   {portfolio_recon['AutoARIMA/BottomUp'].mean():.4f}\")\n",
    "if \"AutoARIMA/MinTrace_method-ols\" in Y_reconciled.columns:\n",
    "    print(f\"  MinTrace:   {portfolio_recon['AutoARIMA/MinTrace_method-ols'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grade-level forecasts\n",
    "grades = sorted([uid for uid in Y_hat_df[\"unique_id\"].unique() if \"/\" in uid])\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, grade_id in enumerate([\"portfolio\"] + grades):\n",
    "    if i >= len(axes):\n",
    "        break\n",
    "    ax = axes[i]\n",
    "\n",
    "    # History\n",
    "    hist = Y_df[Y_df[\"unique_id\"] == grade_id]\n",
    "    fcast = Y_hat_df[Y_hat_df[\"unique_id\"] == grade_id]\n",
    "\n",
    "    ax.plot(hist[\"ds\"], hist[\"y\"], \"k-\", linewidth=1, alpha=0.7)\n",
    "    ax.plot(fcast[\"ds\"], fcast[\"AutoARIMA\"], \"b--\", linewidth=1.5)\n",
    "    ax.fill_between(\n",
    "        fcast[\"ds\"], fcast[\"AutoARIMA-lo-90\"], fcast[\"AutoARIMA-hi-90\"], alpha=0.2, color=\"blue\"\n",
    "    )\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "\n",
    "    label = grade_id.split(\"/\")[-1] if \"/\" in grade_id else \"Portfolio (Total)\"\n",
    "    avg_def = hist[\"y\"].mean()\n",
    "    ax.set_title(f\"{label} (avg={avg_def:.1%})\", fontsize=11)\n",
    "\n",
    "# Hide unused axes\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.suptitle(\"Grade-Level Default Rate Forecasts (AutoARIMA + 90% CI)\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. IFRS 9 & Stress Testing Implications\n",
    "\n",
    "The time series forecasts with conformal intervals directly support regulatory requirements:\n",
    "\n",
    "### Forward-Looking ECL (IFRS 9 para. 5.5.17)\n",
    "IFRS 9 requires incorporating **reasonable and supportable forecasts** into ECL estimates. Our forecasted default rates with intervals provide:\n",
    "- **Baseline scenario**: Point forecast\n",
    "- **Optimistic scenario**: Lower bound of 90% interval\n",
    "- **Adverse scenario**: Upper bound of 95% interval\n",
    "\n",
    "### Data-Driven Stress Testing\n",
    "The upper bound of conformal intervals serves as a **model-driven stress scenario** — more principled than ad-hoc macro assumptions, with mathematical coverage guarantees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IFRS 9 Scenario Analysis\n",
    "print(\"=== IFRS 9 Forward-Looking Default Rate Scenarios ===\")\n",
    "print(f\"Forecast horizon: {HORIZON} months (Stage 1 horizon)\\n\")\n",
    "\n",
    "# LightGBM conformal forecasts\n",
    "scenarios = pd.DataFrame(\n",
    "    {\n",
    "        \"month\": fc_ml[\"ds\"],\n",
    "        \"point_forecast\": fc_ml[\"LightGBM\"],\n",
    "        \"optimistic_90\": fc_ml[\"LightGBM-lo-90\"],\n",
    "        \"adverse_90\": fc_ml[\"LightGBM-hi-90\"],\n",
    "        \"optimistic_95\": fc_ml[\"LightGBM-lo-95\"],\n",
    "        \"adverse_95\": fc_ml[\"LightGBM-hi-95\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Monthly Scenarios:\")\n",
    "print(scenarios.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "# Summary\n",
    "print(\"\\n=== 12-Month Average Default Rate by Scenario ===\")\n",
    "print(f\"  Historical avg (last 12m): {df['y'].tail(12).mean():.4f}\")\n",
    "print(f\"  Optimistic (lo-95):        {scenarios['optimistic_95'].mean():.4f}\")\n",
    "print(f\"  Optimistic (lo-90):        {scenarios['optimistic_90'].mean():.4f}\")\n",
    "print(f\"  Baseline (point):          {scenarios['point_forecast'].mean():.4f}\")\n",
    "print(f\"  Adverse (hi-90):           {scenarios['adverse_90'].mean():.4f}\")\n",
    "print(f\"  Adverse (hi-95):           {scenarios['adverse_95'].mean():.4f}\")\n",
    "\n",
    "# Stress impact\n",
    "stress_ratio = scenarios[\"adverse_95\"].mean() / scenarios[\"point_forecast\"].mean()\n",
    "print(f\"\\n  Stress multiplier (95% / baseline): {stress_ratio:.2f}x\")\n",
    "print(f\"  → Provisions under stress scenario should be {stress_ratio:.2f}x the baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario fan chart\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# History\n",
    "ax.plot(df[\"ds\"].tail(36), df[\"y\"].tail(36), \"k-\", linewidth=2, label=\"Historical\")\n",
    "\n",
    "# Forecast scenarios\n",
    "ax.plot(fc_ml[\"ds\"], fc_ml[\"LightGBM\"], \"b-\", linewidth=2, label=\"Baseline (point)\")\n",
    "ax.fill_between(\n",
    "    fc_ml[\"ds\"],\n",
    "    fc_ml[\"LightGBM-lo-90\"],\n",
    "    fc_ml[\"LightGBM-hi-90\"],\n",
    "    alpha=0.25,\n",
    "    color=\"blue\",\n",
    "    label=\"90% Conformal Interval\",\n",
    ")\n",
    "ax.fill_between(\n",
    "    fc_ml[\"ds\"],\n",
    "    fc_ml[\"LightGBM-lo-95\"],\n",
    "    fc_ml[\"LightGBM-hi-95\"],\n",
    "    alpha=0.12,\n",
    "    color=\"blue\",\n",
    "    label=\"95% Conformal Interval\",\n",
    ")\n",
    "\n",
    "# Annotations\n",
    "ax.axhline(\n",
    "    y=scenarios[\"adverse_95\"].mean(),\n",
    "    color=\"red\",\n",
    "    linestyle=\":\",\n",
    "    alpha=0.6,\n",
    "    label=f\"Stress scenario avg ({scenarios['adverse_95'].mean():.1%})\",\n",
    ")\n",
    "\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "ax.set_title(\"IFRS 9 Forward-Looking Scenarios — Conformal Prediction Intervals\", fontsize=14)\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Default Rate\")\n",
    "ax.legend(loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Sensitivity Analysis — Horizon and Confidence Level\n",
    "\n",
    "We examine how forecast quality degrades with horizon length and how interval width changes with confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity: confidence level vs interval width\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: interval width vs confidence level (from final forecast)\n",
    "levels_test = [50, 70, 80, 90, 95, 99]\n",
    "widths_by_level = []\n",
    "\n",
    "for lev in levels_test:\n",
    "    fc_test = mlf.predict(h=HORIZON, level=[lev])\n",
    "    lo = f\"LightGBM-lo-{lev}\"\n",
    "    hi = f\"LightGBM-hi-{lev}\"\n",
    "    w = (fc_test[hi] - fc_test[lo]).mean()\n",
    "    widths_by_level.append({\"level\": lev, \"avg_width\": w})\n",
    "\n",
    "width_df = pd.DataFrame(widths_by_level)\n",
    "axes[0].plot(width_df[\"level\"], width_df[\"avg_width\"], \"bo-\", linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel(\"Confidence Level (%)\")\n",
    "axes[0].set_ylabel(\"Average Interval Width\")\n",
    "axes[0].set_title(\"Interval Width vs Confidence Level\")\n",
    "axes[0].set_xticks(levels_test)\n",
    "\n",
    "# Right: coverage vs horizon step (from CV)\n",
    "if \"LightGBM-lo-90\" in cv_ml_intervals.columns:\n",
    "    cv_ml_intervals[\"step\"] = cv_ml_intervals.groupby([\"unique_id\", \"cutoff\"]).cumcount() + 1\n",
    "    coverage_by_step = []\n",
    "    for step in range(1, HORIZON + 1):\n",
    "        mask = cv_ml_intervals[\"step\"] == step\n",
    "        if mask.sum() > 0:\n",
    "            subset = cv_ml_intervals[mask]\n",
    "            covered = (\n",
    "                (subset[\"y\"] >= subset[\"LightGBM-lo-90\"])\n",
    "                & (subset[\"y\"] <= subset[\"LightGBM-hi-90\"])\n",
    "            ).mean()\n",
    "            coverage_by_step.append({\"step\": step, \"coverage\": covered})\n",
    "\n",
    "    cov_step_df = pd.DataFrame(coverage_by_step)\n",
    "    axes[1].bar(cov_step_df[\"step\"], cov_step_df[\"coverage\"], color=\"steelblue\", alpha=0.7)\n",
    "    axes[1].axhline(y=0.90, color=\"red\", linestyle=\"--\", label=\"Target 90%\")\n",
    "    axes[1].set_xlabel(\"Forecast Horizon Step (months)\")\n",
    "    axes[1].set_ylabel(\"Empirical Coverage\")\n",
    "    axes[1].set_title(\"90% Coverage by Horizon Step\")\n",
    "    axes[1].legend()\n",
    "    axes[1].set_ylim(0, 1.1)\n",
    "else:\n",
    "    axes[1].text(\n",
    "        0.5,\n",
    "        0.5,\n",
    "        \"Conformal intervals not available in CV\",\n",
    "        transform=axes[1].transAxes,\n",
    "        ha=\"center\",\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Save Artifacts\n",
    "\n",
    "Save forecasts, model objects, and evaluation metrics for downstream notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save forecasts\n",
    "fc_combined.to_parquet(DATA_DIR / \"ts_forecasts.parquet\", index=False)\n",
    "logger.info(f\"Saved ts_forecasts.parquet: {fc_combined.shape}\")\n",
    "\n",
    "# Save ML model\n",
    "with open(MODEL_DIR / \"ts_mlforecast.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mlf, f)\n",
    "logger.info(\"Saved ts_mlforecast.pkl\")\n",
    "\n",
    "# Save hierarchical forecasts\n",
    "Y_hat_df.to_parquet(DATA_DIR / \"ts_hierarchical_forecasts.parquet\", index=False)\n",
    "logger.info(f\"Saved ts_hierarchical_forecasts.parquet: {Y_hat_df.shape}\")\n",
    "\n",
    "# Save CV results\n",
    "cv_stats_intervals.to_parquet(DATA_DIR / \"ts_cv_stats.parquet\", index=False)\n",
    "logger.info(f\"Saved ts_cv_stats.parquet: {cv_stats_intervals.shape}\")\n",
    "\n",
    "# Save IFRS9 scenarios\n",
    "scenarios.to_parquet(DATA_DIR / \"ts_ifrs9_scenarios.parquet\", index=False)\n",
    "logger.info(f\"Saved ts_ifrs9_scenarios.parquet: {scenarios.shape}\")\n",
    "\n",
    "print(\"\\n✓ All time series artifacts saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Models Trained\n",
    "| Model | Type | Prediction Intervals |\n",
    "|-------|------|---------------------|\n",
    "| AutoARIMA | Statistical | Parametric (Gaussian) |\n",
    "| AutoETS | Statistical | Parametric (Gaussian) |\n",
    "| AutoTheta | Statistical | Parametric |\n",
    "| SeasonalNaive | Baseline | Parametric |\n",
    "| LightGBM | ML (mlforecast) | **Conformal** (distribution-free) |\n",
    "\n",
    "### Key Results\n",
    "- **Cross-validation metrics** compared across all models (MAE, RMSE)\n",
    "- **Conformal intervals** from LightGBM provide distribution-free coverage guarantees\n",
    "- **Grade-level hierarchy** forecasted and reconciled (7 grades + portfolio total)\n",
    "- **IFRS 9 scenarios** derived from conformal interval bounds\n",
    "\n",
    "### Artifacts Saved\n",
    "- `data/processed/ts_forecasts.parquet` — Combined forecasts (all models)\n",
    "- `data/processed/ts_hierarchical_forecasts.parquet` — Grade-level forecasts\n",
    "- `data/processed/ts_ifrs9_scenarios.parquet` — IFRS 9 scenario table\n",
    "- `data/processed/ts_cv_stats.parquet` — CV results with intervals\n",
    "- `models/ts_mlforecast.pkl` — Fitted LightGBM forecaster\n",
    "\n",
    "### Next Steps\n",
    "1. **NB06**: Survival Analysis — lifetime PD curves for IFRS 9 Stage 2\n",
    "2. **NB08**: Portfolio Optimization — use both loan-level and portfolio-level intervals as uncertainty sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## Final Conclusions: Time Series Forecasting\n",
    "\n",
    "### Key Findings\n",
    "- Statistical and ML forecasters provide consistent short-horizon default-rate projections.\n",
    "- Forecast outputs support scenario framing rather than single-point planning.\n",
    "- Interval forecasts are necessary for governance under uncertain cycle transitions.\n",
    "\n",
    "### Financial Risk Interpretation\n",
    "- Portfolio-level default dynamics drive provisioning and capital planning cadence.\n",
    "- Forecast uncertainty should be propagated into strategic risk appetite and stress interpretation.\n",
    "- Trend and seasonality shifts require continuous monitoring, not one-off model deployment.\n",
    "\n",
    "### Contribution to End-to-End Pipeline\n",
    "- Produces forward-looking default-rate views that complement loan-level PD models.\n",
    "- Supports macro-level planning context for IFRS9 and portfolio strategy.\n",
    "- Adds a temporal risk lens that the cross-sectional PD model alone cannot provide."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lending-club-risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
