{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 11) Paper 2 — IFRS9 End-to-End\n",
    "\n",
    "Notebook de soporte para el paper IFRS9:\n",
    "- **Objetivo**: consolidar evidencia de escenarios ECL, sensibilidad y staging.\n",
    "- **Salidas**: `reports/paper_material/paper2/figures/` y `reports/paper_material/paper2/tables/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "PROJECT_ROOT = (\n",
    "    Path.cwd().resolve().parent if Path.cwd().name == \"notebooks\" else Path.cwd().resolve()\n",
    ")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "MODEL_DIR = PROJECT_ROOT / \"models\"\n",
    "\n",
    "\n",
    "def load_parquet(name: str) -> pd.DataFrame:\n",
    "    return pd.read_parquet(DATA_DIR / f\"{name}.parquet\")\n",
    "\n",
    "\n",
    "def load_json(name: str, from_models: bool = False) -> dict:\n",
    "    base = MODEL_DIR if from_models else DATA_DIR\n",
    "    return json.loads((base / f\"{name}.json\").read_text())\n",
    "\n",
    "\n",
    "def ensure_dirs(base: Path) -> dict[str, Path]:\n",
    "    dirs = {\n",
    "        \"base\": base,\n",
    "        \"fig\": base / \"figures\",\n",
    "        \"tbl\": base / \"tables\",\n",
    "    }\n",
    "    for d in dirs.values():\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "    return dirs\n",
    "\n",
    "\n",
    "def export_figure(fig: go.Figure, stem: str, out_fig_dir: Path) -> None:\n",
    "    html_path = out_fig_dir / f\"{stem}.html\"\n",
    "    fig.write_html(html_path)\n",
    "    try:\n",
    "        png_path = out_fig_dir / f\"{stem}.png\"\n",
    "        fig.write_image(png_path, width=1400, height=850, scale=2)\n",
    "        print(f\"Saved: {html_path} and {png_path}\")\n",
    "    except Exception as exc:  # noqa: BLE001\n",
    "        print(f\"Saved HTML only ({html_path}). PNG skipped: {exc}\")\n",
    "\n",
    "\n",
    "def export_table(df: pd.DataFrame, stem: str, out_tbl_dir: Path, max_rows: int = 2000) -> None:\n",
    "    csv_path = out_tbl_dir / f\"{stem}.csv\"\n",
    "    tex_path = out_tbl_dir / f\"{stem}.tex\"\n",
    "    out_df = df.copy().head(max_rows)\n",
    "    out_df.to_csv(csv_path, index=False)\n",
    "    try:\n",
    "        latex = out_df.to_latex(index=False, escape=False)\n",
    "        tex_path.write_text(latex, encoding=\"utf-8\")\n",
    "        print(f\"Saved: {csv_path} and {tex_path}\")\n",
    "    except Exception as exc:  # noqa: BLE001\n",
    "        print(f\"Saved CSV only ({csv_path}). LaTeX skipped: {exc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ensure_dirs(PROJECT_ROOT / \"reports\" / \"paper_material\" / \"paper2\")\n",
    "pipeline_summary = load_json(\"pipeline_summary\")\n",
    "ifrs9_summary = load_parquet(\"ifrs9_scenario_summary\")\n",
    "ifrs9_grid = load_parquet(\"ifrs9_sensitivity_grid\")\n",
    "ifrs9_grade = load_parquet(\"ifrs9_scenario_grade_summary\")\n",
    "print(\"ifrs9_summary\", ifrs9_summary.shape)\n",
    "print(\"ifrs9_grid\", ifrs9_grid.shape)\n",
    "print(\"ifrs9_grade\", ifrs9_grade.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline_summary.get(\"pipeline\", {})\n",
    "stages = pipeline.get(\"stages\", {}) if isinstance(pipeline.get(\"stages\"), dict) else {}\n",
    "baseline = ifrs9_summary.loc[ifrs9_summary[\"scenario\"] == \"baseline\"]\n",
    "severe = ifrs9_summary.loc[ifrs9_summary[\"scenario\"] == \"severe_stress\"]\n",
    "baseline_ecl = float(baseline[\"total_ecl\"].iloc[0]) if not baseline.empty else np.nan\n",
    "severe_ecl = float(severe[\"total_ecl\"].iloc[0]) if not severe.empty else np.nan\n",
    "uplift = (\n",
    "    (severe_ecl / baseline_ecl - 1.0)\n",
    "    if np.isfinite(baseline_ecl) and baseline_ecl > 0 and np.isfinite(severe_ecl)\n",
    "    else np.nan\n",
    ")\n",
    "key = pd.DataFrame(\n",
    "    [\n",
    "        {\"metric\": \"stage1_n\", \"value\": stages.get(\"S1\", np.nan)},\n",
    "        {\"metric\": \"stage2_n\", \"value\": stages.get(\"S2\", np.nan)},\n",
    "        {\"metric\": \"stage3_n\", \"value\": stages.get(\"S3\", np.nan)},\n",
    "        {\"metric\": \"baseline_ecl\", \"value\": baseline_ecl},\n",
    "        {\"metric\": \"severe_ecl\", \"value\": severe_ecl},\n",
    "        {\"metric\": \"severe_uplift\", \"value\": uplift},\n",
    "    ]\n",
    ")\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: stage composition by scenario\n",
    "stage_df = ifrs9_summary[[\"scenario\", \"stage1_share\", \"stage2_share\", \"stage3_share\"]].melt(\n",
    "    id_vars=[\"scenario\"],\n",
    "    var_name=\"stage\",\n",
    "    value_name=\"share\",\n",
    ")\n",
    "fig1 = px.bar(\n",
    "    stage_df,\n",
    "    x=\"scenario\",\n",
    "    y=\"share\",\n",
    "    color=\"stage\",\n",
    "    barmode=\"stack\",\n",
    "    title=\"Paper2-Fig1: Stage Composition by Scenario\",\n",
    ")\n",
    "fig1\n",
    "export_figure(fig1, \"paper2_fig1_stage_composition\", out[\"fig\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: ECL range by scenario\n",
    "range_df = ifrs9_summary[[\"scenario\", \"total_ecl_low\", \"total_ecl_point\", \"total_ecl_high\"]].melt(\n",
    "    id_vars=[\"scenario\"],\n",
    "    var_name=\"estimate\",\n",
    "    value_name=\"ecl\",\n",
    ")\n",
    "fig2 = px.bar(\n",
    "    range_df,\n",
    "    x=\"scenario\",\n",
    "    y=\"ecl\",\n",
    "    color=\"estimate\",\n",
    "    barmode=\"group\",\n",
    "    title=\"Paper2-Fig2: ECL Low/Point/High by Scenario\",\n",
    ")\n",
    "fig2\n",
    "export_figure(fig2, \"paper2_fig2_ecl_range_by_scenario\", out[\"fig\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3: sensitivity heatmap\n",
    "disc = (\n",
    "    0.05\n",
    "    if 0.05 in ifrs9_grid[\"discount_rate\"].unique()\n",
    "    else float(ifrs9_grid[\"discount_rate\"].iloc[0])\n",
    ")\n",
    "slice_df = ifrs9_grid.loc[ifrs9_grid[\"discount_rate\"] == disc]\n",
    "heat = (\n",
    "    slice_df.pivot_table(index=\"pd_mult\", columns=\"lgd_mult\", values=\"total_ecl\", aggfunc=\"mean\")\n",
    "    / 1_000_000\n",
    ")\n",
    "fig3 = px.imshow(\n",
    "    heat,\n",
    "    text_auto=\".1f\",\n",
    "    labels={\"x\": \"LGD multiplier\", \"y\": \"PD multiplier\", \"color\": \"ECL (MM)\"},\n",
    "    title=f\"Paper2-Fig3: ECL Sensitivity Heatmap (discount={disc:.2f})\",\n",
    ")\n",
    "fig3\n",
    "export_figure(fig3, \"paper2_fig3_ecl_sensitivity_heatmap\", out[\"fig\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export tables\n",
    "export_table(key, \"paper2_table0_key_metrics\", out[\"tbl\"])\n",
    "export_table(ifrs9_summary, \"paper2_table1_scenario_summary\", out[\"tbl\"])\n",
    "export_table(ifrs9_grid, \"paper2_table2_sensitivity_grid\", out[\"tbl\"], max_rows=5000)\n",
    "export_table(ifrs9_grade, \"paper2_tableA1_grade_summary\", out[\"tbl\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Threats to Validity (draft)\n",
    "- Trigger SICR por incertidumbre requiere calibración con política institucional.\n",
    "- Escenarios macro por multiplicadores son simplificados frente a escenarios oficiales.\n",
    "\n",
    "## Reproducibilidad\n",
    "```bash\n",
    "uv run dvc repro run_ifrs9_sensitivity build_pipeline_results export_streamlit_artifacts\n",
    "uv run pytest -q tests/test_evaluation/test_ifrs9.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
