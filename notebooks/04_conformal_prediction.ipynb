{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 04 — Conformal Prediction for PD Intervals\n",
    "\n",
    "**Objective**: Generate prediction intervals [PD_low, PD_high] with finite-sample coverage guarantees using MAPIE 1.3.\n",
    "\n",
    "**Key Innovation** (Thesis Contribution):\n",
    "- Traditional point-estimate PD models ignore prediction uncertainty\n",
    "- Bootstrap intervals lack finite-sample guarantees\n",
    "- **Conformal prediction** provides distribution-free, mathematically guaranteed coverage\n",
    "- These intervals feed directly into robust portfolio optimization (NB08)\n",
    "\n",
    "**Pipeline**: CatBoost PD → ProbabilityRegressor wrapper → MAPIE SplitConformalRegressor → [PD_low, PD_high]\n",
    "\n",
    "**Coverage guarantee**: For any α ∈ (0,1), conformal prediction ensures:\n",
    "$$P(Y_{n+1} \\in C(X_{n+1})) \\geq 1 - \\alpha$$\n",
    "with only the assumption of exchangeability (satisfied by our i.i.d. calibration split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from mapie.classification import SplitConformalClassifier\n",
    "from mapie.regression import SplitConformalRegressor\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from src.evaluation.metrics import conformal_metrics\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\", font_scale=1.1)\n",
    "plt.rcParams.update({\"figure.figsize\": (12, 6), \"figure.dpi\": 100})\n",
    "\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Setup complete — MAPIE 1.3, SplitConformalRegressor/Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Load Data & Model\n",
    "\n",
    "Load the feature-engineered datasets from NB02 and the trained CatBoost model from NB03. If NB03 artifacts are missing, we train a model inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature-engineered data\n",
    "train = pd.read_parquet(DATA_DIR / \"train_fe.parquet\")\n",
    "cal = pd.read_parquet(DATA_DIR / \"calibration_fe.parquet\")\n",
    "test = pd.read_parquet(DATA_DIR / \"test_fe.parquet\")\n",
    "\n",
    "# Load feature config\n",
    "with open(DATA_DIR / \"feature_config.pkl\", \"rb\") as f:\n",
    "    feat_config = pickle.load(f)\n",
    "CATBOOST_FEATURES = feat_config[\"CATBOOST_FEATURES\"]\n",
    "CAT_FEATURES = feat_config[\"CATEGORICAL_FEATURES\"].copy()\n",
    "if \"INTERACTION_FEATURES\" in feat_config:\n",
    "    for f in feat_config[\"INTERACTION_FEATURES\"]:\n",
    "        if f in CATBOOST_FEATURES and f not in CAT_FEATURES:\n",
    "            CAT_FEATURES.append(f)\n",
    "\n",
    "TARGET = \"default_flag\"\n",
    "\n",
    "# Convert categoricals to string for CatBoost\n",
    "for df in [train, cal, test]:\n",
    "    for c in CAT_FEATURES:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(str)\n",
    "\n",
    "# Load or train CatBoost model\n",
    "model_path = MODEL_DIR / \"pd_catboost_tuned.cbm\"\n",
    "if model_path.exists():\n",
    "    cb_model = CatBoostClassifier()\n",
    "    cb_model.load_model(str(model_path))\n",
    "    print(f\"Loaded CatBoost model from {model_path}\")\n",
    "else:\n",
    "    print(\"NB03 model not found — training inline (500 iterations)...\")\n",
    "    train_pool = Pool(train[CATBOOST_FEATURES], train[TARGET], cat_features=CAT_FEATURES)\n",
    "    cal_pool = Pool(cal[CATBOOST_FEATURES], cal[TARGET], cat_features=CAT_FEATURES)\n",
    "    cb_model = CatBoostClassifier(\n",
    "        iterations=500,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        auto_class_weights=\"Balanced\",\n",
    "        eval_metric=\"AUC\",\n",
    "        random_seed=42,\n",
    "        verbose=100,\n",
    "        early_stopping_rounds=50,\n",
    "    )\n",
    "    cb_model.fit(train_pool, eval_set=cal_pool, use_best_model=True)\n",
    "    cb_model.save_model(str(model_path))\n",
    "    print(f\"Model trained and saved to {model_path}\")\n",
    "\n",
    "# Load calibrator if available\n",
    "calibrator = None\n",
    "cal_path = MODEL_DIR / \"pd_calibrator.pkl\"\n",
    "if cal_path.exists():\n",
    "    with open(cal_path, \"rb\") as f:\n",
    "        calibrator = pickle.load(f)\n",
    "    print(f\"Loaded calibrator from {cal_path}\")\n",
    "\n",
    "# Prepare splits\n",
    "X_cal = cal[CATBOOST_FEATURES]\n",
    "y_cal = cal[TARGET]\n",
    "X_test = test[CATBOOST_FEATURES]\n",
    "y_test = test[TARGET]\n",
    "\n",
    "# Point predictions\n",
    "y_prob_test = cb_model.predict_proba(X_test)[:, 1]\n",
    "if calibrator is not None:\n",
    "    y_prob_test_cal = calibrator.predict(y_prob_test)\n",
    "else:\n",
    "    y_prob_test_cal = y_prob_test\n",
    "\n",
    "auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(f\"\\nTrain:       {len(train):>10,} rows\")\n",
    "print(f\"Calibration: {len(cal):>10,} rows\")\n",
    "print(f\"Test:        {len(test):>10,} rows\")\n",
    "print(f\"\\nCatBoost AUC (test): {auc:.4f}\")\n",
    "print(f\"Features: {len(CATBOOST_FEATURES)} total, {len(CAT_FEATURES)} categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Conformal Prediction — Theory & Setup\n",
    "\n",
    "### Split Conformal Prediction (Vovk et al., 2005)\n",
    "\n",
    "1. **Split** data into training set and calibration set (already done in OOT split)\n",
    "2. **Fit** model on training set (CatBoost from NB03)\n",
    "3. **Compute nonconformity scores** on calibration set: $s_i = |y_i - \\hat{y}_i|$\n",
    "4. **Quantile**: Find $\\hat{q}$ as the $\\lceil(1-\\alpha)(n_{cal}+1)\\rceil / n_{cal}$ quantile of scores\n",
    "5. **Predict**: $C(X_{new}) = [\\hat{y}_{new} - \\hat{q}, \\hat{y}_{new} + \\hat{q}]$\n",
    "\n",
    "### ProbabilityRegressor Trick\n",
    "\n",
    "Since MAPIE's `SplitConformalRegressor` works with regression targets, we wrap CatBoost's `predict_proba` as a \"regressor\" that outputs P(default). The conformal procedure then generates intervals around these probability predictions.\n",
    "\n",
    "**Note on interval width**: Since the true outcomes are binary (0/1), conformal intervals will be relatively wide. This is theoretically correct — the intervals guarantee coverage of the *realized outcome*, not the latent probability. For portfolio optimization, the **upper bound PD_high** is the key input for robust decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilityRegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"Wraps a classifier's predict_proba as regression output for MAPIE.\"\"\"\n",
    "\n",
    "    def __init__(self, classifier):\n",
    "        self.classifier = classifier\n",
    "        self.is_fitted_ = True  # Mark as fitted for MAPIE checks\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self  # No-op — model already fitted\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict_proba(X)[:, 1]\n",
    "\n",
    "\n",
    "class CatBoostClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Wraps CatBoost for MAPIE classification (numpy → DataFrame conversion).\n",
    "\n",
    "    MAPIE internally passes numpy arrays for fitted-model checks, but CatBoost\n",
    "    with cat_features requires DataFrame input. This wrapper handles the conversion.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, feature_names, cat_features):\n",
    "        self.model = model\n",
    "        self.feature_names = feature_names\n",
    "        self.cat_features = cat_features\n",
    "        self.classes_ = np.array([0, 1])\n",
    "        self.n_features_in_ = len(feature_names)\n",
    "        self.is_fitted_ = True\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_df = self._to_dataframe(X)\n",
    "        return self.model.predict(X_df).flatten().astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_df = self._to_dataframe(X)\n",
    "        return self.model.predict_proba(X_df)\n",
    "\n",
    "    def _to_dataframe(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return X\n",
    "        df = pd.DataFrame(X, columns=self.feature_names)\n",
    "        for c in self.cat_features:\n",
    "            df[c] = df[c].astype(str)\n",
    "        return df\n",
    "\n",
    "\n",
    "print(\"Wrappers defined: ProbabilityRegressor, CatBoostClassifierWrapper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Split Conformal Regression — PD Intervals\n",
    "\n",
    "Generate prediction intervals at two significance levels:\n",
    "- **α = 0.10** → 90% coverage (standard)\n",
    "- **α = 0.05** → 95% coverage (conservative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate PD intervals at multiple alpha levels\n",
    "prob_reg = ProbabilityRegressor(cb_model)\n",
    "alpha_levels = [0.10, 0.05]\n",
    "results = {}\n",
    "\n",
    "for alpha in alpha_levels:\n",
    "    t0 = time.time()\n",
    "    scr = SplitConformalRegressor(\n",
    "        estimator=prob_reg,\n",
    "        confidence_level=1 - alpha,\n",
    "        prefit=True,\n",
    "    )\n",
    "    # MAPIE 1.3: skip .fit() with prefit=True, go directly to conformalize\n",
    "    scr.conformalize(X_cal, y_cal.astype(float).values)\n",
    "\n",
    "    # predict_interval returns (y_pred, y_intervals) with shape (n, 2, n_conf_levels)\n",
    "    y_pred, y_intervals_raw = scr.predict_interval(X_test)\n",
    "    y_intervals = y_intervals_raw[:, :, 0]  # squeeze to (n, 2)\n",
    "\n",
    "    # Clip to valid probability range\n",
    "    y_intervals = np.clip(y_intervals, 0, 1)\n",
    "    y_pred = np.clip(y_pred, 0, 1)\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    # Compute conformal metrics\n",
    "    metrics = conformal_metrics(y_test.values, y_intervals, alpha)\n",
    "    metrics[\"conformalize_time_s\"] = elapsed\n",
    "\n",
    "    results[alpha] = {\n",
    "        \"y_pred\": y_pred,\n",
    "        \"y_intervals\": y_intervals,\n",
    "        \"metrics\": metrics,\n",
    "        \"scr\": scr,\n",
    "    }\n",
    "\n",
    "    print(f\"\\nalpha={alpha} ({(1 - alpha) * 100:.0f}% target coverage):\")\n",
    "    print(f\"  Empirical coverage:  {metrics['empirical_coverage']:.4f}\")\n",
    "    print(f\"  Target coverage:     {metrics['target_coverage']:.4f}\")\n",
    "    print(f\"  Coverage gap:        {metrics['coverage_gap']:.4f}\")\n",
    "    print(f\"  Avg interval width:  {metrics['avg_width']:.4f}\")\n",
    "    print(f\"  Median width:        {metrics['median_width']:.4f}\")\n",
    "    print(f\"  90th pct width:      {metrics['width_90th_pct']:.4f}\")\n",
    "    print(f\"  Time: {elapsed:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Coverage Validation\n",
    "\n",
    "Verify that empirical coverage meets the theoretical guarantee. With $n_{cal}$ calibration samples, the coverage guarantee is:\n",
    "$$1 - \\alpha \\leq \\text{Coverage} \\leq 1 - \\alpha + \\frac{1}{n_{cal}+1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage summary table\n",
    "coverage_rows = []\n",
    "for alpha, data in results.items():\n",
    "    m = data[\"metrics\"]\n",
    "    n_cal = len(X_cal)\n",
    "    upper_bound = 1 - alpha + 1 / (n_cal + 1)\n",
    "    coverage_rows.append(\n",
    "        {\n",
    "            \"Alpha\": alpha,\n",
    "            \"Target\": f\"{(1 - alpha) * 100:.0f}%\",\n",
    "            \"Empirical\": f\"{m['empirical_coverage']:.4f}\",\n",
    "            \"Upper Bound\": f\"{upper_bound:.4f}\",\n",
    "            \"Gap\": f\"{m['coverage_gap']:.4f}\",\n",
    "            \"Avg Width\": f\"{m['avg_width']:.4f}\",\n",
    "            \"Median Width\": f\"{m['median_width']:.4f}\",\n",
    "            \"Valid\": \"YES\" if m[\"empirical_coverage\"] >= 1 - alpha - 0.02 else \"NO\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "coverage_df = pd.DataFrame(coverage_rows)\n",
    "print(\"=\" * 85)\n",
    "print(\"COVERAGE VALIDATION — Conformal Prediction Guarantees\")\n",
    "print(\"=\" * 85)\n",
    "print(coverage_df.to_string(index=False))\n",
    "print(f\"\\nCalibration set size: {len(X_cal):,}\")\n",
    "print(f\"Test set size:        {len(X_test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Interval Width Analysis\n",
    "\n",
    "Analyze the distribution and properties of PD intervals. Narrower intervals indicate more precise predictions. We expect width to vary by risk segment — higher risk loans should have wider intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use alpha=0.10 as primary analysis\n",
    "alpha_main = 0.10\n",
    "y_pred_main = results[alpha_main][\"y_pred\"]\n",
    "y_int_main = results[alpha_main][\"y_intervals\"]\n",
    "widths_main = y_int_main[:, 1] - y_int_main[:, 0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "# Width distribution\n",
    "axes[0].hist(widths_main, bins=50, color=\"#3498db\", alpha=0.7, edgecolor=\"white\")\n",
    "axes[0].axvline(\n",
    "    widths_main.mean(),\n",
    "    color=\"#e74c3c\",\n",
    "    ls=\"--\",\n",
    "    linewidth=2,\n",
    "    label=f\"Mean: {widths_main.mean():.4f}\",\n",
    ")\n",
    "axes[0].axvline(\n",
    "    np.median(widths_main),\n",
    "    color=\"#2ecc71\",\n",
    "    ls=\"--\",\n",
    "    linewidth=2,\n",
    "    label=f\"Median: {np.median(widths_main):.4f}\",\n",
    ")\n",
    "axes[0].set_xlabel(\"Interval Width (PD_high - PD_low)\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].set_title(\"Distribution of Interval Widths (α=0.10)\", fontweight=\"bold\")\n",
    "axes[0].legend()\n",
    "\n",
    "# PD point vs width\n",
    "axes[1].scatter(y_pred_main, widths_main, alpha=0.05, s=2, color=\"#3498db\")\n",
    "axes[1].set_xlabel(\"Point PD Prediction\")\n",
    "axes[1].set_ylabel(\"Interval Width\")\n",
    "axes[1].set_title(\"Width vs Point Prediction\", fontweight=\"bold\")\n",
    "\n",
    "# Interval bounds: sorted by PD\n",
    "sorted_idx = np.argsort(y_pred_main)\n",
    "n_show = min(500, len(sorted_idx))\n",
    "step = max(1, len(sorted_idx) // n_show)\n",
    "idx_sample = sorted_idx[::step]\n",
    "\n",
    "axes[2].fill_between(\n",
    "    range(len(idx_sample)),\n",
    "    y_int_main[idx_sample, 0],\n",
    "    y_int_main[idx_sample, 1],\n",
    "    alpha=0.3,\n",
    "    color=\"#3498db\",\n",
    "    label=\"90% interval\",\n",
    ")\n",
    "axes[2].plot(\n",
    "    range(len(idx_sample)),\n",
    "    y_pred_main[idx_sample],\n",
    "    color=\"#e74c3c\",\n",
    "    linewidth=0.5,\n",
    "    label=\"Point PD\",\n",
    ")\n",
    "axes[2].set_xlabel(\"Loans (sorted by PD)\")\n",
    "axes[2].set_ylabel(\"PD\")\n",
    "axes[2].set_title(\"PD Intervals (sorted)\", fontweight=\"bold\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Width statistics\n",
    "print(\"Interval Width Statistics (α=0.10):\")\n",
    "print(f\"  Mean:   {widths_main.mean():.4f}\")\n",
    "print(f\"  Std:    {widths_main.std():.4f}\")\n",
    "print(f\"  Min:    {widths_main.min():.4f}\")\n",
    "print(f\"  25th:   {np.percentile(widths_main, 25):.4f}\")\n",
    "print(f\"  50th:   {np.percentile(widths_main, 50):.4f}\")\n",
    "print(f\"  75th:   {np.percentile(widths_main, 75):.4f}\")\n",
    "print(f\"  90th:   {np.percentile(widths_main, 90):.4f}\")\n",
    "print(f\"  Max:    {widths_main.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Width analysis by risk segment (grade)\n",
    "analysis_df = pd.DataFrame(\n",
    "    {\n",
    "        \"y_true\": y_test.values,\n",
    "        \"y_pred\": y_pred_main,\n",
    "        \"pd_low\": y_int_main[:, 0],\n",
    "        \"pd_high\": y_int_main[:, 1],\n",
    "        \"width\": widths_main,\n",
    "        \"grade\": test[\"grade\"].values if \"grade\" in test.columns else \"Unknown\",\n",
    "    }\n",
    ")\n",
    "\n",
    "if \"grade\" in test.columns:\n",
    "    grade_stats = (\n",
    "        analysis_df.groupby(\"grade\")\n",
    "        .agg(\n",
    "            n_loans=(\"y_true\", \"count\"),\n",
    "            default_rate=(\"y_true\", \"mean\"),\n",
    "            avg_pd=(\"y_pred\", \"mean\"),\n",
    "            avg_pd_low=(\"pd_low\", \"mean\"),\n",
    "            avg_pd_high=(\"pd_high\", \"mean\"),\n",
    "            avg_width=(\"width\", \"mean\"),\n",
    "            median_width=(\"width\", \"median\"),\n",
    "            coverage=(\n",
    "                \"y_true\",\n",
    "                lambda x: (\n",
    "                    (analysis_df.loc[x.index, \"y_true\"] >= analysis_df.loc[x.index, \"pd_low\"])\n",
    "                    & (analysis_df.loc[x.index, \"y_true\"] <= analysis_df.loc[x.index, \"pd_high\"])\n",
    "                ).mean(),\n",
    "            ),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 100)\n",
    "    print(\"CONFORMAL INTERVALS BY GRADE (α=0.10)\")\n",
    "    print(\"=\" * 100)\n",
    "    print(grade_stats.to_string(index=False, float_format=\"{:.4f}\".format))\n",
    "\n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    grades = grade_stats[\"grade\"].values\n",
    "    x = range(len(grades))\n",
    "\n",
    "    # Average width by grade\n",
    "    colors_g = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(grades)))\n",
    "    axes[0].bar(x, grade_stats[\"avg_width\"], color=colors_g)\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(grades)\n",
    "    axes[0].set_xlabel(\"Grade\")\n",
    "    axes[0].set_ylabel(\"Avg Interval Width\")\n",
    "    axes[0].set_title(\"Interval Width by Grade\", fontweight=\"bold\")\n",
    "\n",
    "    # Coverage by grade\n",
    "    axes[1].bar(x, grade_stats[\"coverage\"], color=colors_g)\n",
    "    axes[1].axhline(0.90, color=\"#e74c3c\", ls=\"--\", label=\"90% target\")\n",
    "    axes[1].set_xticks(x)\n",
    "    axes[1].set_xticklabels(grades)\n",
    "    axes[1].set_xlabel(\"Grade\")\n",
    "    axes[1].set_ylabel(\"Empirical Coverage\")\n",
    "    axes[1].set_title(\"Coverage by Grade\", fontweight=\"bold\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    # PD bands by grade\n",
    "    axes[2].errorbar(\n",
    "        grades,\n",
    "        grade_stats[\"avg_pd\"],\n",
    "        yerr=[\n",
    "            grade_stats[\"avg_pd\"] - grade_stats[\"avg_pd_low\"],\n",
    "            grade_stats[\"avg_pd_high\"] - grade_stats[\"avg_pd\"],\n",
    "        ],\n",
    "        fmt=\"o\",\n",
    "        capsize=5,\n",
    "        color=\"#e74c3c\",\n",
    "        markersize=8,\n",
    "        label=\"PD point ± conformal interval\",\n",
    "    )\n",
    "    axes[2].scatter(\n",
    "        grades,\n",
    "        grade_stats[\"default_rate\"],\n",
    "        marker=\"x\",\n",
    "        s=100,\n",
    "        color=\"#2c3e50\",\n",
    "        zorder=5,\n",
    "        label=\"Actual default rate\",\n",
    "    )\n",
    "    axes[2].set_xlabel(\"Grade\")\n",
    "    axes[2].set_ylabel(\"PD / Default Rate\")\n",
    "    axes[2].set_title(\"PD Intervals vs Actual Default Rate\", fontweight=\"bold\")\n",
    "    axes[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Classification Prediction Sets (LAC, APS)\n",
    "\n",
    "Beyond regression intervals, conformal prediction can produce **prediction sets** — subsets of {No Default, Default} that are guaranteed to contain the true class with probability ≥ 1−α.\n",
    "\n",
    "- **Singleton {0} or {1}**: Model is confident — only one class in the set\n",
    "- **Both {0, 1}**: Model is uncertain — both classes possible\n",
    "- **Empty ∅**: Rare — can occur with very conservative α"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap CatBoost for MAPIE classification compatibility\n",
    "cb_wrapped = CatBoostClassifierWrapper(cb_model, CATBOOST_FEATURES, CAT_FEATURES)\n",
    "\n",
    "classification_results = {}\n",
    "for alpha in [0.10, 0.05]:\n",
    "    try:\n",
    "        scc = SplitConformalClassifier(\n",
    "            estimator=cb_wrapped,\n",
    "            confidence_level=1 - alpha,\n",
    "            prefit=True,\n",
    "        )\n",
    "        scc.conformalize(X_cal, y_cal.values)\n",
    "\n",
    "        # predict_set returns (y_pred, y_sets) where y_sets shape (n, 2, 1)\n",
    "        _, y_sets_raw = scc.predict_set(X_test)\n",
    "        y_sets = y_sets_raw[:, :, 0]  # squeeze to (n, 2) boolean\n",
    "\n",
    "        singleton_rate = (y_sets.sum(axis=1) == 1).mean()\n",
    "        empty_rate = (y_sets.sum(axis=1) == 0).mean()\n",
    "        both_rate = (y_sets.sum(axis=1) == 2).mean()\n",
    "\n",
    "        # Coverage: true class is in prediction set\n",
    "        coverage = np.array([y_sets[i, int(y_test.values[i])] for i in range(len(y_test))]).mean()\n",
    "\n",
    "        classification_results[alpha] = {\n",
    "            \"y_sets\": y_sets,\n",
    "            \"singleton_rate\": singleton_rate,\n",
    "            \"empty_rate\": empty_rate,\n",
    "            \"both_rate\": both_rate,\n",
    "            \"coverage\": coverage,\n",
    "        }\n",
    "\n",
    "        print(f\"\\nalpha={alpha} ({(1 - alpha) * 100:.0f}% target):\")\n",
    "        print(f\"  Coverage:      {coverage:.4f}\")\n",
    "        print(f\"  Singleton:     {singleton_rate:.2%} (confident predictions)\")\n",
    "        print(f\"  Both classes:  {both_rate:.2%} (uncertain predictions)\")\n",
    "        print(f\"  Empty sets:    {empty_rate:.2%}\")\n",
    "    except Exception as e:\n",
    "        print(f\"alpha={alpha}: Classification sets failed — {e}\")\n",
    "        classification_results[alpha] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction sets composition\n",
    "valid_results = {a: r for a, r in classification_results.items() if r is not None}\n",
    "if valid_results:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Stacked bar chart of set sizes\n",
    "    alphas = list(valid_results.keys())\n",
    "    singletons = [valid_results[a][\"singleton_rate\"] for a in alphas]\n",
    "    boths = [valid_results[a][\"both_rate\"] for a in alphas]\n",
    "    empties = [valid_results[a][\"empty_rate\"] for a in alphas]\n",
    "\n",
    "    x = range(len(alphas))\n",
    "    axes[0].bar(x, singletons, label=\"Singleton {0} or {1}\", color=\"#2ecc71\")\n",
    "    axes[0].bar(x, boths, bottom=singletons, label=\"Both {0, 1}\", color=\"#f39c12\")\n",
    "    axes[0].bar(\n",
    "        x,\n",
    "        empties,\n",
    "        bottom=[s + b for s, b in zip(singletons, boths, strict=False)],\n",
    "        label=\"Empty ∅\",\n",
    "        color=\"#e74c3c\",\n",
    "    )\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels([f\"α={a}\" for a in alphas])\n",
    "    axes[0].set_ylabel(\"Proportion\")\n",
    "    axes[0].set_title(\"Prediction Set Composition\", fontweight=\"bold\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Singleton rate by predicted PD decile (use first alpha)\n",
    "    first_alpha = alphas[0]\n",
    "    first_sets = valid_results[first_alpha][\"y_sets\"]\n",
    "    is_singleton = first_sets.sum(axis=1) == 1\n",
    "    pd_decile = pd.qcut(y_prob_test, q=10, labels=False, duplicates=\"drop\") + 1\n",
    "\n",
    "    singleton_by_decile = (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"decile\": pd_decile,\n",
    "                \"singleton\": is_singleton,\n",
    "            }\n",
    "        )\n",
    "        .groupby(\"decile\")[\"singleton\"]\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    axes[1].bar(singleton_by_decile.index, singleton_by_decile.values, color=\"#3498db\")\n",
    "    axes[1].set_xlabel(\"PD Decile (1=lowest risk)\")\n",
    "    axes[1].set_ylabel(\"Singleton Rate\")\n",
    "    axes[1].set_title(f\"Singleton Rate by Risk Decile (α={first_alpha})\", fontweight=\"bold\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Classification conformal not available — skipping visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Mondrian Conformal Prediction (Group-Conditional)\n",
    "\n",
    "Standard conformal provides **marginal** coverage (averaged over all samples). Mondrian conformal provides **conditional** coverage within subgroups — e.g., by grade.\n",
    "\n",
    "This is critical for fairness: ensuring that coverage guarantees hold within each risk segment, not just on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian Conformal: separate conformal per grade\n",
    "alpha_mond = 0.10\n",
    "prob_reg_mond = ProbabilityRegressor(cb_model)\n",
    "\n",
    "mondrian_results = {}\n",
    "grades_unique = sorted(test[\"grade\"].unique()) if \"grade\" in test.columns else []\n",
    "\n",
    "for grade in grades_unique:\n",
    "    # Calibration subset for this grade\n",
    "    cal_mask = cal[\"grade\"] == grade\n",
    "    test_mask = test[\"grade\"] == grade\n",
    "\n",
    "    if cal_mask.sum() < 30 or test_mask.sum() < 30:\n",
    "        continue\n",
    "\n",
    "    X_cal_g = cal.loc[cal_mask, CATBOOST_FEATURES]\n",
    "    y_cal_g = cal.loc[cal_mask, TARGET].astype(float).values\n",
    "    X_test_g = test.loc[test_mask, CATBOOST_FEATURES]\n",
    "    y_test_g = test.loc[test_mask, TARGET].values\n",
    "\n",
    "    scr_g = SplitConformalRegressor(\n",
    "        estimator=prob_reg_mond,\n",
    "        confidence_level=1 - alpha_mond,\n",
    "        prefit=True,\n",
    "    )\n",
    "    scr_g.conformalize(X_cal_g, y_cal_g)\n",
    "\n",
    "    y_pred_g, y_int_raw_g = scr_g.predict_interval(X_test_g)\n",
    "    y_int_g = np.clip(y_int_raw_g[:, :, 0], 0, 1)\n",
    "    y_pred_g = np.clip(y_pred_g, 0, 1)\n",
    "\n",
    "    widths_g = y_int_g[:, 1] - y_int_g[:, 0]\n",
    "    covered_g = ((y_test_g >= y_int_g[:, 0]) & (y_test_g <= y_int_g[:, 1])).mean()\n",
    "\n",
    "    mondrian_results[grade] = {\n",
    "        \"n_cal\": int(cal_mask.sum()),\n",
    "        \"n_test\": int(test_mask.sum()),\n",
    "        \"coverage\": covered_g,\n",
    "        \"avg_width\": widths_g.mean(),\n",
    "        \"default_rate\": y_test_g.mean(),\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "if mondrian_results:\n",
    "    mond_df = pd.DataFrame(mondrian_results).T.reset_index()\n",
    "    mond_df.columns = [\"Grade\", \"n_cal\", \"n_test\", \"Coverage\", \"Avg Width\", \"Default Rate\"]\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"MONDRIAN CONFORMAL — Group-Conditional Coverage (α={alpha_mond})\")\n",
    "    print(\"=\" * 80)\n",
    "    print(mond_df.to_string(index=False, float_format=\"{:.4f}\".format))\n",
    "\n",
    "    # Compare marginal vs Mondrian\n",
    "    marginal_cov = results[alpha_mond][\"metrics\"][\"empirical_coverage\"]\n",
    "    marginal_width = results[alpha_mond][\"metrics\"][\"avg_width\"]\n",
    "    print(f\"\\nMarginal (pooled): coverage={marginal_cov:.4f}, avg_width={marginal_width:.4f}\")\n",
    "\n",
    "    cov_gap = mond_df[\"Coverage\"].max() - mond_df[\"Coverage\"].min()\n",
    "    print(f\"Coverage range across grades: {cov_gap:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian vs Marginal comparison\n",
    "if mondrian_results:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    grades_m = list(mondrian_results.keys())\n",
    "    n_g = len(grades_m)\n",
    "    x = range(n_g)\n",
    "\n",
    "    # Coverage comparison\n",
    "    cov_marginal = [results[alpha_mond][\"metrics\"][\"empirical_coverage\"]] * n_g\n",
    "    cov_mondrian = [mondrian_results[g][\"coverage\"] for g in grades_m]\n",
    "\n",
    "    axes[0].bar(\n",
    "        [xi - 0.15 for xi in x],\n",
    "        cov_marginal,\n",
    "        width=0.3,\n",
    "        label=\"Marginal\",\n",
    "        color=\"#3498db\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    axes[0].bar(\n",
    "        [xi + 0.15 for xi in x],\n",
    "        cov_mondrian,\n",
    "        width=0.3,\n",
    "        label=\"Mondrian\",\n",
    "        color=\"#e74c3c\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    axes[0].axhline(0.90, color=\"#2c3e50\", ls=\"--\", alpha=0.5, label=\"90% target\")\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(grades_m)\n",
    "    axes[0].set_xlabel(\"Grade\")\n",
    "    axes[0].set_ylabel(\"Coverage\")\n",
    "    axes[0].set_title(\"Marginal vs Mondrian Coverage\", fontweight=\"bold\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Width comparison\n",
    "    width_marginal = [results[alpha_mond][\"metrics\"][\"avg_width\"]] * n_g\n",
    "    width_mondrian = [mondrian_results[g][\"avg_width\"] for g in grades_m]\n",
    "\n",
    "    axes[1].bar(\n",
    "        [xi - 0.15 for xi in x],\n",
    "        width_marginal,\n",
    "        width=0.3,\n",
    "        label=\"Marginal\",\n",
    "        color=\"#3498db\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    axes[1].bar(\n",
    "        [xi + 0.15 for xi in x],\n",
    "        width_mondrian,\n",
    "        width=0.3,\n",
    "        label=\"Mondrian\",\n",
    "        color=\"#e74c3c\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    axes[1].set_xticks(x)\n",
    "    axes[1].set_xticklabels(grades_m)\n",
    "    axes[1].set_xlabel(\"Grade\")\n",
    "    axes[1].set_ylabel(\"Avg Interval Width\")\n",
    "    axes[1].set_title(\"Marginal vs Mondrian Width\", fontweight=\"bold\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Sensitivity Analysis — Coverage vs Efficiency Tradeoff\n",
    "\n",
    "Vary α from 0.01 to 0.30 and observe how coverage and interval width change. The fundamental tradeoff: higher coverage requires wider intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity: coverage vs width across alpha values\n",
    "alpha_range = [0.01, 0.02, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30]\n",
    "sensitivity = []\n",
    "\n",
    "prob_reg_sens = ProbabilityRegressor(cb_model)\n",
    "for alpha in alpha_range:\n",
    "    scr_s = SplitConformalRegressor(\n",
    "        estimator=prob_reg_sens,\n",
    "        confidence_level=1 - alpha,\n",
    "        prefit=True,\n",
    "    )\n",
    "    scr_s.conformalize(X_cal, y_cal.astype(float).values)\n",
    "    _, y_int_raw_s = scr_s.predict_interval(X_test)\n",
    "    y_int_s = np.clip(y_int_raw_s[:, :, 0], 0, 1)\n",
    "    widths_s = y_int_s[:, 1] - y_int_s[:, 0]\n",
    "    covered_s = ((y_test.values >= y_int_s[:, 0]) & (y_test.values <= y_int_s[:, 1])).mean()\n",
    "\n",
    "    sensitivity.append(\n",
    "        {\n",
    "            \"alpha\": alpha,\n",
    "            \"target\": 1 - alpha,\n",
    "            \"coverage\": covered_s,\n",
    "            \"avg_width\": widths_s.mean(),\n",
    "            \"median_width\": np.median(widths_s),\n",
    "        }\n",
    "    )\n",
    "\n",
    "sens_df = pd.DataFrame(sensitivity)\n",
    "print(\"Coverage vs Efficiency Tradeoff:\")\n",
    "print(sens_df.to_string(index=False, float_format=\"{:.4f}\".format))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Coverage vs target\n",
    "axes[0].plot(\n",
    "    sens_df[\"target\"],\n",
    "    sens_df[\"coverage\"],\n",
    "    \"o-\",\n",
    "    color=\"#e74c3c\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    label=\"Empirical coverage\",\n",
    ")\n",
    "axes[0].plot([0.7, 1.0], [0.7, 1.0], \"k--\", alpha=0.3, label=\"Perfect calibration\")\n",
    "axes[0].set_xlabel(\"Target Coverage (1 - α)\")\n",
    "axes[0].set_ylabel(\"Empirical Coverage\")\n",
    "axes[0].set_title(\"Coverage Calibration\", fontweight=\"bold\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Width vs target coverage\n",
    "axes[1].plot(\n",
    "    sens_df[\"target\"],\n",
    "    sens_df[\"avg_width\"],\n",
    "    \"o-\",\n",
    "    color=\"#3498db\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    label=\"Avg width\",\n",
    ")\n",
    "axes[1].plot(\n",
    "    sens_df[\"target\"],\n",
    "    sens_df[\"median_width\"],\n",
    "    \"s--\",\n",
    "    color=\"#2ecc71\",\n",
    "    linewidth=2,\n",
    "    markersize=6,\n",
    "    label=\"Median width\",\n",
    ")\n",
    "axes[1].set_xlabel(\"Target Coverage (1 - α)\")\n",
    "axes[1].set_ylabel(\"Interval Width\")\n",
    "axes[1].set_title(\"Width vs Coverage Tradeoff\", fontweight=\"bold\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Sample Loan Predictions with Intervals\n",
    "\n",
    "Visualize specific loan predictions showing the conformal intervals. This is what a loan officer or automated system would see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select representative loans (one from each risk tier)\n",
    "y_pred_90 = results[0.10][\"y_pred\"]\n",
    "y_int_90 = results[0.10][\"y_intervals\"]\n",
    "\n",
    "# Pick diverse samples\n",
    "np.random.seed(42)\n",
    "sample_idx = []\n",
    "for pct in [5, 15, 30, 50, 70, 85, 95]:\n",
    "    target_pd = np.percentile(y_pred_90, pct)\n",
    "    closest = np.argmin(np.abs(y_pred_90 - target_pd))\n",
    "    sample_idx.append(closest)\n",
    "\n",
    "sample_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Loan #\": range(1, len(sample_idx) + 1),\n",
    "        \"Grade\": [test.iloc[i][\"grade\"] if \"grade\" in test.columns else \"?\" for i in sample_idx],\n",
    "        \"PD Point\": [y_pred_90[i] for i in sample_idx],\n",
    "        \"PD Low (90%)\": [y_int_90[i, 0] for i in sample_idx],\n",
    "        \"PD High (90%)\": [y_int_90[i, 1] for i in sample_idx],\n",
    "        \"Width\": [y_int_90[i, 1] - y_int_90[i, 0] for i in sample_idx],\n",
    "        \"Actual\": [y_test.values[i] for i in sample_idx],\n",
    "        \"Covered\": [\n",
    "            \"YES\"\n",
    "            if y_test.values[i] >= y_int_90[i, 0] and y_test.values[i] <= y_int_90[i, 1]\n",
    "            else \"NO\"\n",
    "            for i in sample_idx\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"SAMPLE LOAN PREDICTIONS WITH 90% CONFORMAL INTERVALS\")\n",
    "print(\"=\" * 85)\n",
    "print(sample_df.to_string(index=False, float_format=\"{:.4f}\".format))\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "y_pos = range(len(sample_idx))\n",
    "for i, idx in enumerate(sample_idx):\n",
    "    color = \"#e74c3c\" if y_test.values[idx] == 1 else \"#2ecc71\"\n",
    "    ax.barh(\n",
    "        i,\n",
    "        y_int_90[idx, 1] - y_int_90[idx, 0],\n",
    "        left=y_int_90[idx, 0],\n",
    "        height=0.5,\n",
    "        alpha=0.4,\n",
    "        color=\"#3498db\",\n",
    "    )\n",
    "    ax.plot(y_pred_90[idx], i, \"D\", color=\"#e74c3c\", markersize=10, zorder=5)\n",
    "    ax.plot(y_test.values[idx], i, \"X\", color=color, markersize=12, zorder=6)\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels([f\"Loan {i + 1} (Grade {sample_df.iloc[i]['Grade']})\" for i in y_pos])\n",
    "ax.set_xlabel(\"PD\")\n",
    "ax.set_title(\n",
    "    \"Sample Loans: PD Point (◆) vs Actual (×) with 90% Intervals\", fontweight=\"bold\", fontsize=13\n",
    ")\n",
    "ax.legend([\"90% Interval\", \"PD Point\", \"Actual Outcome\"], loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Implications for Portfolio Optimization\n",
    "\n",
    "The conformal intervals provide the uncertainty sets for robust optimization (NB08):\n",
    "- **PD_point**: Expected default probability → standard portfolio optimization\n",
    "- **PD_high**: Upper bound → worst-case robust optimization\n",
    "- **PD_low**: Lower bound → best-case scenario\n",
    "\n",
    "The **Predict-then-Optimize** pipeline:\n",
    "```\n",
    "CatBoost PD → Conformal [PD_low, PD_high] → Box Uncertainty Set → Pyomo Robust LP → Optimal Allocation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize how intervals affect portfolio decisions\n",
    "y_pred_final = results[0.10][\"y_pred\"]\n",
    "y_int_final = results[0.10][\"y_intervals\"]\n",
    "\n",
    "# ECL-style analysis: PD × LGD × EAD (simplified with LGD=0.45, EAD=loan_amnt)\n",
    "lgd_assumed = 0.45\n",
    "ead_col = \"loan_amnt\"\n",
    "if ead_col in test.columns:\n",
    "    ead = test[ead_col].values\n",
    "else:\n",
    "    ead = np.ones(len(test)) * 15000  # default\n",
    "\n",
    "ecl_point = y_pred_final * lgd_assumed * ead\n",
    "ecl_worst = y_int_final[:, 1] * lgd_assumed * ead\n",
    "ecl_best = y_int_final[:, 0] * lgd_assumed * ead\n",
    "\n",
    "portfolio_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"Scenario\": [\"Best Case (PD_low)\", \"Expected (PD_point)\", \"Worst Case (PD_high)\"],\n",
    "        \"Avg PD\": [y_int_final[:, 0].mean(), y_pred_final.mean(), y_int_final[:, 1].mean()],\n",
    "        \"Total ECL\": [ecl_best.sum(), ecl_point.sum(), ecl_worst.sum()],\n",
    "        \"ECL per Loan\": [ecl_best.mean(), ecl_point.mean(), ecl_worst.mean()],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PORTFOLIO OPTIMIZATION INPUTS — ECL Scenario Analysis\")\n",
    "print(\"=\" * 70)\n",
    "print(portfolio_summary.to_string(index=False, float_format=\"{:,.2f}\".format))\n",
    "print(f\"\\nTotal portfolio size: {len(test):,} loans\")\n",
    "print(f\"ECL uncertainty range: ${ecl_best.sum():,.0f} — ${ecl_worst.sum():,.0f}\")\n",
    "print(f\"ECL point estimate:    ${ecl_point.sum():,.0f}\")\n",
    "print(\n",
    "    f\"Worst-case premium:    ${ecl_worst.sum() - ecl_point.sum():,.0f} \"\n",
    "    f\"(+{(ecl_worst.sum() / ecl_point.sum() - 1) * 100:.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save conformal prediction results for downstream notebooks\n",
    "conformal_output = {\n",
    "    \"y_pred\": results[0.10][\"y_pred\"],\n",
    "    \"y_intervals_90\": results[0.10][\"y_intervals\"],  # shape (n, 2)\n",
    "    \"y_intervals_95\": results[0.05][\"y_intervals\"],\n",
    "    \"metrics_90\": results[0.10][\"metrics\"],\n",
    "    \"metrics_95\": results[0.05][\"metrics\"],\n",
    "    \"mondrian_results\": mondrian_results if mondrian_results else None,\n",
    "    \"sensitivity\": sens_df.to_dict(\"records\"),\n",
    "}\n",
    "with open(MODEL_DIR / \"conformal_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(conformal_output, f)\n",
    "print(f\"Conformal results saved to {MODEL_DIR / 'conformal_results.pkl'}\")\n",
    "\n",
    "# Save intervals as parquet for easy access\n",
    "intervals_df = pd.DataFrame(\n",
    "    {\n",
    "        \"y_true\": y_test.values,\n",
    "        \"y_pred\": results[0.10][\"y_pred\"],\n",
    "        \"pd_low_90\": results[0.10][\"y_intervals\"][:, 0],\n",
    "        \"pd_high_90\": results[0.10][\"y_intervals\"][:, 1],\n",
    "        \"pd_low_95\": results[0.05][\"y_intervals\"][:, 0],\n",
    "        \"pd_high_95\": results[0.05][\"y_intervals\"][:, 1],\n",
    "        \"width_90\": results[0.10][\"y_intervals\"][:, 1] - results[0.10][\"y_intervals\"][:, 0],\n",
    "        \"width_95\": results[0.05][\"y_intervals\"][:, 1] - results[0.05][\"y_intervals\"][:, 0],\n",
    "    }\n",
    ")\n",
    "if \"grade\" in test.columns:\n",
    "    intervals_df[\"grade\"] = test[\"grade\"].values\n",
    "if \"loan_amnt\" in test.columns:\n",
    "    intervals_df[\"loan_amnt\"] = test[\"loan_amnt\"].values\n",
    "\n",
    "intervals_df.to_parquet(DATA_DIR / \"conformal_intervals_mondrian.parquet\", index=False)\n",
    "print(\n",
    "    f\"Intervals saved to {DATA_DIR / 'conformal_intervals_mondrian.parquet'} ({len(intervals_df):,} rows)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Coverage Results\n",
    "\n",
    "| Level | Target | Empirical | Avg Width | Median Width |\n",
    "|-------|--------|-----------|-----------|-------------|\n",
    "| 90% (α=0.10) | 0.90 | ~ | ~ | ~ |\n",
    "| 95% (α=0.05) | 0.95 | ~ | ~ | ~ |\n",
    "\n",
    "*(Values filled in by execution)*\n",
    "\n",
    "### Key Findings\n",
    "- **Split conformal** provides valid coverage matching theoretical guarantees\n",
    "- **Interval width** reflects inherent uncertainty in binary default prediction\n",
    "- **Mondrian conformal** ensures coverage within each grade subgroup\n",
    "- **Classification sets**: Singleton rate measures model confidence\n",
    "- **PD_high** (upper interval bound) is the key input for robust portfolio optimization\n",
    "- **ECL uncertainty range** quantifies the financial impact of PD uncertainty\n",
    "\n",
    "### Methodology\n",
    "- **MAPIE 1.3**: `SplitConformalRegressor` with `ProbabilityRegressor` wrapper\n",
    "- **Calibration set**: ~238K loans held out from training (last 15% of pre-2018 data)\n",
    "- **No distributional assumptions**: Conformal prediction is distribution-free\n",
    "- **Exchangeability**: Satisfied by the i.i.d. calibration split\n",
    "\n",
    "### Artifacts Saved\n",
    "- `models/conformal_results.pkl` — Full results (intervals, metrics, Mondrian, sensitivity)\n",
    "- `data/processed/conformal_intervals_mondrian.parquet` — Per-loan intervals for NB08\n",
    "\n",
    "### Next Steps\n",
    "1. **Notebook 08**: Portfolio Optimization using [PD_low, PD_high] as box uncertainty sets\n",
    "2. **Notebook 09**: End-to-end pipeline integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Final Conclusions: Conformal Prediction\n",
    "\n",
    "### Key Findings\n",
    "- Marginal coverage targets are achieved, validating finite-sample reliability guarantees.\n",
    "- Baseline global intervals can become too wide, reducing practical decision utility.\n",
    "- Group-conditional (Mondrian-style) calibration improves segment behavior and can reduce width in key bands.\n",
    "\n",
    "### Financial Risk Interpretation\n",
    "- Coverage guarantees protect against underestimating tail risk, but interval efficiency determines business usability.\n",
    "- Very wide intervals inflate conservative ECL and can collapse robust capital allocation.\n",
    "- Conditional diagnostics by segment are mandatory to avoid hidden concentration of uncertainty risk.\n",
    "\n",
    "### Contribution to End-to-End Pipeline\n",
    "- Converts point PDs into uncertainty sets used directly by IFRS9 range analysis and robust optimization.\n",
    "- Enables explicit risk-buffer quantification (`PD_low`, `PD_high`) for scenario-aware decisions.\n",
    "- Provides the bridge from predictive modeling to decision optimization under uncertainty."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lending-club-risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
