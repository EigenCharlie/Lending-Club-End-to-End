{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Notebook 06: Survival Analysis — Time-to-Default Modeling\n",
    "\n",
    "**Objective**: Model time-to-default using survival analysis techniques (Cox PH, Random Survival Forest).\n",
    "Generate **lifetime PD curves** for IFRS 9 Stage 2/3 provisioning.\n",
    "\n",
    "**Methods**:\n",
    "1. **Kaplan-Meier** — Non-parametric survival curves by grade\n",
    "2. **Cox Proportional Hazards** — Semi-parametric: hazard ratios, assumption checks\n",
    "3. **Random Survival Forest** — Non-parametric, handles non-linear relationships\n",
    "4. **Lifetime PD curves** — Cumulative default probability over time (for IFRS 9)\n",
    "\n",
    "**Data**: `loan_master.parquet` (1.35M loans, OOT train only) + raw CSV for `last_pymnt_d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Project imports\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Survival libraries\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter, NelsonAalenFitter\n",
    "from lifelines.statistics import logrank_test, multivariate_logrank_test\n",
    "from loguru import logger\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
    "from src.models.survival import make_survival_target\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "RAW_DIR = Path(\"../data/raw\")\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Plot style\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=1.1)\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "logger.info(\"NB06 Survival Analysis initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data Loading & Survival Time Construction\n",
    "\n",
    "Survival analysis requires:\n",
    "- **Duration (T)**: Time from loan issuance to event/censoring (months)\n",
    "- **Event (E)**: 1 if default observed, 0 if censored (fully paid or still active)\n",
    "\n",
    "We extract `last_pymnt_d` from the raw CSV (removed during ETL as leakage) to compute exact duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load loan_master (training set only — before 2018-01-01)\n",
    "df_lm = pd.read_parquet(DATA_DIR / \"loan_master.parquet\")\n",
    "logger.info(f\"loan_master: {df_lm.shape}\")\n",
    "\n",
    "# Read raw CSV for last_pymnt_d (needed for survival time)\n",
    "logger.info(\"Reading raw CSV for last_pymnt_d...\")\n",
    "df_raw = pd.read_csv(\n",
    "    RAW_DIR / \"Loan_status_2007-2020Q3.csv\",\n",
    "    usecols=[\"id\", \"last_pymnt_d\"],\n",
    "    low_memory=False,\n",
    ")\n",
    "df_raw[\"id\"] = df_raw[\"id\"].astype(str)\n",
    "df_raw[\"last_pymnt_d\"] = pd.to_datetime(df_raw[\"last_pymnt_d\"], format=\"%b-%Y\")\n",
    "\n",
    "# Merge\n",
    "df_lm[\"id\"] = df_lm[\"id\"].astype(str)\n",
    "df = df_lm.merge(df_raw, on=\"id\", how=\"left\")\n",
    "\n",
    "# Compute time_to_event (months from issue_d to last_pymnt_d)\n",
    "df[\"time_to_event\"] = ((df[\"last_pymnt_d\"] - df[\"issue_d\"]).dt.days / 30.44).round(0)\n",
    "\n",
    "# Handle missing last_pymnt_d: use term as censoring time\n",
    "mask_no_pymnt = df[\"last_pymnt_d\"].isna()\n",
    "df.loc[mask_no_pymnt, \"time_to_event\"] = df.loc[mask_no_pymnt, \"term\"]\n",
    "df[\"time_to_event\"] = df[\"time_to_event\"].clip(lower=1)\n",
    "\n",
    "# Event indicator\n",
    "df[\"event_observed\"] = df[\"default_flag\"].astype(bool)\n",
    "\n",
    "# Summary\n",
    "print(f\"Survival dataset: {df.shape[0]:,} loans\")\n",
    "print(f\"  Events (defaults): {df['event_observed'].sum():,} ({df['event_observed'].mean():.1%})\")\n",
    "print(f\"  Censored: {(~df['event_observed']).sum():,}\")\n",
    "print(f\"  Time range: {df['time_to_event'].min():.0f} - {df['time_to_event'].max():.0f} months\")\n",
    "print(\n",
    "    f\"  Median time (defaults): {df.loc[df['event_observed'], 'time_to_event'].median():.0f} months\"\n",
    ")\n",
    "print(\n",
    "    f\"  Median time (censored): {df.loc[~df['event_observed'], 'time_to_event'].median():.0f} months\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Exploratory Survival Analysis\n",
    "\n",
    "Visualize the distribution of time-to-event across different risk segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Duration distribution by event\n",
    "for evt, label, color in [(True, \"Default\", \"red\"), (False, \"Censored\", \"steelblue\")]:\n",
    "    axes[0].hist(\n",
    "        df.loc[df[\"event_observed\"] == evt, \"time_to_event\"],\n",
    "        bins=50,\n",
    "        alpha=0.6,\n",
    "        label=label,\n",
    "        color=color,\n",
    "        density=True,\n",
    "    )\n",
    "axes[0].set_xlabel(\"Time to Event (months)\")\n",
    "axes[0].set_ylabel(\"Density\")\n",
    "axes[0].set_title(\"Duration Distribution by Event Type\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Default rate by time bucket\n",
    "df[\"time_bucket\"] = pd.cut(\n",
    "    df[\"time_to_event\"],\n",
    "    bins=[0, 6, 12, 18, 24, 36, 48, 60, 100],\n",
    "    labels=[\"0-6\", \"6-12\", \"12-18\", \"18-24\", \"24-36\", \"36-48\", \"48-60\", \"60+\"],\n",
    ")\n",
    "default_by_time = df.groupby(\"time_bucket\", observed=True)[\"default_flag\"].mean()\n",
    "default_by_time.plot(kind=\"bar\", ax=axes[1], color=\"coral\", edgecolor=\"black\")\n",
    "axes[1].set_xlabel(\"Time Bucket (months)\")\n",
    "axes[1].set_ylabel(\"Default Rate\")\n",
    "axes[1].set_title(\"Default Rate by Duration Bucket\")\n",
    "axes[1].yaxis.set_major_formatter(mticker.PercentFormatter(1.0))\n",
    "\n",
    "# Median duration by grade\n",
    "grade_median = df.groupby(\"grade\")[\"time_to_event\"].median().sort_index()\n",
    "grade_median.plot(kind=\"bar\", ax=axes[2], color=\"teal\", edgecolor=\"black\")\n",
    "axes[2].set_xlabel(\"Grade\")\n",
    "axes[2].set_ylabel(\"Median Duration (months)\")\n",
    "axes[2].set_title(\"Median Time-to-Event by Grade\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Kaplan-Meier Survival Curves\n",
    "\n",
    "Non-parametric estimation of the survival function $S(t) = P(T > t)$.\n",
    "We estimate overall portfolio survival and stratify by credit grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Overall KM curve\n",
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(df[\"time_to_event\"], event_observed=df[\"event_observed\"], label=\"Portfolio\")\n",
    "kmf.plot_survival_function(ax=axes[0], ci_show=True, color=\"black\", linewidth=2)\n",
    "axes[0].set_xlabel(\"Time (months)\")\n",
    "axes[0].set_ylabel(\"Survival Probability S(t)\")\n",
    "axes[0].set_title(\"Kaplan-Meier Survival Curve — Full Portfolio\")\n",
    "axes[0].axhline(y=0.5, linestyle=\"--\", color=\"gray\", alpha=0.5)\n",
    "\n",
    "# Median survival time\n",
    "median_surv = kmf.median_survival_time_\n",
    "print(f\"Portfolio median survival time: {median_surv:.1f} months\")\n",
    "print(f\"12-month survival: {kmf.predict(12):.4f}\")\n",
    "print(f\"24-month survival: {kmf.predict(24):.4f}\")\n",
    "print(f\"36-month survival: {kmf.predict(36):.4f}\")\n",
    "\n",
    "# KM by grade\n",
    "colors = {\n",
    "    \"A\": \"#1a9850\",\n",
    "    \"B\": \"#91cf60\",\n",
    "    \"C\": \"#d9ef8b\",\n",
    "    \"D\": \"#fee08b\",\n",
    "    \"E\": \"#fc8d59\",\n",
    "    \"F\": \"#d73027\",\n",
    "    \"G\": \"#a50026\",\n",
    "}\n",
    "for grade in sorted(df[\"grade\"].unique()):\n",
    "    mask = df[\"grade\"] == grade\n",
    "    kmf_g = KaplanMeierFitter()\n",
    "    kmf_g.fit(\n",
    "        df.loc[mask, \"time_to_event\"], event_observed=df.loc[mask, \"event_observed\"], label=grade\n",
    "    )\n",
    "    kmf_g.plot_survival_function(\n",
    "        ax=axes[1], ci_show=False, color=colors.get(grade, \"gray\"), linewidth=1.5\n",
    "    )\n",
    "\n",
    "axes[1].set_xlabel(\"Time (months)\")\n",
    "axes[1].set_ylabel(\"Survival Probability S(t)\")\n",
    "axes[1].set_title(\"KM Survival Curves by Grade\")\n",
    "axes[1].legend(title=\"Grade\", loc=\"lower left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate log-rank test: are survival curves different by grade?\n",
    "result = multivariate_logrank_test(df[\"time_to_event\"], df[\"grade\"], df[\"event_observed\"])\n",
    "print(\"Multivariate Log-Rank Test (Grade stratification):\")\n",
    "print(f\"  Test statistic: {result.test_statistic:.2f}\")\n",
    "print(f\"  p-value: {result.p_value:.2e}\")\n",
    "print(f\"  Degrees of freedom: {result.degrees_of_freedom}\")\n",
    "if result.p_value < 0.001:\n",
    "    print(\"  => Highly significant: survival curves differ by grade\")\n",
    "\n",
    "# Pairwise: A vs G (most extreme)\n",
    "mask_a = df[\"grade\"] == \"A\"\n",
    "mask_g = df[\"grade\"] == \"G\"\n",
    "lr_ag = logrank_test(\n",
    "    df.loc[mask_a, \"time_to_event\"],\n",
    "    df.loc[mask_g, \"time_to_event\"],\n",
    "    df.loc[mask_a, \"event_observed\"],\n",
    "    df.loc[mask_g, \"event_observed\"],\n",
    ")\n",
    "print(f\"\\nPairwise A vs G: statistic={lr_ag.test_statistic:.2f}, p={lr_ag.p_value:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nelson-Aalen estimator: cumulative hazard H(t)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for grade in sorted(df[\"grade\"].unique()):\n",
    "    mask = df[\"grade\"] == grade\n",
    "    naf = NelsonAalenFitter()\n",
    "    naf.fit(\n",
    "        df.loc[mask, \"time_to_event\"], event_observed=df.loc[mask, \"event_observed\"], label=grade\n",
    "    )\n",
    "    naf.plot_cumulative_hazard(ax=ax, ci_show=False, color=colors.get(grade, \"gray\"), linewidth=1.5)\n",
    "\n",
    "ax.set_xlabel(\"Time (months)\")\n",
    "ax.set_ylabel(\"Cumulative Hazard H(t)\")\n",
    "ax.set_title(\"Nelson-Aalen Cumulative Hazard by Grade\")\n",
    "ax.legend(title=\"Grade\", loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Cox Proportional Hazards Model\n",
    "\n",
    "Semi-parametric model: $h(t|X) = h_0(t) \\cdot \\exp(\\beta^T X)$\n",
    "\n",
    "The Cox model estimates **hazard ratios** — how each feature multiplicatively affects the risk of default.\n",
    "Key assumptions: proportional hazards (constant hazard ratios over time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric features for Cox PH (lifelines handles NaN poorly — impute)\n",
    "cox_features = [\n",
    "    \"loan_amnt\",\n",
    "    \"annual_inc\",\n",
    "    \"int_rate\",\n",
    "    \"dti\",\n",
    "    \"installment\",\n",
    "    \"open_acc\",\n",
    "    \"pub_rec\",\n",
    "    \"revol_bal\",\n",
    "    \"revol_util\",\n",
    "    \"total_acc\",\n",
    "    \"fico_range_low\",\n",
    "    \"credit_history_months\",\n",
    "    \"loan_to_income\",\n",
    "    \"term\",\n",
    "]\n",
    "\n",
    "# Build Cox dataframe\n",
    "df_cox = df[cox_features + [\"time_to_event\", \"event_observed\"]].copy()\n",
    "\n",
    "# Impute missing values (Cox PH cannot handle NaN)\n",
    "for col in cox_features:\n",
    "    if df_cox[col].isnull().any():\n",
    "        median_val = df_cox[col].median()\n",
    "        df_cox[col].fillna(median_val, inplace=True)\n",
    "        print(f\"  Imputed {col}: {df_cox[col].isnull().sum()} -> median={median_val:.2f}\")\n",
    "\n",
    "# Standardize features for stable coefficient estimation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_cox[cox_features] = scaler.fit_transform(df_cox[cox_features])\n",
    "\n",
    "print(f\"Cox training data: {df_cox.shape}\")\n",
    "print(f\"Events: {df_cox['event_observed'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Cox PH on full data (lifelines is efficient enough)\n",
    "t0 = time.time()\n",
    "cph = CoxPHFitter(penalizer=0.01)\n",
    "cph.fit(df_cox, duration_col=\"time_to_event\", event_col=\"event_observed\")\n",
    "cox_time = time.time() - t0\n",
    "\n",
    "print(f\"Cox PH trained in {cox_time:.1f}s\")\n",
    "print(f\"Concordance Index: {cph.concordance_index_:.4f}\")\n",
    "print(f\"Partial log-likelihood: {cph.log_likelihood_:.2f}\")\n",
    "print(f\"AIC: {cph.AIC_partial_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "print(\"Cox PH Summary:\")\n",
    "print(cph.summary[[\"coef\", \"exp(coef)\", \"se(coef)\", \"z\", \"p\", \"-log2(p)\"]].round(4))\n",
    "\n",
    "# Forest plot of hazard ratios\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "cph.plot(ax=ax)\n",
    "ax.set_title(\"Cox PH — Hazard Ratios (exp(coef) with 95% CI)\")\n",
    "ax.axvline(x=0, color=\"black\", linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top risk factors\n",
    "hr = cph.summary[\"exp(coef)\"].sort_values(ascending=False)\n",
    "print(\"\\nTop 5 risk factors (HR > 1 = increases hazard):\")\n",
    "for feat, val in hr.head(5).items():\n",
    "    print(f\"  {feat}: HR = {val:.4f}\")\n",
    "print(\"\\nTop 5 protective factors (HR < 1 = decreases hazard):\")\n",
    "for feat, val in hr.tail(5).items():\n",
    "    print(f\"  {feat}: HR = {val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Cox Proportional Hazards — Assumption Check\n",
    "\n",
    "The PH assumption requires that hazard ratios are constant over time.\n",
    "Schoenfeld residuals test: $H_0$: hazards are proportional. Rejection (p < 0.05) indicates violation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check PH assumptions (Schoenfeld residual test)\n",
    "# Use a sample to avoid excessive computation\n",
    "df_cox_sample = df_cox.sample(n=min(50000, len(df_cox)), random_state=RANDOM_STATE)\n",
    "\n",
    "cph_check = CoxPHFitter(penalizer=0.01)\n",
    "cph_check.fit(df_cox_sample, duration_col=\"time_to_event\", event_col=\"event_observed\")\n",
    "\n",
    "try:\n",
    "    results = cph_check.check_assumptions(df_cox_sample, p_value_threshold=0.05, show_plots=False)\n",
    "    if isinstance(results, list) and len(results) == 0:\n",
    "        print(\"PH assumption satisfied for all covariates (p > 0.05)\")\n",
    "    else:\n",
    "        print(\"PH assumption violated for some covariates — see output above\")\n",
    "        print(\"This is common in large credit datasets where hazard ratios evolve over time.\")\n",
    "        print(\"Consider: stratified Cox model, time-varying coefficients, or RSF.\")\n",
    "except Exception as e:\n",
    "    print(f\"Assumption check note: {e}\")\n",
    "    print(\"With large datasets, some violations are expected. RSF handles this naturally.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Random Survival Forest\n",
    "\n",
    "Non-parametric ensemble: handles non-linear effects, interactions, and PH violations.\n",
    "\n",
    "**Note**: RSF is memory-intensive with scikit-survival. We train on a stratified sample\n",
    "(50K loans) with `max_depth=8` and evaluate on a held-out test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for RSF (same as Cox, but no standardization needed)\n",
    "rsf_features = [\n",
    "    \"loan_amnt\",\n",
    "    \"annual_inc\",\n",
    "    \"int_rate\",\n",
    "    \"dti\",\n",
    "    \"installment\",\n",
    "    \"open_acc\",\n",
    "    \"pub_rec\",\n",
    "    \"revol_bal\",\n",
    "    \"revol_util\",\n",
    "    \"total_acc\",\n",
    "    \"fico_range_low\",\n",
    "    \"credit_history_months\",\n",
    "    \"loan_to_income\",\n",
    "    \"term\",\n",
    "]\n",
    "\n",
    "# Build RSF dataframe (original scale, imputed)\n",
    "df_rsf = df[rsf_features + [\"time_to_event\", \"event_observed\"]].copy()\n",
    "for col in rsf_features:\n",
    "    if df_rsf[col].isnull().any():\n",
    "        df_rsf[col].fillna(df_rsf[col].median(), inplace=True)\n",
    "\n",
    "# Stratified sample for RSF (memory constraint with sksurv)\n",
    "RSF_TRAIN_SIZE = 50_000\n",
    "RSF_TEST_SIZE = 20_000\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_rsf_train, df_rsf_test = train_test_split(\n",
    "    df_rsf,\n",
    "    train_size=RSF_TRAIN_SIZE,\n",
    "    test_size=RSF_TEST_SIZE,\n",
    "    stratify=df_rsf[\"event_observed\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "X_rsf_train = df_rsf_train[rsf_features]\n",
    "X_rsf_test = df_rsf_test[rsf_features]\n",
    "\n",
    "# Create structured arrays for sksurv\n",
    "y_rsf_train = make_survival_target(\n",
    "    df_rsf_train, event_col=\"event_observed\", time_col=\"time_to_event\"\n",
    ")\n",
    "y_rsf_test = make_survival_target(df_rsf_test, event_col=\"event_observed\", time_col=\"time_to_event\")\n",
    "\n",
    "print(f\"RSF train: {X_rsf_train.shape}, events={df_rsf_train['event_observed'].sum():,}\")\n",
    "print(f\"RSF test:  {X_rsf_test.shape}, events={df_rsf_test['event_observed'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Survival Forest\n",
    "rsf = RandomSurvivalForest(\n",
    "    n_estimators=100,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=15,\n",
    "    max_features=\"sqrt\",\n",
    "    max_depth=8,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "t0 = time.time()\n",
    "rsf.fit(X_rsf_train, y_rsf_train)\n",
    "rsf_time = time.time() - t0\n",
    "\n",
    "# Evaluate\n",
    "c_index_train = rsf.score(X_rsf_train, y_rsf_train)\n",
    "c_index_test = rsf.score(X_rsf_test, y_rsf_test)\n",
    "\n",
    "print(f\"RSF trained in {rsf_time:.1f}s\")\n",
    "print(f\"  C-index (train): {c_index_train:.4f}\")\n",
    "print(f\"  C-index (test):  {c_index_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Model Comparison: Cox PH vs Random Survival Forest\n",
    "\n",
    "Compare discriminative ability via concordance index (C-index).\n",
    "C-index ranges from 0.5 (random) to 1.0 (perfect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cox C-index on the same RSF test set\n",
    "\n",
    "# Cox predictions on RSF test set (need standardized features)\n",
    "df_rsf_test_std = df_rsf_test[rsf_features].copy()\n",
    "df_rsf_test_std[rsf_features] = scaler.transform(df_rsf_test_std[rsf_features])\n",
    "cox_risk = cph.predict_partial_hazard(df_rsf_test_std).values.ravel()\n",
    "\n",
    "# Cox C-index\n",
    "c_cox = concordance_index_censored(\n",
    "    df_rsf_test[\"event_observed\"].values.astype(bool),\n",
    "    df_rsf_test[\"time_to_event\"].values,\n",
    "    cox_risk,\n",
    ")\n",
    "cox_c_index = c_cox[0]\n",
    "\n",
    "# RSF risk scores\n",
    "rsf_risk = rsf.predict(X_rsf_test)\n",
    "\n",
    "print(\"Model Comparison (on RSF test set):\")\n",
    "print(f\"{'Model':<25} {'C-index':>10}\")\n",
    "print(\"-\" * 37)\n",
    "print(f\"{'Cox PH':<25} {cox_c_index:>10.4f}\")\n",
    "print(f\"{'Random Survival Forest':<25} {c_index_test:>10.4f}\")\n",
    "delta = c_index_test - cox_c_index\n",
    "print(f\"{'RSF improvement':<25} {delta:>+10.4f}\")\n",
    "\n",
    "# Compare table\n",
    "comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\"Cox PH\", \"Random Survival Forest\"],\n",
    "        \"C-index\": [cox_c_index, c_index_test],\n",
    "        \"Training Time (s)\": [cox_time, rsf_time],\n",
    "        \"Interpretable\": [\"Yes (hazard ratios)\", \"No (black-box)\"],\n",
    "        \"PH Required\": [\"Yes\", \"No\"],\n",
    "    }\n",
    ")\n",
    "print()\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation importance for RSF (built-in not supported in sksurv 0.26)\n",
    "print(\"Computing RSF permutation importance (may take a minute)...\")\n",
    "t0 = time.time()\n",
    "perm_imp = permutation_importance(\n",
    "    rsf,\n",
    "    X_rsf_test,\n",
    "    y_rsf_test,\n",
    "    n_repeats=5,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    scoring=None,  # uses default .score() = C-index\n",
    ")\n",
    "print(f\"  Done in {time.time() - t0:.1f}s\")\n",
    "\n",
    "# Plot\n",
    "imp_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Feature\": rsf_features,\n",
    "        \"Importance\": perm_imp.importances_mean,\n",
    "        \"Std\": perm_imp.importances_std,\n",
    "    }\n",
    ").sort_values(\"Importance\", ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.barh(\n",
    "    imp_df[\"Feature\"], imp_df[\"Importance\"], xerr=imp_df[\"Std\"], color=\"teal\", edgecolor=\"black\"\n",
    ")\n",
    "ax.set_xlabel(\"Permutation Importance (C-index decrease)\")\n",
    "ax.set_title(\"RSF Feature Importance (Permutation-based)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 5 features by RSF importance:\")\n",
    "for _, row in imp_df.tail(5).iloc[::-1].iterrows():\n",
    "    print(f\"  {row['Feature']}: {row['Importance']:.4f} +/- {row['Std']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Lifetime PD Curves\n",
    "\n",
    "Generate $PD(t) = 1 - S(t)$ curves for IFRS 9 Stage 2/3 provisioning.\n",
    "\n",
    "- **Stage 1**: Uses 12-month PD (from CatBoost in NB03)\n",
    "- **Stage 2**: Uses lifetime PD curve from survival model\n",
    "- **Stage 3**: PD = 1 (credit-impaired)\n",
    "\n",
    "We generate curves for representative loans from each grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate lifetime PD curves for representative loans per grade\n",
    "# Use Cox model (smooth, parametric-like curves)\n",
    "times_months = np.arange(1, 61)  # 1 to 60 months\n",
    "\n",
    "# Get one representative loan per grade (median features)\n",
    "representative_loans = []\n",
    "for grade in sorted(df[\"grade\"].unique()):\n",
    "    mask = df[\"grade\"] == grade\n",
    "    df_grade = df.loc[mask, rsf_features]\n",
    "    for col in rsf_features:\n",
    "        if df_grade[col].isnull().any():\n",
    "            df_grade[col] = df_grade[col].fillna(df_grade[col].median())\n",
    "    median_row = df_grade.median()\n",
    "    median_row.name = grade\n",
    "    representative_loans.append(median_row)\n",
    "\n",
    "rep_df = pd.DataFrame(representative_loans)\n",
    "rep_df.index.name = \"grade\"\n",
    "print(\"Representative loans (median features per grade):\")\n",
    "print(rep_df[[\"int_rate\", \"loan_amnt\", \"annual_inc\", \"fico_range_low\", \"dti\"]].round(2))\n",
    "\n",
    "# Cox predictions: survival function -> PD = 1 - S(t)\n",
    "rep_df_std = rep_df.copy()\n",
    "rep_df_std[rsf_features] = scaler.transform(rep_df_std[rsf_features])\n",
    "cox_surv = cph.predict_survival_function(rep_df_std)\n",
    "\n",
    "# Plot lifetime PD curves from Cox\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "for grade in sorted(df[\"grade\"].unique()):\n",
    "    grade_idx = list(rep_df.index).index(grade)\n",
    "    surv_func = cox_surv.iloc[:, grade_idx]\n",
    "    # Interpolate to monthly grid\n",
    "    pd_curve = 1 - np.interp(times_months, surv_func.index.values, surv_func.values)\n",
    "    axes[0].plot(\n",
    "        times_months, pd_curve, label=grade, color=colors.get(grade, \"gray\"), linewidth=1.5\n",
    "    )\n",
    "\n",
    "axes[0].set_xlabel(\"Time (months)\")\n",
    "axes[0].set_ylabel(\"Cumulative PD\")\n",
    "axes[0].set_title(\"Cox PH — Lifetime PD Curves by Grade\")\n",
    "axes[0].legend(title=\"Grade\", loc=\"upper left\")\n",
    "axes[0].yaxis.set_major_formatter(mticker.PercentFormatter(1.0))\n",
    "\n",
    "# Key IFRS9 time points\n",
    "for grade in sorted(df[\"grade\"].unique()):\n",
    "    grade_idx = list(rep_df.index).index(grade)\n",
    "    surv_func = cox_surv.iloc[:, grade_idx]\n",
    "    pd_12m = 1 - np.interp(12, surv_func.index.values, surv_func.values)\n",
    "    pd_lifetime = 1 - np.interp(60, surv_func.index.values, surv_func.values)\n",
    "    axes[1].bar(\n",
    "        grade,\n",
    "        pd_12m,\n",
    "        color=colors.get(grade, \"gray\"),\n",
    "        alpha=0.6,\n",
    "        label=\"12-month PD\" if grade == \"A\" else \"\",\n",
    "    )\n",
    "    axes[1].bar(\n",
    "        grade,\n",
    "        pd_lifetime - pd_12m,\n",
    "        bottom=pd_12m,\n",
    "        color=colors.get(grade, \"gray\"),\n",
    "        alpha=0.3,\n",
    "        label=\"Additional lifetime PD\" if grade == \"A\" else \"\",\n",
    "    )\n",
    "\n",
    "axes[1].set_xlabel(\"Grade\")\n",
    "axes[1].set_ylabel(\"Cumulative PD\")\n",
    "axes[1].set_title(\"12-month PD vs Lifetime PD by Grade (Cox)\")\n",
    "axes[1].legend(loc=\"upper left\")\n",
    "axes[1].yaxis.set_major_formatter(mticker.PercentFormatter(1.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IFRS 9 lifetime PD table\n",
    "ifrs9_times = [12, 24, 36, 48, 60]\n",
    "pd_table = {}\n",
    "\n",
    "for grade in sorted(df[\"grade\"].unique()):\n",
    "    grade_idx = list(rep_df.index).index(grade)\n",
    "    surv_func = cox_surv.iloc[:, grade_idx]\n",
    "    pds = {}\n",
    "    for t in ifrs9_times:\n",
    "        pd_t = 1 - np.interp(t, surv_func.index.values, surv_func.values)\n",
    "        pds[f\"PD_{t}m\"] = pd_t\n",
    "    pd_table[grade] = pds\n",
    "\n",
    "pd_table_df = pd.DataFrame(pd_table).T\n",
    "pd_table_df.index.name = \"Grade\"\n",
    "\n",
    "print(\"IFRS 9 Lifetime PD Table (Cox PH):\")\n",
    "print(pd_table_df.to_string(float_format=lambda x: f\"{x:.4f}\"))\n",
    "print()\n",
    "print(\"IFRS 9 Provisioning Multiplier (Lifetime / 12-month):\")\n",
    "for grade in pd_table_df.index:\n",
    "    pd_12 = pd_table_df.loc[grade, \"PD_12m\"]\n",
    "    pd_60 = pd_table_df.loc[grade, \"PD_60m\"]\n",
    "    if pd_12 > 0:\n",
    "        mult = pd_60 / pd_12\n",
    "        print(f\"  Grade {grade}: {mult:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lifetime PD from RSF — predict on representative loans (median per grade)\n",
    "\n",
    "# Simpler approach: predict on representative loans\n",
    "rep_rsf = rep_df[rsf_features].copy()\n",
    "for col in rsf_features:\n",
    "    if rep_rsf[col].isnull().any():\n",
    "        rep_rsf[col] = rep_rsf[col].fillna(rep_rsf[col].median())\n",
    "\n",
    "rsf_surv = rsf.predict_survival_function(rep_rsf)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for i, grade in enumerate(sorted(df[\"grade\"].unique())):\n",
    "    sf = rsf_surv[i]\n",
    "    pd_curve = 1 - sf.y\n",
    "    ax.step(\n",
    "        sf.x, pd_curve, label=grade, color=colors.get(grade, \"gray\"), linewidth=1.5, where=\"post\"\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(\"Time (months)\")\n",
    "ax.set_ylabel(\"Cumulative PD\")\n",
    "ax.set_title(\"RSF — Lifetime PD Curves by Grade\")\n",
    "ax.legend(title=\"Grade\", loc=\"upper left\")\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(1.0))\n",
    "ax.set_xlim(0, 60)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Hazard Rate Analysis\n",
    "\n",
    "Examine the **instantaneous hazard rate** (risk of default at time $t$ given survival to $t$).\n",
    "This helps identify when loans are most vulnerable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothed hazard rate from Nelson-Aalen estimator\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for grade in sorted(df[\"grade\"].unique()):\n",
    "    mask = df[\"grade\"] == grade\n",
    "    naf = NelsonAalenFitter()\n",
    "    naf.fit(df.loc[mask, \"time_to_event\"], event_observed=df.loc[mask, \"event_observed\"])\n",
    "\n",
    "    # Smoothed hazard (kernel smoothed derivative of cumulative hazard)\n",
    "    naf.plot_hazard(\n",
    "        bandwidth=3,\n",
    "        ax=ax,\n",
    "        label=grade,\n",
    "        ci_show=False,\n",
    "        color=colors.get(grade, \"gray\"),\n",
    "        linewidth=1.5,\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(\"Time (months)\")\n",
    "ax.set_ylabel(\"Hazard Rate h(t)\")\n",
    "ax.set_title(\"Smoothed Hazard Rate by Grade (Bandwidth=3)\")\n",
    "ax.legend(title=\"Grade\", loc=\"upper right\")\n",
    "ax.set_xlim(0, 60)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Peak hazard timing (approximate, from smoothed curves):\")\n",
    "print(\"  Lower grades (E-G) peak earlier (months 6-12)\")\n",
    "print(\"  Higher grades (A-B) have flatter, lower hazard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. IFRS 9 Integration: Survival-Based Staging\n",
    "\n",
    "Connect survival analysis outputs to IFRS 9 staging:\n",
    "- **Stage 1**: 12-month PD from CatBoost → ECL = PD_12m x LGD x EAD\n",
    "- **Stage 2**: Lifetime PD from survival model → ECL = PD_lifetime x LGD x EAD\n",
    "- **Stage 3**: PD = 1.0, full provisioning\n",
    "\n",
    "Use the **marginal PD** (period-by-period default probability) for more granular provisioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute marginal PDs: P(default in month t | survived to month t-1)\n",
    "# marginal_PD(t) = S(t-1) - S(t) / S(t-1) = 1 - S(t)/S(t-1)\n",
    "\n",
    "\n",
    "def compute_marginal_pd(surv_func_values, times):\n",
    "    \"\"\"Compute period-by-period marginal PDs from survival function.\"\"\"\n",
    "    marginal = np.zeros(len(times))\n",
    "    for i in range(len(times)):\n",
    "        if i == 0:\n",
    "            marginal[i] = 1 - surv_func_values[i]\n",
    "        else:\n",
    "            if surv_func_values[i - 1] > 0:\n",
    "                marginal[i] = 1 - surv_func_values[i] / surv_func_values[i - 1]\n",
    "            else:\n",
    "                marginal[i] = 0\n",
    "    return marginal\n",
    "\n",
    "\n",
    "# Compute for each grade using Cox model\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "marginal_pds = {}\n",
    "for grade in sorted(df[\"grade\"].unique()):\n",
    "    grade_idx = list(rep_df.index).index(grade)\n",
    "    surv_func = cox_surv.iloc[:, grade_idx]\n",
    "    surv_vals = np.interp(times_months, surv_func.index.values, surv_func.values)\n",
    "    mpd = compute_marginal_pd(surv_vals, times_months)\n",
    "    marginal_pds[grade] = mpd\n",
    "    axes[0].plot(times_months, mpd, label=grade, color=colors.get(grade, \"gray\"), linewidth=1.5)\n",
    "\n",
    "axes[0].set_xlabel(\"Month\")\n",
    "axes[0].set_ylabel(\"Marginal PD\")\n",
    "axes[0].set_title(\"Monthly Marginal PD by Grade (Cox PH)\")\n",
    "axes[0].legend(title=\"Grade\", loc=\"upper right\")\n",
    "axes[0].yaxis.set_major_formatter(mticker.PercentFormatter(1.0))\n",
    "\n",
    "# ECL term structure: sum of discounted marginal PDs\n",
    "discount_rate = 0.05 / 12  # 5% annual\n",
    "ecl_structure = {}\n",
    "for grade in sorted(df[\"grade\"].unique()):\n",
    "    mpd = marginal_pds[grade]\n",
    "    ecl_monthly = mpd * np.exp(-discount_rate * times_months)\n",
    "    ecl_cumulative = np.cumsum(ecl_monthly)\n",
    "    ecl_structure[grade] = ecl_cumulative\n",
    "    axes[1].plot(\n",
    "        times_months, ecl_cumulative, label=grade, color=colors.get(grade, \"gray\"), linewidth=1.5\n",
    "    )\n",
    "\n",
    "axes[1].set_xlabel(\"Month\")\n",
    "axes[1].set_ylabel(\"Cumulative Discounted PD\")\n",
    "axes[1].set_title(\"ECL Term Structure by Grade (5% discount)\")\n",
    "axes[1].legend(title=\"Grade\", loc=\"upper left\")\n",
    "axes[1].axvline(x=12, color=\"black\", linestyle=\"--\", alpha=0.5, label=\"12-month (Stage 1)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IFRS 9 ECL comparison: Stage 1 (12m) vs Stage 2 (lifetime)\n",
    "# Assume LGD = 0.45, EAD = loan_amnt (simplified)\n",
    "LGD = 0.45\n",
    "ecl_comparison = []\n",
    "\n",
    "for grade in sorted(df[\"grade\"].unique()):\n",
    "    grade_idx = list(rep_df.index).index(grade)\n",
    "    surv_func = cox_surv.iloc[:, grade_idx]\n",
    "\n",
    "    pd_12m = 1 - np.interp(12, surv_func.index.values, surv_func.values)\n",
    "    pd_lifetime = 1 - np.interp(60, surv_func.index.values, surv_func.values)\n",
    "    avg_loan = df.loc[df[\"grade\"] == grade, \"loan_amnt\"].mean()\n",
    "\n",
    "    ecl_stage1 = pd_12m * LGD * avg_loan\n",
    "    ecl_stage2 = pd_lifetime * LGD * avg_loan\n",
    "\n",
    "    ecl_comparison.append(\n",
    "        {\n",
    "            \"Grade\": grade,\n",
    "            \"Avg Loan\": avg_loan,\n",
    "            \"PD_12m\": pd_12m,\n",
    "            \"PD_lifetime\": pd_lifetime,\n",
    "            \"ECL_Stage1\": ecl_stage1,\n",
    "            \"ECL_Stage2\": ecl_stage2,\n",
    "            \"Stage2/Stage1\": ecl_stage2 / ecl_stage1 if ecl_stage1 > 0 else np.nan,\n",
    "        }\n",
    "    )\n",
    "\n",
    "ecl_df = pd.DataFrame(ecl_comparison)\n",
    "print(\"IFRS 9 ECL Comparison (LGD=0.45):\")\n",
    "print(\n",
    "    ecl_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\" if abs(x) < 10 else f\"{x:,.0f}\")\n",
    ")\n",
    "print()\n",
    "print(\"Key insight: Stage 2 ECL is significantly higher than Stage 1, especially for lower grades.\")\n",
    "print(f\"Average Stage2/Stage1 multiplier: {ecl_df['Stage2/Stage1'].mean():.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Summary & Save Artifacts\n",
    "\n",
    "### Key Findings\n",
    "1. **Kaplan-Meier**: Clear separation of survival curves by grade. Log-rank test confirms statistical significance.\n",
    "2. **Cox PH**: Identifies key hazard drivers (interest rate, FICO, income). C-index on par with simple models.\n",
    "3. **Random Survival Forest**: Better discrimination (C-index), handles non-linear effects, but less interpretable.\n",
    "4. **Lifetime PD curves**: Enable IFRS 9 Stage 2 provisioning with survival-based ECL.\n",
    "5. **IFRS 9 multiplier**: Stage 2 ECL is 2-4x higher than Stage 1 for lower grades.\n",
    "\n",
    "### Connection to Other Notebooks\n",
    "- **NB03 (PD)**: Point-in-time PD from CatBoost → Stage 1 ECL\n",
    "- **NB04 (Conformal)**: PD intervals → uncertainty-aware SICR detection\n",
    "- **NB06 (This)**: Lifetime PD from survival models → Stage 2/3 ECL\n",
    "- **NB08 (Optimization)**: Combine all for robust portfolio optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save Cox model\n",
    "with open(MODEL_DIR / \"cox_ph_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cph, f)\n",
    "logger.info(f\"Saved Cox PH model to {MODEL_DIR / 'cox_ph_model.pkl'}\")\n",
    "\n",
    "# Save lifetime PD table\n",
    "pd_table_df.to_parquet(DATA_DIR / \"lifetime_pd_table.parquet\")\n",
    "logger.info(f\"Saved lifetime PD table to {DATA_DIR / 'lifetime_pd_table.parquet'}\")\n",
    "\n",
    "# Save IFRS 9 ECL comparison\n",
    "ecl_df.to_parquet(DATA_DIR / \"ifrs9_ecl_comparison.parquet\")\n",
    "\n",
    "# Save survival data summary\n",
    "surv_summary = {\n",
    "    \"cox_concordance_index\": cph.concordance_index_,\n",
    "    \"rsf_c_index_test\": c_index_test,\n",
    "    \"cox_training_time\": cox_time,\n",
    "    \"rsf_training_time\": rsf_time,\n",
    "    \"n_loans\": len(df),\n",
    "    \"n_events\": int(df[\"event_observed\"].sum()),\n",
    "    \"event_rate\": float(df[\"event_observed\"].mean()),\n",
    "    \"median_time_default\": float(df.loc[df[\"event_observed\"], \"time_to_event\"].median()),\n",
    "    \"median_time_censored\": float(df.loc[~df[\"event_observed\"], \"time_to_event\"].median()),\n",
    "    \"rsf_sample_size\": RSF_TRAIN_SIZE,\n",
    "    \"cox_features\": cox_features,\n",
    "}\n",
    "with open(MODEL_DIR / \"survival_summary.pkl\", \"wb\") as f:\n",
    "    pickle.dump(surv_summary, f)\n",
    "\n",
    "print(\"Artifacts saved:\")\n",
    "print(f\"  Cox PH model: {MODEL_DIR / 'cox_ph_model.pkl'}\")\n",
    "print(f\"  Lifetime PD table: {DATA_DIR / 'lifetime_pd_table.parquet'}\")\n",
    "print(f\"  IFRS 9 ECL comparison: {DATA_DIR / 'ifrs9_ecl_comparison.parquet'}\")\n",
    "print(f\"  Survival summary: {MODEL_DIR / 'survival_summary.pkl'}\")\n",
    "print(\"\\nNB06 Survival Analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Final Conclusions: Survival Analysis\n",
    "\n",
    "### Key Findings\n",
    "- Time-to-event models capture default timing heterogeneity beyond binary default labels.\n",
    "- Cox and RSF provide complementary perspectives on hazard structure.\n",
    "- Assumption diagnostics are critical, especially proportional-hazards checks.\n",
    "\n",
    "### Financial Risk Interpretation\n",
    "- Timing of default materially affects discounted loss, recovery strategy, and provisioning horizon.\n",
    "- Lifetime risk curves improve Stage 2/Stage 3 understanding versus static 12-month PD alone.\n",
    "- Hazard decomposition helps identify segments where deterioration accelerates earlier.\n",
    "\n",
    "### Contribution to End-to-End Pipeline\n",
    "- Extends risk quantification from \"if default\" to \"when default\".\n",
    "- Supports lifetime PD interpretation for IFRS9-aligned analysis.\n",
    "- Complements PD/conformal outputs with horizon-sensitive credit risk structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lending-club-risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
