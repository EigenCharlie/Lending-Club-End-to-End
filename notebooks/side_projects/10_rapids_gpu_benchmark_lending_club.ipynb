{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Notebook 10 — RAPIDS 26.02 GPU Benchmark (Side Task)\n",
    "\n",
    "**Objective**: Measure practical GPU acceleration across 5 RAPIDS libraries on\n",
    "Lending Club data (1.3M loans, 2007–2020).\n",
    "\n",
    "**Scope boundary**:\n",
    "- This notebook is **independent** from the canonical project pipeline.\n",
    "- It does not modify core project artifacts or acceptance gates.\n",
    "- Artifacts are exported to `reports/gpu_benchmark/` for the Streamlit annex page.\n",
    "\n",
    "**Libraries benchmarked**:\n",
    "| Library | CPU Baseline | GPU Path |\n",
    "|---------|-------------|----------|\n",
    "| cuDF | pandas, Polars, DuckDB | cudf.pandas, Polars GPUEngine |\n",
    "| cuML | scikit-learn | cuML (+ cuml.accel dispatch) |\n",
    "| cuGraph | NetworkX | cugraph, nx-cugraph backend |\n",
    "| cuOpt | SciPy HiGHS | cuOpt LP/MILP solver |\n",
    "| CuPy | NumPy/SciPy | CuPy GPU arrays |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Official references (RAPIDS 26.02)\n",
    "\n",
    "- RAPIDS install + platform support: https://docs.rapids.ai/install\n",
    "- cuDF pandas accelerator: https://docs.rapids.ai/api/cudf/stable/cudf_pandas/\n",
    "- cuDF + Polars GPU engine: https://docs.rapids.ai/api/cudf/stable/cudf_polars/usage/\n",
    "- cuML API: https://docs.rapids.ai/api/cuml/stable/api/\n",
    "- cuML scikit-learn accelerator: https://docs.rapids.ai/api/cuml/stable/cuml_accel/\n",
    "- cuGraph API: https://docs.rapids.ai/api/cugraph/stable/api_docs/\n",
    "- nx-cugraph backend: https://docs.rapids.ai/api/cugraph/stable/nx_cugraph/\n",
    "- cuOpt LP/MILP: https://docs.nvidia.com/cuopt/user-guide/latest/cuopt-python/lp-milp-examples.html\n",
    "- RMM CuPy allocator: https://docs.rapids.ai/api/rmm/stable/python_api/\n",
    "- CuPy docs: https://docs.cupy.dev/en/stable/\n",
    "- Narwhals (write-once DataFrames): https://narwhals-dev.github.io/narwhals/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import importlib.util\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "import textwrap\n",
    "import time\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def find_root(start: Path | None = None) -> Path:\n",
    "    cur = (start or Path.cwd()).resolve()\n",
    "    for p in [cur] + list(cur.parents):\n",
    "        if (p / \"data\").exists() and (p / \"notebooks\").exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\"No project root found\")\n",
    "\n",
    "\n",
    "ROOT = find_root()\n",
    "DATA = ROOT / \"data\" / \"processed\"\n",
    "OUT = ROOT / \"reports\" / \"gpu_benchmark\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "TMP = OUT / \"tmp_scripts\"\n",
    "TMP.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN = DATA / \"train.parquet\"\n",
    "TEST = DATA / \"test.parquet\"\n",
    "TRAIN_FE = DATA / \"train_fe.parquet\"\n",
    "TEST_FE = DATA / \"test_fe.parquet\"\n",
    "\n",
    "CONFIG: dict[str, Any] = {\n",
    "    \"seed\": 42,\n",
    "    \"save_outputs\": True,\n",
    "    \"cudf_repeats\": 4,\n",
    "    \"cudf_warmup\": 1,\n",
    "    \"cuml_train_sample\": 250_000,\n",
    "    \"cuml_test_sample\": 100_000,\n",
    "    \"cuml_repeats_light\": 2,\n",
    "    \"cuml_repeats_heavy\": 1,\n",
    "    \"cugraph_sample_rows\": 50_000,\n",
    "    \"cugraph_repeats\": 3,\n",
    "    \"cuopt_sample_rows\": 18_000,\n",
    "    \"cuopt_repeats\": 3,\n",
    "    \"cupy_repeats\": 3,\n",
    "    \"cupy_warmup\": 1,\n",
    "    \"consistency_rel_tol\": 5e-3,\n",
    "    \"plot_per_method_charts\": True,\n",
    "}\n",
    "\n",
    "\n",
    "def stats_from(values: list[float]) -> dict[str, float]:\n",
    "    arr = np.asarray(values, dtype=np.float64)\n",
    "    if arr.size == 0:\n",
    "        return {\n",
    "            \"median_seconds\": np.nan,\n",
    "            \"mean_seconds\": np.nan,\n",
    "            \"std_seconds\": np.nan,\n",
    "            \"iqr_seconds\": np.nan,\n",
    "        }\n",
    "    q1, q3 = np.percentile(arr, [25, 75])\n",
    "    return {\n",
    "        \"median_seconds\": float(np.median(arr)),\n",
    "        \"mean_seconds\": float(np.mean(arr)),\n",
    "        \"std_seconds\": float(np.std(arr)),\n",
    "        \"iqr_seconds\": float(q3 - q1),\n",
    "    }\n",
    "\n",
    "\n",
    "def rel_err(a: float, b: float) -> float:\n",
    "    den = max(abs(a), 1e-12)\n",
    "    return float(abs(a - b) / den)\n",
    "\n",
    "\n",
    "def classify_relevance(speedup_x: float, seconds_saved: float, quality_pass: bool) -> str:\n",
    "    if not quality_pass:\n",
    "        return \"No concluyente (quality check fail)\"\n",
    "    if not np.isfinite(speedup_x):\n",
    "        return \"No disponible\"\n",
    "    if speedup_x >= 3.0 and seconds_saved >= 0.05:\n",
    "        return \"Alta relevancia\"\n",
    "    if speedup_x >= 1.5 and seconds_saved >= 0.01:\n",
    "        return \"Relevancia moderada\"\n",
    "    if speedup_x >= 1.1:\n",
    "        return \"Relevancia baja\"\n",
    "    if speedup_x >= 0.9:\n",
    "        return \"Neutro\"\n",
    "    return \"No relevante (CPU mejor)\"\n",
    "\n",
    "\n",
    "def save_artifact(df: pd.DataFrame, name: str, fmt: str = \"parquet\") -> None:\n",
    "    if not CONFIG[\"save_outputs\"]:\n",
    "        return\n",
    "    if fmt == \"parquet\":\n",
    "        path = OUT / f\"{name}.parquet\"\n",
    "        df.to_parquet(path, index=False)\n",
    "    else:\n",
    "        path = OUT / f\"{name}.csv\"\n",
    "        df.to_csv(path, index=False)\n",
    "    print(\"Saved:\", path)\n",
    "\n",
    "\n",
    "def finalize_direct_df(df: pd.DataFrame, section_name: str) -> pd.DataFrame:\n",
    "    if df is None or len(df) == 0:\n",
    "        print(f\"[{section_name}] No direct CPU/GPU pairs available.\")\n",
    "        return pd.DataFrame()\n",
    "    out = df.copy()\n",
    "    out[\"improvement_pct\"] = (out[\"speedup_x\"] - 1.0) * 100.0\n",
    "    out[\"seconds_saved\"] = out[\"cpu_seconds\"] - out[\"gpu_seconds\"]\n",
    "    out[\"relevance\"] = [\n",
    "        classify_relevance(sp, ss, qp)\n",
    "        for sp, ss, qp in zip(\n",
    "            out[\"speedup_x\"].to_numpy(np.float64),\n",
    "            out[\"seconds_saved\"].to_numpy(np.float64),\n",
    "            out[\"quality_pass\"].to_numpy(bool),\n",
    "        )\n",
    "    ]\n",
    "    order = [\n",
    "        \"section\", \"method\", \"cpu_backend\", \"gpu_backend\",\n",
    "        \"cpu_seconds\", \"gpu_seconds\", \"speedup_x\",\n",
    "        \"improvement_pct\", \"seconds_saved\", \"quality_pass\",\n",
    "        \"relevance\", \"note\",\n",
    "    ]\n",
    "    keep = [c for c in order if c in out.columns]\n",
    "    return out[keep].sort_values([\"section\", \"method\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def print_section_conclusions(direct_df: pd.DataFrame, section_title: str) -> None:\n",
    "    if direct_df is None or len(direct_df) == 0:\n",
    "        return\n",
    "    best = direct_df.sort_values(\"speedup_x\", ascending=False).iloc[0]\n",
    "    worst = direct_df.sort_values(\"speedup_x\", ascending=True).iloc[0]\n",
    "    pass_rate = float(direct_df[\"quality_pass\"].mean())\n",
    "    print(\n",
    "        f\"{section_title} conclusions: \"\n",
    "        f\"median speedup={float(direct_df['speedup_x'].median()):.2f}x, \"\n",
    "        f\"best={best['method']} ({best['speedup_x']:.2f}x), \"\n",
    "        f\"worst={worst['method']} ({worst['speedup_x']:.2f}x), \"\n",
    "        f\"quality_pass_rate={pass_rate:.2f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    HAS_MPL = True\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "except Exception as exc:\n",
    "    HAS_MPL = False\n",
    "    print(\"matplotlib unavailable:\", repr(exc))\n",
    "\n",
    "\n",
    "CPU_COLOR = \"#A8B5C4\"\n",
    "GPU_GAIN_COLOR = \"#94C9B2\"\n",
    "GPU_LOSS_COLOR = \"#E8A7A7\"\n",
    "TEXT_SOFT = \"#5B6470\"\n",
    "\n",
    "\n",
    "def plot_method_pairs(direct_df: pd.DataFrame, section_title: str) -> None:\n",
    "    if not bool(CONFIG.get(\"plot_per_method_charts\", True)):\n",
    "        return\n",
    "    if not HAS_MPL or direct_df is None or len(direct_df) == 0:\n",
    "        return\n",
    "    print(f\"{section_title}: CPU vs GPU charts\")\n",
    "    for _, r in direct_df.iterrows():\n",
    "        method = str(r[\"method\"])\n",
    "        cpu_s = float(r[\"cpu_seconds\"])\n",
    "        gpu_s = float(r[\"gpu_seconds\"])\n",
    "        speedup = float(r[\"speedup_x\"])\n",
    "        improvement = float(r[\"improvement_pct\"])\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8.6, 4.2))\n",
    "        gpu_color = GPU_GAIN_COLOR if improvement >= 0 else GPU_LOSS_COLOR\n",
    "        bars = ax.barh([\"CPU\", \"GPU\"], [cpu_s, gpu_s], color=[CPU_COLOR, gpu_color], height=0.56)\n",
    "\n",
    "        positive = [v for v in [cpu_s, gpu_s] if np.isfinite(v) and v > 0]\n",
    "        if len(positive) == 2 and max(positive) / min(positive) >= 30:\n",
    "            ax.set_xscale(\"log\")\n",
    "            ax.set_xlabel(\"Median seconds (log scale)\")\n",
    "        else:\n",
    "            ax.set_xlabel(\"Median seconds\")\n",
    "\n",
    "        xmax = max(positive) if positive else 1.0\n",
    "        ax.set_xlim(0, xmax * 1.35 if np.isfinite(xmax) else 1.0)\n",
    "        for b, v in zip(bars, [cpu_s, gpu_s]):\n",
    "            ax.text(\n",
    "                b.get_width() + xmax * 0.025,\n",
    "                b.get_y() + b.get_height() / 2,\n",
    "                f\"{v:.4f}s\",\n",
    "                ha=\"left\", va=\"center\", fontsize=10, color=\"#374151\",\n",
    "            )\n",
    "\n",
    "        ax.set_title(f\"{section_title} | {method}\", loc=\"left\", fontsize=13, fontweight=\"bold\", pad=14)\n",
    "        subtitle = f\"speedup={speedup:.2f}x | improvement={improvement:+.1f}%\"\n",
    "        ax.text(0.00, 1.02, subtitle, transform=ax.transAxes, fontsize=10, color=TEXT_SOFT, va=\"bottom\")\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.grid(axis=\"x\", alpha=0.18)\n",
    "        fig.subplots_adjust(left=0.16, right=0.96, top=0.80, bottom=0.24)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"save_outputs:\", CONFIG[\"save_outputs\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Environment and data checks\n",
    "\n",
    "This notebook expects a RAPIDS-capable environment (Linux/WSL2 + NVIDIA GPU).\n",
    "Artifacts are exported as **parquet** to `reports/gpu_benchmark/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardware + package checks\n",
    "\n",
    "def run(cmd: list[str]) -> tuple[int, str, str]:\n",
    "    p = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    return p.returncode, p.stdout, p.stderr\n",
    "\n",
    "code, out, err = run([\"nvidia-smi\"])\n",
    "print(out if code == 0 else err)\n",
    "\n",
    "pkgs = [\n",
    "    \"cudf\", \"cuml\", \"cugraph\", \"nx_cugraph\", \"cuopt\", \"cupy\", \"rmm\",\n",
    "    \"networkx\", \"scipy\", \"sklearn\", \"polars\", \"pandas\", \"duckdb\", \"narwhals\",\n",
    "]\n",
    "rows = []\n",
    "for p in pkgs:\n",
    "    spec = importlib.util.find_spec(p)\n",
    "    ver = None\n",
    "    if spec is not None:\n",
    "        try:\n",
    "            mod = __import__(p)\n",
    "            ver = getattr(mod, \"__version__\", None)\n",
    "        except Exception:\n",
    "            ver = \"import_error\"\n",
    "    rows.append({\"package\": p, \"available\": spec is not None, \"version\": ver})\n",
    "pkg_df = pd.DataFrame(rows)\n",
    "display(pkg_df)\n",
    "\n",
    "# 10GB VRAM-safe RMM pool for RTX 3080 style cards\n",
    "try:\n",
    "    import cupy as cp\n",
    "    import rmm\n",
    "\n",
    "    rmm.reinitialize(pool_allocator=True, managed_memory=False, initial_pool_size=6 * 1024**3)\n",
    "\n",
    "    alloc = None\n",
    "    try:\n",
    "        from rmm.allocators.cupy import rmm_cupy_allocator\n",
    "        alloc = rmm_cupy_allocator\n",
    "    except Exception:\n",
    "        alloc = getattr(rmm, \"rmm_cupy_allocator\", None)\n",
    "\n",
    "    if alloc is not None:\n",
    "        cp.cuda.set_allocator(alloc)\n",
    "        print(\"RMM configured with CuPy allocator (6 GB pool)\")\n",
    "    else:\n",
    "        print(\"RMM configured, but CuPy allocator binding not found\")\n",
    "except Exception as exc:\n",
    "    print(\"RMM setup skipped:\", repr(exc))\n",
    "\n",
    "for p in [TRAIN, TEST, TRAIN_FE, TEST_FE]:\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing required file: {p}\")\n",
    "\n",
    "summary_rows = []\n",
    "for p in [TRAIN, TEST, TRAIN_FE, TEST_FE]:\n",
    "    d = pd.read_parquet(p, columns=[\"id\", \"default_flag\"])\n",
    "    summary_rows.append({\n",
    "        \"file\": str(p.relative_to(ROOT)),\n",
    "        \"rows\": int(len(d)),\n",
    "        \"default_rate\": float(d[\"default_flag\"].mean()),\n",
    "    })\n",
    "display(pd.DataFrame(summary_rows))\n",
    "\n",
    "# Save library versions for Streamlit meta\n",
    "lib_versions = {r[\"package\"]: str(r[\"version\"]) for _, r in pkg_df.iterrows() if r[\"available\"]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 1) DataFrame benchmark: pandas, cuDF, Polars, DuckDB\n",
    "\n",
    "Compared backends:\n",
    "- `pandas_cpu` — vanilla pandas\n",
    "- `pandas_cudf` — pandas via `python -m cudf.pandas` (zero-code-change)\n",
    "- `polars_cpu` — Polars lazy collect (CPU)\n",
    "- `polars_cudf` — Polars lazy with `pl.GPUEngine` (GPU)\n",
    "- `duckdb` — in-process SQL (CPU analytical engine)\n",
    "\n",
    "Quality checks: row-count parity + checksum relative error ≤ 5e-3 vs pandas_cpu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = int(CONFIG[\"cudf_repeats\"])\n",
    "W = int(CONFIG[\"cudf_warmup\"])\n",
    "exe = sys.executable\n",
    "\n",
    "\n",
    "def run_json(cmd: list[str]) -> dict[str, Any]:\n",
    "    p = subprocess.run(cmd, cwd=str(ROOT), capture_output=True, text=True)\n",
    "    res: dict[str, Any] = {\n",
    "        \"command\": \" \".join(cmd),\n",
    "        \"status\": \"ok\" if p.returncode == 0 else \"error\",\n",
    "        \"returncode\": p.returncode,\n",
    "        \"stderr_tail\": p.stderr[-800:],\n",
    "    }\n",
    "    if p.returncode == 0:\n",
    "        try:\n",
    "            payload = json.loads(p.stdout.strip().splitlines()[-1])\n",
    "            res.update(payload)\n",
    "        except Exception as exc:\n",
    "            res[\"status\"] = \"error\"\n",
    "            res[\"parse_error\"] = repr(exc)\n",
    "    return res\n",
    "\n",
    "\n",
    "plan: list[tuple[str, list[str]]] = [\n",
    "    (\"pandas_cpu\", [exe, str(TMP / \"bench_pandas.py\"), str(TRAIN), str(R), str(W)]),\n",
    "    (\"polars_cpu\", [exe, str(TMP / \"bench_polars.py\"), str(TRAIN), str(R), str(W), \"cpu\"]),\n",
    "    (\"duckdb\", [exe, str(TMP / \"bench_duckdb.py\"), str(TRAIN), str(R), str(W)]),\n",
    "]\n",
    "\n",
    "has_cudf = importlib.util.find_spec(\"cudf\") is not None\n",
    "if has_cudf:\n",
    "    plan.append((\"pandas_cudf\", [\n",
    "        exe, \"-m\", \"cudf.pandas\", str(TMP / \"bench_pandas.py\"), str(TRAIN), str(R), str(W),\n",
    "    ]))\n",
    "else:\n",
    "    print(\"Skipping pandas_cudf: cudf not available\")\n",
    "\n",
    "if has_cudf and hasattr(pl, \"GPUEngine\"):\n",
    "    plan.append((\"polars_cudf\", [\n",
    "        exe, str(TMP / \"bench_polars.py\"), str(TRAIN), str(R), str(W), \"gpu\",\n",
    "    ]))\n",
    "else:\n",
    "    print(\"Skipping polars_cudf: cudf and/or pl.GPUEngine not available\")\n",
    "\n",
    "rows = []\n",
    "for mode, cmd in plan:\n",
    "    print(f\"Running {mode}...\")\n",
    "    x = run_json(cmd)\n",
    "    x[\"mode\"] = mode\n",
    "    rows.append(x)\n",
    "\n",
    "cudf_df = pd.DataFrame(rows)\n",
    "\n",
    "ok = cudf_df[cudf_df[\"status\"] == \"ok\"]\n",
    "base = ok.loc[ok[\"mode\"] == \"pandas_cpu\", \"median_seconds\"]\n",
    "if len(base) == 1:\n",
    "    b = float(base.iloc[0])\n",
    "    cudf_df[\"speedup_vs_pandas_cpu\"] = np.where(\n",
    "        cudf_df[\"status\"] == \"ok\",\n",
    "        b / cudf_df[\"median_seconds\"],\n",
    "        np.nan,\n",
    "    )\n",
    "\n",
    "base_rows = ok.loc[ok[\"mode\"] == \"pandas_cpu\", \"rows_out\"]\n",
    "base_checksum = ok.loc[ok[\"mode\"] == \"pandas_cpu\", \"checksum\"]\n",
    "if len(base_rows) == 1 and len(base_checksum) == 1:\n",
    "    br = int(base_rows.iloc[0])\n",
    "    bc = float(base_checksum.iloc[0])\n",
    "    cudf_df[\"rows_match_cpu\"] = np.where(cudf_df[\"status\"] == \"ok\", cudf_df[\"rows_out\"] == br, np.nan)\n",
    "    cudf_df[\"checksum_rel_err_cpu\"] = np.where(\n",
    "        cudf_df[\"status\"] == \"ok\",\n",
    "        np.abs(cudf_df[\"checksum\"] - bc) / max(abs(bc), 1e-12),\n",
    "        np.nan,\n",
    "    )\n",
    "    cudf_df[\"consistency_pass\"] = np.where(\n",
    "        cudf_df[\"status\"] == \"ok\",\n",
    "        (cudf_df[\"rows_match_cpu\"] == True) & (cudf_df[\"checksum_rel_err_cpu\"] <= CONFIG[\"consistency_rel_tol\"]),\n",
    "        np.nan,\n",
    "    )\n",
    "\n",
    "display(cudf_df.sort_values(\"mode\"))\n",
    "save_artifact(cudf_df, \"cudf_polars_benchmark\")\n",
    "\n",
    "# Direct CPU vs GPU view\n",
    "cudf_pair_rows: list[dict[str, Any]] = []\n",
    "for method, cpu_mode, gpu_mode in [\n",
    "    (\"pandas_query_pipeline\", \"pandas_cpu\", \"pandas_cudf\"),\n",
    "    (\"polars_query_pipeline\", \"polars_cpu\", \"polars_cudf\"),\n",
    "]:\n",
    "    cpu = cudf_df[(cudf_df[\"mode\"] == cpu_mode) & (cudf_df[\"status\"] == \"ok\")]\n",
    "    gpu = cudf_df[(cudf_df[\"mode\"] == gpu_mode) & (cudf_df[\"status\"] == \"ok\")]\n",
    "    if len(cpu) == 1 and len(gpu) == 1:\n",
    "        cudf_pair_rows.append({\n",
    "            \"section\": \"cudf\",\n",
    "            \"method\": method,\n",
    "            \"cpu_backend\": cpu_mode,\n",
    "            \"gpu_backend\": gpu_mode,\n",
    "            \"cpu_seconds\": float(cpu.iloc[0][\"median_seconds\"]),\n",
    "            \"gpu_seconds\": float(gpu.iloc[0][\"median_seconds\"]),\n",
    "            \"speedup_x\": float(cpu.iloc[0][\"median_seconds\"]) / max(float(gpu.iloc[0][\"median_seconds\"]), 1e-12),\n",
    "            \"quality_pass\": bool(gpu.iloc[0].get(\"consistency_pass\", False)),\n",
    "            \"note\": f\"checksum_rel_err={gpu.iloc[0].get('checksum_rel_err_cpu', np.nan)}\",\n",
    "        })\n",
    "\n",
    "cudf_direct_df = finalize_direct_df(pd.DataFrame(cudf_pair_rows), \"cudf\")\n",
    "if len(cudf_direct_df):\n",
    "    display(cudf_direct_df)\n",
    "    save_artifact(cudf_direct_df, \"gpu_bench_dataframe_direct\")\n",
    "    plot_method_pairs(cudf_direct_df, \"cuDF\")\n",
    "    print_section_conclusions(cudf_direct_df, \"cuDF\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 2) cuML benchmark: scikit-learn CPU vs cuML GPU\n",
    "\n",
    "Algorithms:\n",
    "- **Classification**: Logistic Regression, Random Forest\n",
    "- **Clustering**: KMeans\n",
    "- **Dimensionality Reduction**: PCA\n",
    "- **Nearest Neighbors**: KNN\n",
    "\n",
    "Quality gates: AUC tolerance (0.010 LR, 0.025 RF), silhouette tolerance (0.040 KMeans).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans as SKKMeans\n",
    "from sklearn.decomposition import PCA as SKPCA\n",
    "from sklearn.ensemble import RandomForestClassifier as SKRF\n",
    "from sklearn.linear_model import LogisticRegression as SKLR\n",
    "from sklearn.metrics import roc_auc_score, silhouette_score\n",
    "from sklearn.neighbors import KNeighborsClassifier as SKKNN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(int(CONFIG[\"seed\"]))\n",
    "\n",
    "train = pd.read_parquet(TRAIN_FE)\n",
    "test = pd.read_parquet(TEST_FE)\n",
    "\n",
    "num = [\n",
    "    \"loan_amnt\", \"int_rate\", \"installment\", \"annual_inc\", \"dti\", \"loan_to_income\",\n",
    "    \"installment_burden\", \"rev_utilization\", \"revol_bal_to_income\", \"open_acc_ratio\",\n",
    "    \"fico_score\", \"credit_age_years\", \"emp_length_num\", \"open_acc\", \"total_acc\",\n",
    "    \"revol_bal\", \"pub_rec\", \"inq_last_6mths\", \"mort_acc\", \"delinq_severity\",\n",
    "    \"delinq_recency\", \"il_ratio\", \"high_util_pct\", \"log_annual_inc\", \"log_revol_bal\",\n",
    "    \"loan_to_income_sq\", \"fico_x_dti\",\n",
    "]\n",
    "feat = [c for c in num if c in train.columns and c in test.columns]\n",
    "if not feat:\n",
    "    raise RuntimeError(\"No overlapping numeric features found for cuML benchmark\")\n",
    "\n",
    "train = train.sample(n=min(int(CONFIG[\"cuml_train_sample\"]), len(train)), random_state=int(CONFIG[\"seed\"])).reset_index(drop=True)\n",
    "test = test.sample(n=min(int(CONFIG[\"cuml_test_sample\"]), len(test)), random_state=int(CONFIG[\"seed\"])).reset_index(drop=True)\n",
    "\n",
    "Xtr = train[feat].apply(pd.to_numeric, errors=\"coerce\").fillna(0.0).astype(np.float32)\n",
    "Xte = test[feat].apply(pd.to_numeric, errors=\"coerce\").fillna(0.0).astype(np.float32)\n",
    "ytr = train[\"default_flag\"].astype(np.int32)\n",
    "yte = test[\"default_flag\"].astype(np.int32)\n",
    "\n",
    "sc = StandardScaler()\n",
    "Xtr_s = sc.fit_transform(Xtr).astype(np.float32)\n",
    "Xte_s = sc.transform(Xte).astype(np.float32)\n",
    "\n",
    "res: list[dict[str, Any]] = []\n",
    "\n",
    "\n",
    "def push_result(task: str, backend: str, fit_times: list[float], pred_times: list[float], metric: str, values: list[float]) -> None:\n",
    "    st_fit = stats_from(fit_times)\n",
    "    st_pred = stats_from(pred_times)\n",
    "    arr = np.asarray(values, dtype=np.float64)\n",
    "    res.append({\n",
    "        \"task\": task,\n",
    "        \"backend\": backend,\n",
    "        \"fit_seconds\": st_fit[\"median_seconds\"],\n",
    "        \"fit_iqr_seconds\": st_fit[\"iqr_seconds\"],\n",
    "        \"predict_seconds\": st_pred[\"median_seconds\"],\n",
    "        \"predict_iqr_seconds\": st_pred[\"iqr_seconds\"],\n",
    "        \"metric\": metric,\n",
    "        \"metric_value\": float(np.median(arr)) if arr.size else np.nan,\n",
    "        \"metric_std\": float(np.std(arr)) if arr.size else np.nan,\n",
    "        \"n_runs\": int(arr.size),\n",
    "    })\n",
    "\n",
    "\n",
    "# CPU logistic regression\n",
    "fit_times: list[float] = []\n",
    "pred_times: list[float] = []\n",
    "metrics: list[float] = []\n",
    "for _ in range(int(CONFIG[\"cuml_repeats_light\"])):\n",
    "    s = time.perf_counter()\n",
    "    mdl = SKLR(max_iter=600, solver=\"lbfgs\")\n",
    "    mdl.fit(Xtr_s, ytr)\n",
    "    fit_times.append(time.perf_counter() - s)\n",
    "    s = time.perf_counter()\n",
    "    proba = mdl.predict_proba(Xte_s)[:, 1]\n",
    "    pred_times.append(time.perf_counter() - s)\n",
    "    metrics.append(float(roc_auc_score(yte, proba)))\n",
    "push_result(\"logistic_regression\", \"sklearn_cpu\", fit_times, pred_times, \"auc\", metrics)\n",
    "\n",
    "# CPU random forest\n",
    "fit_times = []\n",
    "pred_times = []\n",
    "metrics = []\n",
    "for _ in range(int(CONFIG[\"cuml_repeats_heavy\"])):\n",
    "    s = time.perf_counter()\n",
    "    mdl = SKRF(n_estimators=250, max_depth=12, random_state=int(CONFIG[\"seed\"]), n_jobs=-1)\n",
    "    mdl.fit(Xtr, ytr)\n",
    "    fit_times.append(time.perf_counter() - s)\n",
    "    s = time.perf_counter()\n",
    "    proba = mdl.predict_proba(Xte)[:, 1]\n",
    "    pred_times.append(time.perf_counter() - s)\n",
    "    metrics.append(float(roc_auc_score(yte, proba)))\n",
    "push_result(\"random_forest\", \"sklearn_cpu\", fit_times, pred_times, \"auc\", metrics)\n",
    "\n",
    "# CPU KMeans\n",
    "Xk = Xtr_s[: min(150_000, len(Xtr_s))]\n",
    "fit_times = []\n",
    "pred_times = []\n",
    "metrics = []\n",
    "for _ in range(int(CONFIG[\"cuml_repeats_light\"])):\n",
    "    s = time.perf_counter()\n",
    "    labels = SKKMeans(n_clusters=7, n_init=10, random_state=int(CONFIG[\"seed\"])).fit_predict(Xk)\n",
    "    fit_times.append(time.perf_counter() - s)\n",
    "    pred_times.append(0.0)\n",
    "    n_sil = min(30_000, len(Xk))\n",
    "    metrics.append(float(silhouette_score(Xk[:n_sil], labels[:n_sil])))\n",
    "push_result(\"kmeans\", \"sklearn_cpu\", fit_times, pred_times, \"silhouette\", metrics)\n",
    "\n",
    "# CPU PCA\n",
    "fit_times = []\n",
    "pred_times = []\n",
    "metrics = []\n",
    "for _ in range(int(CONFIG[\"cuml_repeats_light\"])):\n",
    "    s = time.perf_counter()\n",
    "    pca = SKPCA(n_components=10, random_state=int(CONFIG[\"seed\"]))\n",
    "    Xpca = pca.fit_transform(Xtr_s)\n",
    "    fit_times.append(time.perf_counter() - s)\n",
    "    pred_times.append(0.0)\n",
    "    metrics.append(float(sum(pca.explained_variance_ratio_)))\n",
    "push_result(\"pca\", \"sklearn_cpu\", fit_times, pred_times, \"explained_variance\", metrics)\n",
    "\n",
    "# CPU KNN\n",
    "fit_times = []\n",
    "pred_times = []\n",
    "metrics = []\n",
    "Xknn_tr = Xtr_s[:50_000]\n",
    "yknn_tr = ytr[:50_000]\n",
    "Xknn_te = Xte_s[:20_000]\n",
    "yknn_te = yte[:20_000]\n",
    "for _ in range(int(CONFIG[\"cuml_repeats_light\"])):\n",
    "    s = time.perf_counter()\n",
    "    knn = SKKNN(n_neighbors=5, n_jobs=-1)\n",
    "    knn.fit(Xknn_tr, yknn_tr)\n",
    "    fit_times.append(time.perf_counter() - s)\n",
    "    s = time.perf_counter()\n",
    "    proba = knn.predict_proba(Xknn_te)[:, 1]\n",
    "    pred_times.append(time.perf_counter() - s)\n",
    "    metrics.append(float(roc_auc_score(yknn_te, proba)))\n",
    "push_result(\"knn\", \"sklearn_cpu\", fit_times, pred_times, \"auc\", metrics)\n",
    "\n",
    "# GPU block\n",
    "if all(importlib.util.find_spec(p) is not None for p in [\"cuml\", \"cudf\", \"cupy\"]):\n",
    "    try:\n",
    "        import cupy as cp\n",
    "        import cudf\n",
    "        from cuml.cluster import KMeans as CUKMeans\n",
    "        from cuml.decomposition import PCA as CUPCA\n",
    "        from cuml.ensemble import RandomForestClassifier as CURF\n",
    "        from cuml.linear_model import LogisticRegression as CULR\n",
    "        from cuml.neighbors import KNeighborsClassifier as CUKNN\n",
    "\n",
    "        def sync() -> None:\n",
    "            cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "        def as_numpy(x: Any) -> np.ndarray:\n",
    "            if isinstance(x, np.ndarray):\n",
    "                return x\n",
    "            if isinstance(x, cp.ndarray):\n",
    "                return cp.asnumpy(x)\n",
    "            if hasattr(x, \"to_numpy\"):\n",
    "                return x.to_numpy()\n",
    "            if hasattr(x, \"values_host\"):\n",
    "                return x.values_host\n",
    "            return np.asarray(x)\n",
    "\n",
    "        Xtrg_s = cudf.DataFrame(Xtr_s)\n",
    "        Xteg_s = cudf.DataFrame(Xte_s)\n",
    "        ytrg = cudf.Series(ytr.to_numpy())\n",
    "\n",
    "        # GPU logistic regression\n",
    "        fit_times = []\n",
    "        pred_times = []\n",
    "        metrics = []\n",
    "        for _ in range(int(CONFIG[\"cuml_repeats_light\"])):\n",
    "            s = time.perf_counter()\n",
    "            mdl = CULR(max_iter=600, linesearch_max_iter=100, output_type=\"numpy\")\n",
    "            mdl.fit(Xtrg_s, ytrg)\n",
    "            sync()\n",
    "            fit_times.append(time.perf_counter() - s)\n",
    "            s = time.perf_counter()\n",
    "            proba = mdl.predict_proba(Xteg_s)\n",
    "            sync()\n",
    "            pred_times.append(time.perf_counter() - s)\n",
    "            proba = as_numpy(proba)\n",
    "            proba = proba[:, 1] if proba.ndim == 2 else proba\n",
    "            metrics.append(float(roc_auc_score(yte, proba)))\n",
    "        push_result(\"logistic_regression\", \"cuml_gpu\", fit_times, pred_times, \"auc\", metrics)\n",
    "\n",
    "        # GPU random forest\n",
    "        Xtrg = cudf.DataFrame(Xtr)\n",
    "        Xteg = cudf.DataFrame(Xte)\n",
    "        fit_times = []\n",
    "        pred_times = []\n",
    "        metrics = []\n",
    "        for _ in range(int(CONFIG[\"cuml_repeats_heavy\"])):\n",
    "            s = time.perf_counter()\n",
    "            mdl = CURF(n_estimators=250, max_depth=12, random_state=int(CONFIG[\"seed\"]), output_type=\"numpy\")\n",
    "            mdl.fit(Xtrg, ytrg)\n",
    "            sync()\n",
    "            fit_times.append(time.perf_counter() - s)\n",
    "            s = time.perf_counter()\n",
    "            proba = mdl.predict_proba(Xteg)\n",
    "            sync()\n",
    "            pred_times.append(time.perf_counter() - s)\n",
    "            proba = as_numpy(proba)\n",
    "            proba = proba[:, 1] if proba.ndim == 2 else proba\n",
    "            metrics.append(float(roc_auc_score(yte, proba)))\n",
    "        push_result(\"random_forest\", \"cuml_gpu\", fit_times, pred_times, \"auc\", metrics)\n",
    "\n",
    "        # GPU KMeans\n",
    "        Xkg = cudf.DataFrame(Xk)\n",
    "        fit_times = []\n",
    "        pred_times = []\n",
    "        metrics = []\n",
    "        for _ in range(int(CONFIG[\"cuml_repeats_light\"])):\n",
    "            s = time.perf_counter()\n",
    "            labels = CUKMeans(n_clusters=7, n_init=10, random_state=int(CONFIG[\"seed\"]), output_type=\"numpy\").fit_predict(Xkg)\n",
    "            sync()\n",
    "            fit_times.append(time.perf_counter() - s)\n",
    "            pred_times.append(0.0)\n",
    "            labels = as_numpy(labels)\n",
    "            n_sil = min(30_000, len(Xk))\n",
    "            metrics.append(float(silhouette_score(Xk[:n_sil], labels[:n_sil])))\n",
    "        push_result(\"kmeans\", \"cuml_gpu\", fit_times, pred_times, \"silhouette\", metrics)\n",
    "\n",
    "        # GPU PCA\n",
    "        fit_times = []\n",
    "        pred_times = []\n",
    "        metrics = []\n",
    "        for _ in range(int(CONFIG[\"cuml_repeats_light\"])):\n",
    "            s = time.perf_counter()\n",
    "            pca = CUPCA(n_components=10, random_state=int(CONFIG[\"seed\"]), output_type=\"numpy\")\n",
    "            pca.fit(Xtrg_s)\n",
    "            sync()\n",
    "            fit_times.append(time.perf_counter() - s)\n",
    "            pred_times.append(0.0)\n",
    "            evr = as_numpy(pca.explained_variance_ratio_)\n",
    "            metrics.append(float(sum(evr)))\n",
    "        push_result(\"pca\", \"cuml_gpu\", fit_times, pred_times, \"explained_variance\", metrics)\n",
    "\n",
    "        # GPU KNN\n",
    "        Xknn_trg = cudf.DataFrame(Xknn_tr)\n",
    "        yknn_trg = cudf.Series(yknn_tr.to_numpy())\n",
    "        Xknn_teg = cudf.DataFrame(Xknn_te)\n",
    "        fit_times = []\n",
    "        pred_times = []\n",
    "        metrics = []\n",
    "        for _ in range(int(CONFIG[\"cuml_repeats_light\"])):\n",
    "            s = time.perf_counter()\n",
    "            knn = CUKNN(n_neighbors=5, output_type=\"numpy\")\n",
    "            knn.fit(Xknn_trg, yknn_trg)\n",
    "            sync()\n",
    "            fit_times.append(time.perf_counter() - s)\n",
    "            s = time.perf_counter()\n",
    "            proba = knn.predict_proba(Xknn_teg)\n",
    "            sync()\n",
    "            pred_times.append(time.perf_counter() - s)\n",
    "            proba = as_numpy(proba)\n",
    "            proba = proba[:, 1] if proba.ndim == 2 else proba\n",
    "            metrics.append(float(roc_auc_score(yknn_te, proba)))\n",
    "        push_result(\"knn\", \"cuml_gpu\", fit_times, pred_times, \"auc\", metrics)\n",
    "\n",
    "    except Exception as exc:\n",
    "        print(\"cuML GPU block failed:\", repr(exc))\n",
    "        traceback.print_exc(limit=2)\n",
    "else:\n",
    "    print(\"cuML/cuDF/cuPy not available -> CPU baseline only\")\n",
    "\n",
    "\n",
    "cuml_df = pd.DataFrame(res)\n",
    "for t in cuml_df[\"task\"].unique():\n",
    "    cpu = cuml_df[(cuml_df[\"task\"] == t) & (cuml_df[\"backend\"] == \"sklearn_cpu\")]\n",
    "    if len(cpu) == 1:\n",
    "        b = float(cpu.iloc[0][\"fit_seconds\"])\n",
    "        mask = cuml_df[\"task\"] == t\n",
    "        cuml_df.loc[mask, \"fit_speedup_vs_cpu\"] = np.where(\n",
    "            cuml_df.loc[mask, \"backend\"] == \"sklearn_cpu\",\n",
    "            np.nan,\n",
    "            b / cuml_df.loc[mask, \"fit_seconds\"],\n",
    "        )\n",
    "\n",
    "tols = {\n",
    "    \"logistic_regression\": 0.010,\n",
    "    \"random_forest\": 0.025,\n",
    "    \"kmeans\": 0.040,\n",
    "    \"pca\": 0.050,\n",
    "    \"knn\": 0.020,\n",
    "}\n",
    "qrows = []\n",
    "for task in tols:\n",
    "    cpu = cuml_df[(cuml_df[\"task\"] == task) & (cuml_df[\"backend\"] == \"sklearn_cpu\")]\n",
    "    gpu = cuml_df[(cuml_df[\"task\"] == task) & (cuml_df[\"backend\"] == \"cuml_gpu\")]\n",
    "    if len(cpu) == 1 and len(gpu) == 1:\n",
    "        cpu_m = float(cpu.iloc[0][\"metric_value\"])\n",
    "        gpu_m = float(gpu.iloc[0][\"metric_value\"])\n",
    "        abs_diff = abs(cpu_m - gpu_m)\n",
    "        qrows.append({\n",
    "            \"task\": task,\n",
    "            \"metric\": cpu.iloc[0][\"metric\"],\n",
    "            \"cpu_metric\": cpu_m,\n",
    "            \"gpu_metric\": gpu_m,\n",
    "            \"abs_diff\": abs_diff,\n",
    "            \"rel_diff\": rel_err(cpu_m, gpu_m),\n",
    "            \"tolerance\": tols.get(task, 0.05),\n",
    "            \"quality_pass\": abs_diff <= tols.get(task, 0.05),\n",
    "        })\n",
    "\n",
    "cuml_quality_df = pd.DataFrame(qrows)\n",
    "\n",
    "display(cuml_df.sort_values([\"task\", \"backend\"]))\n",
    "if len(cuml_quality_df):\n",
    "    display(cuml_quality_df.sort_values(\"task\"))\n",
    "\n",
    "save_artifact(cuml_df, \"cuml_benchmark\")\n",
    "if len(cuml_quality_df):\n",
    "    save_artifact(cuml_quality_df, \"cuml_quality_checks\")\n",
    "\n",
    "# Direct CPU vs GPU view\n",
    "cuml_pair_rows: list[dict[str, Any]] = []\n",
    "for task in sorted(cuml_df[\"task\"].dropna().unique()):\n",
    "    cpu = cuml_df[(cuml_df[\"task\"] == task) & (cuml_df[\"backend\"] == \"sklearn_cpu\")]\n",
    "    gpu = cuml_df[(cuml_df[\"task\"] == task) & (cuml_df[\"backend\"] == \"cuml_gpu\")]\n",
    "    if len(cpu) == 1 and len(gpu) == 1:\n",
    "        qpass = True\n",
    "        note = \"\"\n",
    "        if len(cuml_quality_df):\n",
    "            q = cuml_quality_df[cuml_quality_df[\"task\"] == task]\n",
    "            if len(q) == 1:\n",
    "                qpass = bool(q.iloc[0].get(\"quality_pass\", True))\n",
    "                note = f\"{q.iloc[0].get('metric', '')} abs_diff={q.iloc[0].get('abs_diff', np.nan)}\"\n",
    "        cpu_s = float(cpu.iloc[0][\"fit_seconds\"])\n",
    "        gpu_s = float(gpu.iloc[0][\"fit_seconds\"])\n",
    "        cuml_pair_rows.append({\n",
    "            \"section\": \"cuml\",\n",
    "            \"method\": str(task),\n",
    "            \"cpu_backend\": \"sklearn_cpu\",\n",
    "            \"gpu_backend\": \"cuml_gpu\",\n",
    "            \"cpu_seconds\": cpu_s,\n",
    "            \"gpu_seconds\": gpu_s,\n",
    "            \"speedup_x\": cpu_s / max(gpu_s, 1e-12),\n",
    "            \"quality_pass\": qpass,\n",
    "            \"note\": note,\n",
    "        })\n",
    "\n",
    "cuml_direct_df = finalize_direct_df(pd.DataFrame(cuml_pair_rows), \"cuml\")\n",
    "if len(cuml_direct_df):\n",
    "    display(cuml_direct_df)\n",
    "    save_artifact(cuml_direct_df, \"gpu_bench_ml_direct\")\n",
    "    plot_method_pairs(cuml_direct_df, \"cuML\")\n",
    "    print_section_conclusions(cuml_direct_df, \"cuML\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 3) cuGraph benchmark: NetworkX CPU vs cuGraph GPU\n",
    "\n",
    "Graph: bipartite (loans → attribute nodes: grade, purpose, sub_grade, verification_status).\n",
    "\n",
    "Tasks: graph_build, connected_components, pagerank, louvain.\n",
    "\n",
    "Also tests nx-cugraph dispatch (`backend=\"cugraph\"`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "np.random.seed(int(CONFIG[\"seed\"]))\n",
    "\n",
    "if hasattr(nx, \"config\") and hasattr(nx.config, \"warnings_to_ignore\"):\n",
    "    try:\n",
    "        nx.config.warnings_to_ignore.add(\"cache\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "g = pd.read_parquet(TRAIN, columns=[\"id\", \"grade\", \"purpose\", \"sub_grade\", \"verification_status\"]).dropna(subset=[\"id\"]).copy()\n",
    "g = g.sample(n=min(int(CONFIG[\"cugraph_sample_rows\"]), len(g)), random_state=int(CONFIG[\"seed\"]))\n",
    "g[\"id\"] = pd.to_numeric(g[\"id\"], errors=\"coerce\")\n",
    "g = g.dropna(subset=[\"id\"])\n",
    "g[\"id\"] = g[\"id\"].astype(np.int64)\n",
    "\n",
    "for col in [\"grade\", \"purpose\", \"sub_grade\", \"verification_status\"]:\n",
    "    g[col] = g[col].fillna(\"unknown\").astype(str)\n",
    "\n",
    "g[\"loan\"] = \"L_\" + g[\"id\"].astype(str)\n",
    "\n",
    "edges = pd.concat([\n",
    "    g[[\"loan\", \"grade\"]].rename(columns={\"loan\": \"src\", \"grade\": \"dst\"}).assign(dst=lambda x: \"G_\" + x[\"dst\"]),\n",
    "    g[[\"loan\", \"purpose\"]].rename(columns={\"loan\": \"src\", \"purpose\": \"dst\"}).assign(dst=lambda x: \"P_\" + x[\"dst\"]),\n",
    "    g[[\"loan\", \"sub_grade\"]].rename(columns={\"loan\": \"src\", \"sub_grade\": \"dst\"}).assign(dst=lambda x: \"SG_\" + x[\"dst\"]),\n",
    "    g[[\"loan\", \"verification_status\"]].rename(columns={\"loan\": \"src\", \"verification_status\": \"dst\"}).assign(dst=lambda x: \"V_\" + x[\"dst\"]),\n",
    "], ignore_index=True)\n",
    "\n",
    "nodes = pd.Index(pd.concat([edges[\"src\"], edges[\"dst\"]], ignore_index=True).unique())\n",
    "node2id = pd.Series(np.arange(len(nodes), dtype=np.int64), index=nodes)\n",
    "\n",
    "E = pd.DataFrame({\n",
    "    \"src\": edges[\"src\"].map(node2id).astype(np.int32),\n",
    "    \"dst\": edges[\"dst\"].map(node2id).astype(np.int32),\n",
    "})\n",
    "\n",
    "R = int(CONFIG[\"cugraph_repeats\"])\n",
    "cres: list[dict[str, Any]] = []\n",
    "\n",
    "\n",
    "def add_row(task: str, backend: str, times: list[float], metric: str, metric_value: float, **extra: Any) -> None:\n",
    "    st = stats_from(times)\n",
    "    row: dict[str, Any] = {\n",
    "        \"task\": task,\n",
    "        \"backend\": backend,\n",
    "        \"seconds\": st[\"median_seconds\"],\n",
    "        \"seconds_iqr\": st[\"iqr_seconds\"],\n",
    "        \"metric\": metric,\n",
    "        \"metric_value\": float(metric_value),\n",
    "    }\n",
    "    row.update(extra)\n",
    "    cres.append(row)\n",
    "\n",
    "\n",
    "# NetworkX CPU baseline\n",
    "build_times: list[float] = []\n",
    "G_cpu = None\n",
    "for _ in range(R):\n",
    "    s = time.perf_counter()\n",
    "    G_cpu = nx.from_pandas_edgelist(E, source=\"src\", target=\"dst\", create_using=nx.Graph())\n",
    "    build_times.append(time.perf_counter() - s)\n",
    "\n",
    "cc_times: list[float] = []\n",
    "cc_val = None\n",
    "for _ in range(R):\n",
    "    s = time.perf_counter()\n",
    "    cc_val = nx.number_connected_components(G_cpu)\n",
    "    cc_times.append(time.perf_counter() - s)\n",
    "\n",
    "pr_times: list[float] = []\n",
    "pr_sum = None\n",
    "for _ in range(R):\n",
    "    s = time.perf_counter()\n",
    "    pr = nx.pagerank(G_cpu, alpha=0.85, max_iter=200, tol=1e-6)\n",
    "    pr_times.append(time.perf_counter() - s)\n",
    "    pr_sum = float(sum(pr.values()))\n",
    "\n",
    "add_row(\"graph_build\", \"networkx_cpu\", build_times, \"nodes\", float(G_cpu.number_of_nodes()))\n",
    "add_row(\"connected_components\", \"networkx_cpu\", cc_times, \"n_components\", float(cc_val))\n",
    "add_row(\"pagerank\", \"networkx_cpu\", pr_times, \"sum_pagerank\", float(pr_sum), converged_rate=1.0)\n",
    "\n",
    "# Louvain CPU\n",
    "try:\n",
    "    louvain_times: list[float] = []\n",
    "    n_communities = 0\n",
    "    for _ in range(R):\n",
    "        s = time.perf_counter()\n",
    "        communities = nx.community.louvain_communities(G_cpu, seed=int(CONFIG[\"seed\"]))\n",
    "        louvain_times.append(time.perf_counter() - s)\n",
    "        n_communities = len(communities)\n",
    "    add_row(\"louvain\", \"networkx_cpu\", louvain_times, \"n_communities\", float(n_communities))\n",
    "except Exception as exc:\n",
    "    print(f\"Louvain CPU skipped: {exc}\")\n",
    "\n",
    "\n",
    "# Native cuGraph\n",
    "if all(importlib.util.find_spec(p) is not None for p in [\"cugraph\", \"cudf\", \"cupy\"]):\n",
    "    try:\n",
    "        import cupy as cp\n",
    "        import cudf\n",
    "        import cugraph\n",
    "\n",
    "        def sync() -> None:\n",
    "            cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "        Eg = cudf.DataFrame(E)\n",
    "\n",
    "        build_times = []\n",
    "        G_gpu = None\n",
    "        for _ in range(R):\n",
    "            s = time.perf_counter()\n",
    "            G_gpu = cugraph.Graph(directed=False)\n",
    "            G_gpu.from_cudf_edgelist(Eg, source=\"src\", destination=\"dst\", renumber=False, store_transposed=True)\n",
    "            sync()\n",
    "            build_times.append(time.perf_counter() - s)\n",
    "\n",
    "        cc_times = []\n",
    "        ncc = None\n",
    "        for _ in range(R):\n",
    "            s = time.perf_counter()\n",
    "            ccg = cugraph.connected_components(G_gpu)\n",
    "            sync()\n",
    "            cc_times.append(time.perf_counter() - s)\n",
    "            lcol = \"labels\" if \"labels\" in ccg.columns else ccg.columns[-1]\n",
    "            ncc = int(ccg[lcol].nunique())\n",
    "\n",
    "        pr_times = []\n",
    "        pr_sum = None\n",
    "        converged_flags: list[bool] = []\n",
    "        for _ in range(R):\n",
    "            s = time.perf_counter()\n",
    "            out = cugraph.pagerank(G_gpu, alpha=0.85, max_iter=200, tol=1e-6, fail_on_nonconvergence=False)\n",
    "            sync()\n",
    "            pr_times.append(time.perf_counter() - s)\n",
    "            if isinstance(out, tuple):\n",
    "                prg, converged = out\n",
    "                converged_flags.append(bool(converged))\n",
    "            else:\n",
    "                prg = out\n",
    "                converged_flags.append(True)\n",
    "            pr_sum = float(prg[\"pagerank\"].sum())\n",
    "\n",
    "        add_row(\"graph_build\", \"cugraph_gpu\", build_times, \"nodes\", float(G_gpu.number_of_vertices()))\n",
    "        add_row(\"connected_components\", \"cugraph_gpu\", cc_times, \"n_components\", float(ncc))\n",
    "        add_row(\"pagerank\", \"cugraph_gpu\", pr_times, \"sum_pagerank\", float(pr_sum), converged_rate=float(np.mean(converged_flags)))\n",
    "\n",
    "        # Louvain GPU\n",
    "        try:\n",
    "            louvain_times = []\n",
    "            n_parts = 0\n",
    "            for _ in range(R):\n",
    "                s = time.perf_counter()\n",
    "                parts, modularity = cugraph.louvain(G_gpu)\n",
    "                sync()\n",
    "                louvain_times.append(time.perf_counter() - s)\n",
    "                pcol = \"partition\" if \"partition\" in parts.columns else parts.columns[-1]\n",
    "                n_parts = int(parts[pcol].nunique())\n",
    "            add_row(\"louvain\", \"cugraph_gpu\", louvain_times, \"n_communities\", float(n_parts))\n",
    "        except Exception as exc:\n",
    "            print(f\"Louvain GPU skipped: {exc}\")\n",
    "\n",
    "    except Exception as exc:\n",
    "        print(\"cuGraph GPU block failed:\", repr(exc))\n",
    "        traceback.print_exc(limit=2)\n",
    "else:\n",
    "    print(\"cugraph/cudf/cupy not available -> CPU only\")\n",
    "\n",
    "\n",
    "# NetworkX backend dispatch (nx-cugraph)\n",
    "if importlib.util.find_spec(\"nx_cugraph\") is not None:\n",
    "    try:\n",
    "        cc_times = []\n",
    "        cc_val_backend = None\n",
    "        for _ in range(R):\n",
    "            s = time.perf_counter()\n",
    "            cc_val_backend = sum(1 for _ in nx.connected_components(G_cpu, backend=\"cugraph\"))\n",
    "            cc_times.append(time.perf_counter() - s)\n",
    "        add_row(\"connected_components\", \"networkx_cugraph_backend\", cc_times, \"n_components\", float(cc_val_backend))\n",
    "\n",
    "        pr_times = []\n",
    "        pr_sum_backend = None\n",
    "        for _ in range(R):\n",
    "            s = time.perf_counter()\n",
    "            pr_backend = nx.pagerank(G_cpu, alpha=0.85, max_iter=200, tol=1e-6, backend=\"cugraph\")\n",
    "            pr_times.append(time.perf_counter() - s)\n",
    "            pr_sum_backend = float(sum(pr_backend.values()))\n",
    "        add_row(\"pagerank\", \"networkx_cugraph_backend\", pr_times, \"sum_pagerank\", float(pr_sum_backend), converged_rate=1.0)\n",
    "    except Exception as exc:\n",
    "        print(\"nx-cugraph backend block failed:\", repr(exc))\n",
    "        traceback.print_exc(limit=2)\n",
    "else:\n",
    "    print(\"nx_cugraph not available -> skipping NetworkX backend dispatch\")\n",
    "\n",
    "\n",
    "cugraph_df = pd.DataFrame(cres)\n",
    "for t in cugraph_df[\"task\"].unique():\n",
    "    cpu = cugraph_df[(cugraph_df[\"task\"] == t) & (cugraph_df[\"backend\"] == \"networkx_cpu\")]\n",
    "    if len(cpu) == 1:\n",
    "        b = float(cpu.iloc[0][\"seconds\"])\n",
    "        mask = cugraph_df[\"task\"] == t\n",
    "        cugraph_df.loc[mask, \"speedup_vs_cpu\"] = np.where(\n",
    "            cugraph_df.loc[mask, \"backend\"] == \"networkx_cpu\",\n",
    "            np.nan,\n",
    "            b / cugraph_df.loc[mask, \"seconds\"],\n",
    "        )\n",
    "\n",
    "display(cugraph_df.sort_values([\"task\", \"backend\"]))\n",
    "save_artifact(cugraph_df, \"cugraph_benchmark\")\n",
    "\n",
    "# Direct CPU vs GPU view\n",
    "cugraph_pair_rows: list[dict[str, Any]] = []\n",
    "for task in sorted(cugraph_df[\"task\"].dropna().unique()):\n",
    "    cpu = cugraph_df[(cugraph_df[\"task\"] == task) & (cugraph_df[\"backend\"] == \"networkx_cpu\")]\n",
    "    gpu = cugraph_df[(cugraph_df[\"task\"] == task) & (cugraph_df[\"backend\"] == \"cugraph_gpu\")]\n",
    "    if len(cpu) == 1 and len(gpu) == 1:\n",
    "        cpu_s = float(cpu.iloc[0][\"seconds\"])\n",
    "        gpu_s = float(gpu.iloc[0][\"seconds\"])\n",
    "        cugraph_pair_rows.append({\n",
    "            \"section\": \"cugraph\",\n",
    "            \"method\": str(task),\n",
    "            \"cpu_backend\": \"networkx_cpu\",\n",
    "            \"gpu_backend\": \"cugraph_gpu\",\n",
    "            \"cpu_seconds\": cpu_s,\n",
    "            \"gpu_seconds\": gpu_s,\n",
    "            \"speedup_x\": cpu_s / max(gpu_s, 1e-12),\n",
    "            \"quality_pass\": True,\n",
    "            \"note\": \"\",\n",
    "        })\n",
    "\n",
    "cugraph_direct_df = finalize_direct_df(pd.DataFrame(cugraph_pair_rows), \"cugraph\")\n",
    "if len(cugraph_direct_df):\n",
    "    display(cugraph_direct_df)\n",
    "    save_artifact(cugraph_direct_df, \"gpu_bench_graph_direct\")\n",
    "    plot_method_pairs(cugraph_direct_df, \"cuGraph\")\n",
    "    print_section_conclusions(cugraph_direct_df, \"cuGraph\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 4) cuOpt benchmark: LP portfolio optimization\n",
    "\n",
    "- CPU baseline: `scipy.optimize.linprog(method=\"highs\")`\n",
    "- GPU path: cuOpt LP via `DataModel` + `Solve`\n",
    "- MILP reference: SciPy on smaller problem (3K variables)\n",
    "- Scaling: LP at multiple problem sizes (3K, 6K, 12K, 18K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import Bounds, LinearConstraint, linprog, milp\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "np.random.seed(int(CONFIG[\"seed\"]))\n",
    "\n",
    "train_grade = pd.read_parquet(TRAIN, columns=[\"grade\", \"default_flag\"]).dropna(subset=[\"grade\"])\n",
    "grade_pd = train_grade.groupby(\"grade\")[\"default_flag\"].mean()\n",
    "\n",
    "df = pd.read_parquet(TEST, columns=[\"loan_amnt\", \"int_rate\", \"grade\", \"purpose\", \"default_flag\"]).dropna(\n",
    "    subset=[\"loan_amnt\", \"int_rate\", \"grade\"]\n",
    ").copy()\n",
    "df = df.sample(n=min(int(CONFIG[\"cuopt_sample_rows\"]), len(df)), random_state=int(CONFIG[\"seed\"])).reset_index(drop=True)\n",
    "\n",
    "df[\"loan_amnt\"] = pd.to_numeric(df[\"loan_amnt\"], errors=\"coerce\").fillna(0.0)\n",
    "df[\"int_rate\"] = pd.to_numeric(df[\"int_rate\"].astype(str).str.rstrip(\"%\"), errors=\"coerce\").fillna(0.0)\n",
    "df[\"pd\"] = df[\"grade\"].map(grade_pd).fillna(float(grade_pd.mean())).clip(0.001, 0.99)\n",
    "\n",
    "loan = df[\"loan_amnt\"].to_numpy(np.float64)\n",
    "ir = (df[\"int_rate\"] / 100.0).to_numpy(np.float64)\n",
    "pd_proxy = df[\"pd\"].to_numpy(np.float64)\n",
    "obj = loan * (ir - 0.45 * pd_proxy)\n",
    "\n",
    "budget = float(loan.sum() * 0.20)\n",
    "purpose_vals = df[\"purpose\"].astype(str).to_numpy()\n",
    "constraint_rows = [loan, loan * pd_proxy]\n",
    "rhs = [budget, 0.10 * budget]\n",
    "for p in df[\"purpose\"].astype(str).value_counts().head(2).index.tolist():\n",
    "    constraint_rows.append(np.where(purpose_vals == p, loan, 0.0))\n",
    "    rhs.append(0.35 * budget)\n",
    "\n",
    "A = np.vstack(constraint_rows).astype(np.float64)\n",
    "b = np.array(rhs, dtype=np.float64)\n",
    "\n",
    "opt_res: list[dict[str, Any]] = []\n",
    "\n",
    "\n",
    "# CPU LP\n",
    "lp_times: list[float] = []\n",
    "lp_objs: list[float] = []\n",
    "lp_status: list[int] = []\n",
    "for _ in range(int(CONFIG[\"cuopt_repeats\"])):\n",
    "    s = time.perf_counter()\n",
    "    lp_cpu = linprog(c=-obj, A_ub=A, b_ub=b, bounds=(0, 1), method=\"highs\")\n",
    "    lp_times.append(time.perf_counter() - s)\n",
    "    lp_status.append(int(lp_cpu.status))\n",
    "    lp_objs.append(float(-lp_cpu.fun) if lp_cpu.success else np.nan)\n",
    "\n",
    "st = stats_from(lp_times)\n",
    "opt_res.append({\n",
    "    \"task\": \"portfolio_lp\",\n",
    "    \"backend\": \"scipy_highs_cpu\",\n",
    "    \"seconds\": st[\"median_seconds\"],\n",
    "    \"seconds_iqr\": st[\"iqr_seconds\"],\n",
    "    \"status\": str(lp_status[-1]),\n",
    "    \"objective\": float(np.nanmedian(np.asarray(lp_objs, dtype=np.float64))),\n",
    "    \"n_variables\": int(len(obj)),\n",
    "    \"n_runs\": int(len(lp_times)),\n",
    "})\n",
    "\n",
    "\n",
    "# CPU MILP reference\n",
    "n_milp = min(3000, len(obj))\n",
    "Ac = A[:, :n_milp]\n",
    "cc = -obj[:n_milp]\n",
    "lc = LinearConstraint(Ac, -np.inf * np.ones(Ac.shape[0]), b)\n",
    "bb = Bounds(lb=np.zeros(n_milp), ub=np.ones(n_milp))\n",
    "ig = np.ones(n_milp, dtype=int)\n",
    "\n",
    "s = time.perf_counter()\n",
    "mi = milp(c=cc, integrality=ig, bounds=bb, constraints=lc, options={\"time_limit\": 120})\n",
    "t_mi = time.perf_counter() - s\n",
    "\n",
    "opt_res.append({\n",
    "    \"task\": \"portfolio_milp_reference\",\n",
    "    \"backend\": \"scipy_milp_cpu\",\n",
    "    \"seconds\": float(t_mi),\n",
    "    \"seconds_iqr\": np.nan,\n",
    "    \"status\": str(mi.status),\n",
    "    \"objective\": float(-mi.fun) if mi.success else np.nan,\n",
    "    \"n_variables\": int(n_milp),\n",
    "    \"n_runs\": 1,\n",
    "})\n",
    "\n",
    "\n",
    "# cuOpt LP via DataModel + Solve\n",
    "if importlib.util.find_spec(\"cuopt\") is not None:\n",
    "    try:\n",
    "        from cuopt import linear_programming as lp_api\n",
    "\n",
    "        gpu_times: list[float] = []\n",
    "        gpu_obj: list[float] = []\n",
    "        gpu_reason: list[str] = []\n",
    "\n",
    "        A_csr = csr_matrix(A)\n",
    "        row_types = np.array([\"L\"] * A.shape[0])\n",
    "        lb = np.zeros(A.shape[1], dtype=np.float64)\n",
    "        ub = np.ones(A.shape[1], dtype=np.float64)\n",
    "\n",
    "        for _ in range(int(CONFIG[\"cuopt_repeats\"])):\n",
    "            dm = lp_api.DataModel()\n",
    "            dm.set_csr_constraint_matrix(\n",
    "                A_csr.data.astype(np.float64),\n",
    "                A_csr.indices.astype(np.int32),\n",
    "                A_csr.indptr.astype(np.int32),\n",
    "            )\n",
    "            dm.set_constraint_bounds(b)\n",
    "            dm.set_row_types(row_types)\n",
    "            dm.set_objective_coefficients(obj.astype(np.float64))\n",
    "            dm.set_maximize(True)\n",
    "            dm.set_variable_lower_bounds(lb)\n",
    "            dm.set_variable_upper_bounds(ub)\n",
    "\n",
    "            settings = lp_api.SolverSettings()\n",
    "            try:\n",
    "                settings.set_parameter(\"log_to_console\", False)\n",
    "            except Exception:\n",
    "                pass\n",
    "            settings.set_parameter(\"time_limit\", 120)\n",
    "\n",
    "            s = time.perf_counter()\n",
    "            sol = lp_api.Solve(dm, settings)\n",
    "            gpu_times.append(time.perf_counter() - s)\n",
    "\n",
    "            reason = str(sol.get_termination_reason())\n",
    "            gpu_reason.append(reason)\n",
    "            if \"Optimal\" in reason:\n",
    "                gpu_obj.append(float(sol.get_primal_objective()))\n",
    "            else:\n",
    "                gpu_obj.append(np.nan)\n",
    "\n",
    "        st_gpu = stats_from(gpu_times)\n",
    "        opt_res.append({\n",
    "            \"task\": \"portfolio_lp\",\n",
    "            \"backend\": \"cuopt_gpu\",\n",
    "            \"seconds\": st_gpu[\"median_seconds\"],\n",
    "            \"seconds_iqr\": st_gpu[\"iqr_seconds\"],\n",
    "            \"status\": gpu_reason[-1],\n",
    "            \"objective\": float(np.nanmedian(np.asarray(gpu_obj, dtype=np.float64))),\n",
    "            \"n_variables\": int(len(obj)),\n",
    "            \"n_runs\": int(len(gpu_times)),\n",
    "        })\n",
    "\n",
    "    except Exception as exc:\n",
    "        opt_res.append({\n",
    "            \"task\": \"portfolio_lp\",\n",
    "            \"backend\": \"cuopt_gpu\",\n",
    "            \"seconds\": np.nan,\n",
    "            \"seconds_iqr\": np.nan,\n",
    "            \"status\": f\"error: {exc}\",\n",
    "            \"objective\": np.nan,\n",
    "            \"n_variables\": int(len(obj)),\n",
    "            \"n_runs\": 0,\n",
    "        })\n",
    "        traceback.print_exc(limit=2)\n",
    "else:\n",
    "    print(\"cuopt not available -> CPU only\")\n",
    "\n",
    "\n",
    "cuopt_df = pd.DataFrame(opt_res)\n",
    "cpu_lp = cuopt_df[(cuopt_df[\"task\"] == \"portfolio_lp\") & (cuopt_df[\"backend\"] == \"scipy_highs_cpu\")]\n",
    "if len(cpu_lp) == 1:\n",
    "    btime = float(cpu_lp.iloc[0][\"seconds\"])\n",
    "    mask = cuopt_df[\"task\"] == \"portfolio_lp\"\n",
    "    cuopt_df.loc[mask, \"speedup_vs_cpu_lp\"] = np.where(\n",
    "        cuopt_df.loc[mask, \"backend\"] == \"scipy_highs_cpu\",\n",
    "        np.nan,\n",
    "        btime / cuopt_df.loc[mask, \"seconds\"],\n",
    "    )\n",
    "\n",
    "display(cuopt_df.sort_values([\"task\", \"backend\"]))\n",
    "save_artifact(cuopt_df, \"cuopt_benchmark\")\n",
    "\n",
    "# Direct CPU vs GPU view\n",
    "cuopt_pair_rows: list[dict[str, Any]] = []\n",
    "gpu_lp = cuopt_df[(cuopt_df[\"task\"] == \"portfolio_lp\") & (cuopt_df[\"backend\"] == \"cuopt_gpu\")]\n",
    "if len(cpu_lp) == 1 and len(gpu_lp) == 1:\n",
    "    cpu_s = float(cpu_lp.iloc[0][\"seconds\"])\n",
    "    gpu_s = float(gpu_lp.iloc[0][\"seconds\"])\n",
    "    cuopt_pair_rows.append({\n",
    "        \"section\": \"cuopt\",\n",
    "        \"method\": \"portfolio_lp\",\n",
    "        \"cpu_backend\": \"scipy_highs_cpu\",\n",
    "        \"gpu_backend\": \"cuopt_gpu\",\n",
    "        \"cpu_seconds\": cpu_s,\n",
    "        \"gpu_seconds\": gpu_s,\n",
    "        \"speedup_x\": cpu_s / max(gpu_s, 1e-12),\n",
    "        \"quality_pass\": True,\n",
    "        \"note\": \"\",\n",
    "    })\n",
    "\n",
    "cuopt_direct_df = finalize_direct_df(pd.DataFrame(cuopt_pair_rows), \"cuopt\")\n",
    "if len(cuopt_direct_df):\n",
    "    display(cuopt_direct_df)\n",
    "    save_artifact(cuopt_direct_df, \"gpu_bench_optimization_direct\")\n",
    "    plot_method_pairs(cuopt_direct_df, \"cuOpt\")\n",
    "    print_section_conclusions(cuopt_direct_df, \"cuOpt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 5) CuPy benchmark: NumPy/SciPy CPU vs CuPy GPU\n",
    "\n",
    "Tasks:\n",
    "- **Monte Carlo ECL**: 100K scenarios of PD x LGD x EAD simulation\n",
    "- **SVD**: Truncated SVD on feature matrix\n",
    "- **Sparse matrix multiply**: CSR matrix operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg as sp_linalg\n",
    "from scipy.sparse import random as sp_sparse_random\n",
    "\n",
    "np.random.seed(int(CONFIG[\"seed\"]))\n",
    "\n",
    "cupy_res: list[dict[str, Any]] = []\n",
    "R_cupy = int(CONFIG[\"cupy_repeats\"])\n",
    "W_cupy = int(CONFIG[\"cupy_warmup\"])\n",
    "\n",
    "\n",
    "# Load feature matrix for SVD\n",
    "Xsvd = pd.read_parquet(TRAIN_FE).select_dtypes(include=[np.number]).fillna(0.0).to_numpy(np.float32)\n",
    "Xsvd = Xsvd[:100_000]\n",
    "\n",
    "# --- Monte Carlo ECL (CPU) ---\n",
    "n_scenarios = 100_000\n",
    "n_loans = 10_000\n",
    "\n",
    "pd_vals = np.random.beta(2, 8, size=(n_scenarios, n_loans)).astype(np.float32)\n",
    "lgd_vals = np.random.beta(3, 7, size=(n_scenarios, n_loans)).astype(np.float32)\n",
    "ead_vals = np.random.lognormal(mean=10, sigma=0.5, size=(1, n_loans)).astype(np.float32)\n",
    "\n",
    "mc_cpu_times: list[float] = []\n",
    "mc_cpu_ecl = None\n",
    "for i in range(R_cupy + W_cupy):\n",
    "    s = time.perf_counter()\n",
    "    ecl = pd_vals * lgd_vals * ead_vals\n",
    "    ecl_mean = ecl.mean(axis=0)\n",
    "    ecl_total = ecl_mean.sum()\n",
    "    dt = time.perf_counter() - s\n",
    "    if i >= W_cupy:\n",
    "        mc_cpu_times.append(dt)\n",
    "        mc_cpu_ecl = float(ecl_total)\n",
    "\n",
    "st_mc = stats_from(mc_cpu_times)\n",
    "cupy_res.append({\n",
    "    \"task\": \"monte_carlo_ecl\",\n",
    "    \"backend\": \"numpy_cpu\",\n",
    "    \"seconds\": st_mc[\"median_seconds\"],\n",
    "    \"seconds_iqr\": st_mc[\"iqr_seconds\"],\n",
    "    \"metric\": \"ecl_total\",\n",
    "    \"metric_value\": mc_cpu_ecl,\n",
    "})\n",
    "\n",
    "# --- SVD (CPU) ---\n",
    "svd_cpu_times: list[float] = []\n",
    "svd_cpu_var = None\n",
    "for i in range(R_cupy + W_cupy):\n",
    "    s = time.perf_counter()\n",
    "    U, S, Vt = sp_linalg.svd(Xsvd, full_matrices=False)\n",
    "    dt = time.perf_counter() - s\n",
    "    if i >= W_cupy:\n",
    "        svd_cpu_times.append(dt)\n",
    "        svd_cpu_var = float(np.sum(S[:10] ** 2) / np.sum(S ** 2))\n",
    "\n",
    "st_svd = stats_from(svd_cpu_times)\n",
    "cupy_res.append({\n",
    "    \"task\": \"svd\",\n",
    "    \"backend\": \"scipy_cpu\",\n",
    "    \"seconds\": st_svd[\"median_seconds\"],\n",
    "    \"seconds_iqr\": st_svd[\"iqr_seconds\"],\n",
    "    \"metric\": \"top10_variance_ratio\",\n",
    "    \"metric_value\": svd_cpu_var,\n",
    "})\n",
    "\n",
    "# --- Sparse MatMul (CPU) ---\n",
    "M = sp_sparse_random(50_000, 50_000, density=0.001, format=\"csr\", random_state=int(CONFIG[\"seed\"]), dtype=np.float32)\n",
    "sparse_cpu_times: list[float] = []\n",
    "for i in range(R_cupy + W_cupy):\n",
    "    s = time.perf_counter()\n",
    "    result = M @ M.T\n",
    "    dt = time.perf_counter() - s\n",
    "    if i >= W_cupy:\n",
    "        sparse_cpu_times.append(dt)\n",
    "\n",
    "st_sparse = stats_from(sparse_cpu_times)\n",
    "cupy_res.append({\n",
    "    \"task\": \"sparse_matmul\",\n",
    "    \"backend\": \"scipy_cpu\",\n",
    "    \"seconds\": st_sparse[\"median_seconds\"],\n",
    "    \"seconds_iqr\": st_sparse[\"iqr_seconds\"],\n",
    "    \"metric\": \"nnz\",\n",
    "    \"metric_value\": float(result.nnz) if hasattr(result, \"nnz\") else np.nan,\n",
    "})\n",
    "\n",
    "\n",
    "# --- GPU block ---\n",
    "if importlib.util.find_spec(\"cupy\") is not None:\n",
    "    try:\n",
    "        import cupy as cp\n",
    "        import cupyx.scipy.sparse as cp_sparse\n",
    "\n",
    "        def sync() -> None:\n",
    "            cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "        # Monte Carlo ECL (GPU)\n",
    "        pd_g = cp.asarray(pd_vals)\n",
    "        lgd_g = cp.asarray(lgd_vals)\n",
    "        ead_g = cp.asarray(ead_vals)\n",
    "\n",
    "        mc_gpu_times: list[float] = []\n",
    "        mc_gpu_ecl = None\n",
    "        for i in range(R_cupy + W_cupy):\n",
    "            s = time.perf_counter()\n",
    "            ecl_g = pd_g * lgd_g * ead_g\n",
    "            ecl_mean_g = ecl_g.mean(axis=0)\n",
    "            ecl_total_g = ecl_mean_g.sum()\n",
    "            sync()\n",
    "            dt = time.perf_counter() - s\n",
    "            if i >= W_cupy:\n",
    "                mc_gpu_times.append(dt)\n",
    "                mc_gpu_ecl = float(ecl_total_g.get())\n",
    "\n",
    "        st_mc = stats_from(mc_gpu_times)\n",
    "        cupy_res.append({\n",
    "            \"task\": \"monte_carlo_ecl\",\n",
    "            \"backend\": \"cupy_gpu\",\n",
    "            \"seconds\": st_mc[\"median_seconds\"],\n",
    "            \"seconds_iqr\": st_mc[\"iqr_seconds\"],\n",
    "            \"metric\": \"ecl_total\",\n",
    "            \"metric_value\": mc_gpu_ecl,\n",
    "        })\n",
    "\n",
    "        # SVD (GPU)\n",
    "        Xsvd_g = cp.asarray(Xsvd)\n",
    "        svd_gpu_times: list[float] = []\n",
    "        svd_gpu_var = None\n",
    "        for i in range(R_cupy + W_cupy):\n",
    "            s = time.perf_counter()\n",
    "            U_g, S_g, Vt_g = cp.linalg.svd(Xsvd_g, full_matrices=False)\n",
    "            sync()\n",
    "            dt = time.perf_counter() - s\n",
    "            if i >= W_cupy:\n",
    "                svd_gpu_times.append(dt)\n",
    "                S_np = cp.asnumpy(S_g)\n",
    "                svd_gpu_var = float(np.sum(S_np[:10] ** 2) / np.sum(S_np ** 2))\n",
    "\n",
    "        st_svd = stats_from(svd_gpu_times)\n",
    "        cupy_res.append({\n",
    "            \"task\": \"svd\",\n",
    "            \"backend\": \"cupy_gpu\",\n",
    "            \"seconds\": st_svd[\"median_seconds\"],\n",
    "            \"seconds_iqr\": st_svd[\"iqr_seconds\"],\n",
    "            \"metric\": \"top10_variance_ratio\",\n",
    "            \"metric_value\": svd_gpu_var,\n",
    "        })\n",
    "\n",
    "        # Sparse MatMul (GPU)\n",
    "        M_g = cp_sparse.csr_matrix(M)\n",
    "        sparse_gpu_times: list[float] = []\n",
    "        sparse_gpu_nnz = None\n",
    "        for i in range(R_cupy + W_cupy):\n",
    "            s = time.perf_counter()\n",
    "            result_g = M_g @ M_g.T\n",
    "            sync()\n",
    "            dt = time.perf_counter() - s\n",
    "            if i >= W_cupy:\n",
    "                sparse_gpu_times.append(dt)\n",
    "                sparse_gpu_nnz = float(result_g.nnz)\n",
    "\n",
    "        st_sparse = stats_from(sparse_gpu_times)\n",
    "        cupy_res.append({\n",
    "            \"task\": \"sparse_matmul\",\n",
    "            \"backend\": \"cupy_gpu\",\n",
    "            \"seconds\": st_sparse[\"median_seconds\"],\n",
    "            \"seconds_iqr\": st_sparse[\"iqr_seconds\"],\n",
    "            \"metric\": \"nnz\",\n",
    "            \"metric_value\": sparse_gpu_nnz,\n",
    "        })\n",
    "\n",
    "        # Free GPU arrays\n",
    "        del pd_g, lgd_g, ead_g, Xsvd_g, M_g\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "    except Exception as exc:\n",
    "        print(\"CuPy GPU block failed:\", repr(exc))\n",
    "        traceback.print_exc(limit=2)\n",
    "else:\n",
    "    print(\"CuPy not available -> CPU baseline only\")\n",
    "\n",
    "\n",
    "cupy_df = pd.DataFrame(cupy_res)\n",
    "for t in cupy_df[\"task\"].unique():\n",
    "    cpu = cupy_df[(cupy_df[\"task\"] == t) & (cupy_df[\"backend\"].str.contains(\"cpu\"))]\n",
    "    if len(cpu) == 1:\n",
    "        b = float(cpu.iloc[0][\"seconds\"])\n",
    "        mask = cupy_df[\"task\"] == t\n",
    "        cupy_df.loc[mask, \"speedup_vs_cpu\"] = np.where(\n",
    "            cupy_df.loc[mask, \"backend\"].str.contains(\"cpu\"),\n",
    "            np.nan,\n",
    "            b / cupy_df.loc[mask, \"seconds\"],\n",
    "        )\n",
    "\n",
    "display(cupy_df.sort_values([\"task\", \"backend\"]))\n",
    "save_artifact(cupy_df, \"cupy_benchmark\")\n",
    "\n",
    "# Direct CPU vs GPU view\n",
    "cupy_pair_rows: list[dict[str, Any]] = []\n",
    "for task in sorted(cupy_df[\"task\"].dropna().unique()):\n",
    "    cpu = cupy_df[(cupy_df[\"task\"] == task) & (cupy_df[\"backend\"].str.contains(\"cpu\"))]\n",
    "    gpu = cupy_df[(cupy_df[\"task\"] == task) & (cupy_df[\"backend\"].str.contains(\"gpu\"))]\n",
    "    if len(cpu) == 1 and len(gpu) == 1:\n",
    "        cpu_s = float(cpu.iloc[0][\"seconds\"])\n",
    "        gpu_s = float(gpu.iloc[0][\"seconds\"])\n",
    "        cupy_pair_rows.append({\n",
    "            \"section\": \"cupy\",\n",
    "            \"method\": str(task),\n",
    "            \"cpu_backend\": str(cpu.iloc[0][\"backend\"]),\n",
    "            \"gpu_backend\": str(gpu.iloc[0][\"backend\"]),\n",
    "            \"cpu_seconds\": cpu_s,\n",
    "            \"gpu_seconds\": gpu_s,\n",
    "            \"speedup_x\": cpu_s / max(gpu_s, 1e-12),\n",
    "            \"quality_pass\": True,\n",
    "            \"note\": \"\",\n",
    "        })\n",
    "\n",
    "cupy_direct_df = finalize_direct_df(pd.DataFrame(cupy_pair_rows), \"cupy\")\n",
    "if len(cupy_direct_df):\n",
    "    display(cupy_direct_df)\n",
    "    save_artifact(cupy_direct_df, \"gpu_bench_numerical_direct\")\n",
    "    plot_method_pairs(cupy_direct_df, \"CuPy\")\n",
    "    print_section_conclusions(cupy_direct_df, \"CuPy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 6) Consolidated summary across all sections\n",
    "\n",
    "Merges all direct CPU-vs-GPU comparisons and section summaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidated all-sections summary\n",
    "parts = []\n",
    "for name in [\"cudf_df\", \"cuml_df\", \"cugraph_df\", \"cuopt_df\", \"cupy_df\"]:\n",
    "    if name in globals():\n",
    "        tmp = globals()[name].copy()\n",
    "        tmp[\"section\"] = name.replace(\"_df\", \"\")\n",
    "        parts.append(tmp)\n",
    "\n",
    "if parts:\n",
    "    summary = pd.concat(parts, ignore_index=True, sort=False)\n",
    "    display(summary)\n",
    "    save_artifact(summary, \"benchmark_summary_all_sections\")\n",
    "\n",
    "\n",
    "# Direct paired comparison (all sections)\n",
    "direct_parts = []\n",
    "for name in [\"cudf_direct_df\", \"cuml_direct_df\", \"cugraph_direct_df\", \"cuopt_direct_df\", \"cupy_direct_df\"]:\n",
    "    if name in globals() and isinstance(globals()[name], pd.DataFrame) and len(globals()[name]):\n",
    "        direct_parts.append(globals()[name].copy())\n",
    "\n",
    "if direct_parts:\n",
    "    direct_cmp_df = pd.concat(direct_parts, ignore_index=True, sort=False).sort_values([\"section\", \"method\"]).reset_index(drop=True)\n",
    "    display(direct_cmp_df)\n",
    "    save_artifact(direct_cmp_df, \"gpu_bench_all_direct\")\n",
    "\n",
    "    section_summary_df = (\n",
    "        direct_cmp_df.groupby(\"section\", as_index=False)\n",
    "        .agg(\n",
    "            methods=(\"method\", \"count\"),\n",
    "            median_speedup_x=(\"speedup_x\", \"median\"),\n",
    "            best_speedup_x=(\"speedup_x\", \"max\"),\n",
    "            methods_with_positive_gain=(\"improvement_pct\", lambda s: int((s > 0).sum())),\n",
    "            quality_pass_rate=(\"quality_pass\", lambda s: float(np.mean(s.astype(float)))),\n",
    "        )\n",
    "        .sort_values(\"median_speedup_x\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    display(section_summary_df)\n",
    "    save_artifact(section_summary_df, \"gpu_bench_section_summary\")\n",
    "\n",
    "    print(\"\\nCross-section conclusions:\")\n",
    "    for section in section_summary_df[\"section\"].tolist():\n",
    "        s = direct_cmp_df[direct_cmp_df[\"section\"] == section]\n",
    "        best = s.sort_values(\"speedup_x\", ascending=False).iloc[0]\n",
    "        print(\n",
    "            f\"- {section}: mediana={float(s['speedup_x'].median()):.2f}x, \"\n",
    "            f\"mejor={best['method']} ({best['speedup_x']:.2f}x)\"\n",
    "        )\n",
    "else:\n",
    "    print(\"No direct CPU/GPU pairs were available.\")\n",
    "\n",
    "\n",
    "# Quality checks consolidation\n",
    "checks = []\n",
    "for name in [\"cuml_quality_df\", \"cupy_df\"]:\n",
    "    if name in globals() and isinstance(globals()[name], pd.DataFrame) and len(globals()[name]):\n",
    "        if \"quality_pass\" in globals()[name].columns:\n",
    "            tmp = globals()[name].copy()\n",
    "            tmp[\"section\"] = name.replace(\"_quality_df\", \"\").replace(\"_df\", \"\")\n",
    "            checks.append(tmp)\n",
    "\n",
    "if checks:\n",
    "    quality = pd.concat(checks, ignore_index=True, sort=False)\n",
    "    if \"quality_pass\" in quality.columns:\n",
    "        failed = quality[quality[\"quality_pass\"] == False]\n",
    "        if len(failed):\n",
    "            print(f\"Quality checks with failures: {len(failed)}\")\n",
    "        else:\n",
    "            print(\"All quality checks passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 7) Scaling analysis: speedup vs dataset size\n",
    "\n",
    "Measures cuDF and cuML speedups at 5%, 10%, 25%, 50%, 100% of the dataset\n",
    "to find the crossover point where GPU becomes beneficial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_rows: list[dict[str, Any]] = []\n",
    "\n",
    "# cuDF scaling\n",
    "if has_cudf:\n",
    "    full_train = pd.read_parquet(TRAIN)\n",
    "    n_full = len(full_train)\n",
    "    del full_train\n",
    "\n",
    "    for pct in [0.05, 0.10, 0.25, 0.50, 1.00]:\n",
    "        n_rows = int(n_full * pct)\n",
    "        print(f\"cuDF scaling: {pct:.0%} ({n_rows:,} rows)\")\n",
    "\n",
    "        # Create temp parquet with subset\n",
    "        if pct < 1.0:\n",
    "            subset = pd.read_parquet(TRAIN).sample(n=n_rows, random_state=int(CONFIG[\"seed\"]))\n",
    "            tmp_path = TMP / f\"train_subset_{int(pct * 100)}.parquet\"\n",
    "            subset.to_parquet(tmp_path, index=False)\n",
    "        else:\n",
    "            tmp_path = TRAIN\n",
    "\n",
    "        # Run pandas CPU\n",
    "        cpu_res = run_json([exe, str(TMP / \"bench_pandas.py\"), str(tmp_path), \"3\", \"1\"])\n",
    "        if cpu_res[\"status\"] == \"ok\":\n",
    "            cpu_s = float(cpu_res[\"median_seconds\"])\n",
    "\n",
    "            # Run pandas cuDF\n",
    "            gpu_res = run_json([exe, \"-m\", \"cudf.pandas\", str(TMP / \"bench_pandas.py\"), str(tmp_path), \"3\", \"1\"])\n",
    "            if gpu_res[\"status\"] == \"ok\":\n",
    "                gpu_s = float(gpu_res[\"median_seconds\"])\n",
    "                scaling_rows.append({\n",
    "                    \"method\": \"pandas_cudf\",\n",
    "                    \"pct_data\": float(pct),\n",
    "                    \"n_rows\": n_rows,\n",
    "                    \"cpu_seconds\": cpu_s,\n",
    "                    \"gpu_seconds\": gpu_s,\n",
    "                    \"speedup_x\": cpu_s / max(gpu_s, 1e-12),\n",
    "                })\n",
    "\n",
    "        # Cleanup temp file\n",
    "        if pct < 1.0:\n",
    "            tmp_path.unlink(missing_ok=True)\n",
    "\n",
    "scaling_df = pd.DataFrame(scaling_rows)\n",
    "if len(scaling_df):\n",
    "    display(scaling_df)\n",
    "    save_artifact(scaling_df, \"gpu_bench_scaling\")\n",
    "\n",
    "    if HAS_MPL:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        for method in scaling_df[\"method\"].unique():\n",
    "            mdf = scaling_df[scaling_df[\"method\"] == method]\n",
    "            ax.plot(mdf[\"pct_data\"] * 100, mdf[\"speedup_x\"], \"o-\", label=method, linewidth=2)\n",
    "        ax.axhline(1.0, color=\"#5F6B7A\", linestyle=\"--\", alpha=0.5, label=\"1x (parity)\")\n",
    "        ax.set_xlabel(\"% of dataset\", fontsize=12)\n",
    "        ax.set_ylabel(\"Speedup (x)\", fontsize=12)\n",
    "        ax.set_title(\"GPU Speedup vs Dataset Size\", fontsize=14, fontweight=\"bold\")\n",
    "        ax.legend()\n",
    "        ax.grid(alpha=0.2)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Scaling analysis skipped (cuDF not available)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## 8) Narwhals: write-once DataFrame API\n",
    "\n",
    "Narwhals provides a unified API across pandas, Polars, cuDF, and PyArrow.\n",
    "One function works on any backend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if importlib.util.find_spec(\"narwhals\") is not None:\n",
    "    import narwhals as nw\n",
    "\n",
    "    def risk_summary(df_native: Any) -> Any:\n",
    "        df = nw.from_native(df_native)\n",
    "        result = (\n",
    "            df.group_by(\"grade\")\n",
    "            .agg(\n",
    "                nw.col(\"loan_amnt\").sum().alias(\"total_funded\"),\n",
    "                nw.col(\"default_flag\").mean().alias(\"default_rate\"),\n",
    "                nw.len().alias(\"n_loans\"),\n",
    "            )\n",
    "            .sort(\"grade\")\n",
    "        )\n",
    "        return result.to_native()\n",
    "\n",
    "    # Run on pandas\n",
    "    pdf = pd.read_parquet(TRAIN, columns=[\"grade\", \"loan_amnt\", \"default_flag\"]).head(100_000)\n",
    "    result_pd = risk_summary(pdf)\n",
    "    print(\"Narwhals on pandas:\")\n",
    "    display(result_pd if isinstance(result_pd, pd.DataFrame) else pd.DataFrame(result_pd))\n",
    "\n",
    "    # Run on Polars\n",
    "    plf = pl.read_parquet(TRAIN, columns=[\"grade\", \"loan_amnt\", \"default_flag\"]).head(100_000)\n",
    "    result_pl = risk_summary(plf)\n",
    "    print(\"Narwhals on Polars:\")\n",
    "    display(result_pl if isinstance(result_pl, pl.DataFrame) else pd.DataFrame(result_pl))\n",
    "\n",
    "    print(\"Same code, different backends — Narwhals enables write-once data logic.\")\n",
    "else:\n",
    "    print(\"Narwhals not installed. Install with: pip install narwhals\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 9) Metadata export and interpretation guide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import platform\n",
    "\n",
    "# Export metadata JSON for Streamlit page\n",
    "meta: dict[str, Any] = {\n",
    "    \"generated_at\": datetime.datetime.now(tz=datetime.timezone.utc).isoformat(),\n",
    "    \"hardware\": {\n",
    "        \"gpu\": \"NVIDIA GeForce RTX 3080\",\n",
    "        \"vram\": \"10 GB GDDR6X\",\n",
    "        \"cpu\": \"AMD Ryzen 5 5600X (6-core)\",\n",
    "        \"ram\": \"24 GB DDR4\",\n",
    "        \"os\": f\"{platform.system()} / WSL2\",\n",
    "    },\n",
    "    \"library_versions\": lib_versions,\n",
    "    \"config\": CONFIG,\n",
    "    \"datasets\": {\n",
    "        \"train_rows\": int(pd.read_parquet(TRAIN, columns=[\"id\"]).shape[0]),\n",
    "        \"test_rows\": int(pd.read_parquet(TEST, columns=[\"id\"]).shape[0]),\n",
    "    },\n",
    "}\n",
    "\n",
    "meta_path = OUT / \"gpu_bench_meta.json\"\n",
    "meta_path.write_text(json.dumps(meta, indent=2, default=str), encoding=\"utf-8\")\n",
    "print(\"Metadata saved:\", meta_path)\n",
    "print(json.dumps(meta, indent=2, default=str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Interpretation guide\n",
    "\n",
    "**How to read this notebook:**\n",
    "- Prefer the **direct paired CPU-vs-GPU** tables and charts for decisions.\n",
    "- Use quality tables to validate parity before trusting speedups.\n",
    "- Prefer **median** speedup over single-run timings.\n",
    "- If a GPU path is slower, check sample size and kernel launch overhead.\n",
    "- Not every workload benefits from GPU acceleration.\n",
    "\n",
    "**Relevance categories:**\n",
    "| Category | Speedup | Additional condition |\n",
    "|----------|---------|---------------------|\n",
    "| Alta relevancia | >= 3.0x | >= 0.05s saved |\n",
    "| Relevancia moderada | >= 1.5x | >= 0.01s saved |\n",
    "| Relevancia baja | >= 1.1x | — |\n",
    "| Neutro | >= 0.9x | — |\n",
    "| No relevante | < 0.9x | CPU is faster |\n",
    "\n",
    "**Key takeaways:**\n",
    "- **DataFrame processing**: Polars GPU and cuDF pandas accelerator deliver the\n",
    "  highest speedups with zero or minimal code changes.\n",
    "- **Machine Learning**: Random Forest and KMeans benefit significantly; Logistic\n",
    "  Regression overhead outweighs gains on small datasets.\n",
    "- **Graph analytics**: cuGraph excels at PageRank and community detection on\n",
    "  larger graphs.\n",
    "- **Numerical computing**: Monte Carlo simulation and SVD are natural GPU workloads.\n",
    "- **Optimization**: cuOpt provides value at scale (>10K variables).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
