{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Notebook 10 - RAPIDS + cuOpt Benchmark (Side Task)\n",
    "\n",
    "Objective: measure practical acceleration value from `cuDF`, `cuML`, `cuGraph`, `cuOpt` on Lending Club data.\n",
    "\n",
    "Scope boundary:\n",
    "- This notebook is independent from the canonical project pipeline.\n",
    "- It does not modify core project artifacts or acceptance gates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Official references (current docs)\n",
    "\n",
    "- RAPIDS install + platform support: https://docs.rapids.ai/install\n",
    "- cuDF pandas accelerator: https://docs.rapids.ai/api/cudf/stable/cudf_pandas/\n",
    "- cuDF + Polars GPU engine: https://docs.rapids.ai/api/cudf/stable/cudf_polars/usage/\n",
    "- cuML API: https://docs.rapids.ai/api/cuml/stable/api/\n",
    "- cuGraph API (including non-convergence handling): https://docs.rapids.ai/api/cugraph/stable/api_docs/api/cugraph/cugraph.pagerank/\n",
    "- nx-cugraph backend usage: https://docs.rapids.ai/api/cugraph/stable/nx_cugraph/\n",
    "- RMM CuPy allocator: https://docs.rapids.ai/api/rmm/nightly/python_api/\n",
    "- cuOpt LP Python API: https://docs.nvidia.com/cuopt/user-guide/latest/cuopt-python/lp-milp-examples.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import importlib.util\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "import textwrap\n",
    "import time\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def find_root(start: Path | None = None) -> Path:\n",
    "    cur = (start or Path.cwd()).resolve()\n",
    "    for p in [cur] + list(cur.parents):\n",
    "        if (p / \"data\").exists() and (p / \"notebooks\").exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\"No project root found\")\n",
    "\n",
    "\n",
    "ROOT = find_root()\n",
    "DATA = ROOT / \"data\" / \"processed\"\n",
    "OUT = ROOT / \"reports\" / \"gpu_benchmark\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN = DATA / \"train.parquet\"\n",
    "TEST = DATA / \"test.parquet\"\n",
    "TRAIN_FE = DATA / \"train_fe.parquet\"\n",
    "TEST_FE = DATA / \"test_fe.parquet\"\n",
    "\n",
    "CONFIG: dict[str, Any] = {\n",
    "    \"seed\": 42,\n",
    "    \"save_outputs\": False,\n",
    "    \"cudf_repeats\": 4,\n",
    "    \"cudf_warmup\": 1,\n",
    "    \"cuml_train_sample\": 250_000,\n",
    "    \"cuml_test_sample\": 100_000,\n",
    "    \"cuml_repeats_light\": 2,\n",
    "    \"cuml_repeats_heavy\": 1,\n",
    "    \"cugraph_sample_rows\": 30_000,\n",
    "    \"cugraph_repeats\": 3,\n",
    "    \"cuopt_sample_rows\": 18_000,\n",
    "    \"cuopt_repeats\": 3,\n",
    "    \"consistency_rel_tol\": 5e-3,\n",
    "    \"plot_per_method_charts\": True,\n",
    "}\n",
    "\n",
    "\n",
    "def stats_from(values: list[float]) -> dict[str, float]:\n",
    "    arr = np.asarray(values, dtype=np.float64)\n",
    "    if arr.size == 0:\n",
    "        return {\n",
    "            \"median_seconds\": np.nan,\n",
    "            \"mean_seconds\": np.nan,\n",
    "            \"std_seconds\": np.nan,\n",
    "            \"iqr_seconds\": np.nan,\n",
    "        }\n",
    "    q1, q3 = np.percentile(arr, [25, 75])\n",
    "    return {\n",
    "        \"median_seconds\": float(np.median(arr)),\n",
    "        \"mean_seconds\": float(np.mean(arr)),\n",
    "        \"std_seconds\": float(np.std(arr)),\n",
    "        \"iqr_seconds\": float(q3 - q1),\n",
    "    }\n",
    "\n",
    "\n",
    "def rel_err(a: float, b: float) -> float:\n",
    "    den = max(abs(a), 1e-12)\n",
    "    return float(abs(a - b) / den)\n",
    "\n",
    "\n",
    "def maybe_save(df: pd.DataFrame, name: str) -> None:\n",
    "    if CONFIG[\"save_outputs\"]:\n",
    "        out = OUT / name\n",
    "        df.to_csv(out, index=False)\n",
    "        print(\"Saved:\", out)\n",
    "\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    HAS_MPL = True\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "except Exception as exc:\n",
    "    HAS_MPL = False\n",
    "    print(\"matplotlib unavailable:\", repr(exc))\n",
    "\n",
    "\n",
    "CPU_COLOR = \"#A8B5C4\"\n",
    "GPU_GAIN_COLOR = \"#94C9B2\"\n",
    "GPU_LOSS_COLOR = \"#E8A7A7\"\n",
    "TEXT_SOFT = \"#5B6470\"\n",
    "\n",
    "\n",
    "def classify_relevance(speedup_x: float, seconds_saved: float, quality_pass: bool) -> str:\n",
    "    if not quality_pass:\n",
    "        return \"No concluyente (quality check fail)\"\n",
    "    if not np.isfinite(speedup_x):\n",
    "        return \"No disponible\"\n",
    "    if speedup_x >= 3.0 and seconds_saved >= 0.05:\n",
    "        return \"Alta relevancia\"\n",
    "    if speedup_x >= 1.5 and seconds_saved >= 0.01:\n",
    "        return \"Relevancia moderada\"\n",
    "    if speedup_x >= 1.1:\n",
    "        return \"Relevancia baja\"\n",
    "    if speedup_x >= 0.9:\n",
    "        return \"Neutro\"\n",
    "    return \"No relevante (CPU mejor)\"\n",
    "\n",
    "\n",
    "def finalize_direct_df(df: pd.DataFrame, section_name: str) -> pd.DataFrame:\n",
    "    if df is None or len(df) == 0:\n",
    "        print(f\"[{section_name}] No direct CPU/GPU pairs available.\")\n",
    "        return pd.DataFrame()\n",
    "    out = df.copy()\n",
    "    out[\"improvement_pct\"] = (out[\"speedup_x\"] - 1.0) * 100.0\n",
    "    out[\"seconds_saved\"] = out[\"cpu_seconds\"] - out[\"gpu_seconds\"]\n",
    "    out[\"relevance\"] = [\n",
    "        classify_relevance(sp, ss, qp)\n",
    "        for sp, ss, qp in zip(\n",
    "            out[\"speedup_x\"].to_numpy(np.float64),\n",
    "            out[\"seconds_saved\"].to_numpy(np.float64),\n",
    "            out[\"quality_pass\"].to_numpy(bool),\n",
    "            strict=False,\n",
    "        )\n",
    "    ]\n",
    "    order = [\n",
    "        \"section\",\n",
    "        \"method\",\n",
    "        \"cpu_backend\",\n",
    "        \"gpu_backend\",\n",
    "        \"cpu_seconds\",\n",
    "        \"gpu_seconds\",\n",
    "        \"speedup_x\",\n",
    "        \"improvement_pct\",\n",
    "        \"seconds_saved\",\n",
    "        \"quality_pass\",\n",
    "        \"relevance\",\n",
    "        \"note\",\n",
    "    ]\n",
    "    keep = [c for c in order if c in out.columns]\n",
    "    return out[keep].sort_values([\"section\", \"method\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def plot_method_pairs(direct_df: pd.DataFrame, section_title: str) -> None:\n",
    "    if not bool(CONFIG.get(\"plot_per_method_charts\", True)):\n",
    "        return\n",
    "    if not HAS_MPL or direct_df is None or len(direct_df) == 0:\n",
    "        return\n",
    "    print(f\"{section_title}: gráficos CPU vs GPU por método\")\n",
    "    for _, r in direct_df.iterrows():\n",
    "        method = str(r[\"method\"])\n",
    "        cpu_s = float(r[\"cpu_seconds\"])\n",
    "        gpu_s = float(r[\"gpu_seconds\"])\n",
    "        speedup = float(r[\"speedup_x\"])\n",
    "        improvement = float(r[\"improvement_pct\"])\n",
    "        qpass = bool(r[\"quality_pass\"])\n",
    "        relevance = str(r[\"relevance\"])\n",
    "        note = str(r.get(\"note\", \"\")).strip()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8.6, 4.2))\n",
    "        gpu_color = GPU_GAIN_COLOR if improvement >= 0 else GPU_LOSS_COLOR\n",
    "        bars = ax.barh([\"CPU\", \"GPU\"], [cpu_s, gpu_s], color=[CPU_COLOR, gpu_color], height=0.56)\n",
    "\n",
    "        positive = [v for v in [cpu_s, gpu_s] if np.isfinite(v) and v > 0]\n",
    "        if len(positive) == 2 and max(positive) / min(positive) >= 30:\n",
    "            ax.set_xscale(\"log\")\n",
    "            ax.set_xlabel(\"Median seconds (log scale)\")\n",
    "        else:\n",
    "            ax.set_xlabel(\"Median seconds\")\n",
    "\n",
    "        xmax = max(positive) if positive else 1.0\n",
    "        ax.set_xlim(0, xmax * 1.35 if np.isfinite(xmax) else 1.0)\n",
    "        for b, v in zip(bars, [cpu_s, gpu_s], strict=False):\n",
    "            ax.text(\n",
    "                b.get_width() + xmax * 0.025,\n",
    "                b.get_y() + b.get_height() / 2,\n",
    "                f\"{v:.4f}s\",\n",
    "                ha=\"left\",\n",
    "                va=\"center\",\n",
    "                fontsize=10,\n",
    "                color=\"#374151\",\n",
    "            )\n",
    "\n",
    "        ax.set_title(\n",
    "            f\"{section_title} | {method}\", loc=\"left\", fontsize=13, fontweight=\"bold\", pad=14\n",
    "        )\n",
    "        subtitle = (\n",
    "            f\"speedup={speedup:.2f}x | improvement={improvement:+.1f}% | \"\n",
    "            f\"quality_pass={qpass} | {relevance}\"\n",
    "        )\n",
    "        ax.text(\n",
    "            0.00, 1.02, subtitle, transform=ax.transAxes, fontsize=10, color=TEXT_SOFT, va=\"bottom\"\n",
    "        )\n",
    "        if note:\n",
    "            ax.text(\n",
    "                0.00,\n",
    "                -0.24,\n",
    "                f\"detalle: {note[:120]}\",\n",
    "                transform=ax.transAxes,\n",
    "                fontsize=9,\n",
    "                color=TEXT_SOFT,\n",
    "            )\n",
    "\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.grid(axis=\"x\", alpha=0.18)\n",
    "        fig.subplots_adjust(left=0.16, right=0.96, top=0.80, bottom=0.24)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def print_section_conclusions(direct_df: pd.DataFrame, section_title: str) -> None:\n",
    "    if direct_df is None or len(direct_df) == 0:\n",
    "        return\n",
    "    best = direct_df.sort_values(\"speedup_x\", ascending=False).iloc[0]\n",
    "    worst = direct_df.sort_values(\"speedup_x\", ascending=True).iloc[0]\n",
    "    pass_rate = float(direct_df[\"quality_pass\"].mean())\n",
    "    print(\n",
    "        f\"{section_title} conclusions: \"\n",
    "        f\"median speedup={float(direct_df['speedup_x'].median()):.2f}x, \"\n",
    "        f\"best={best['method']} ({best['speedup_x']:.2f}x), \"\n",
    "        f\"worst={worst['method']} ({worst['speedup_x']:.2f}x), \"\n",
    "        f\"quality_pass_rate={pass_rate:.2f}\"\n",
    "    )\n",
    "    for _, r in direct_df.sort_values(\"speedup_x\", ascending=False).iterrows():\n",
    "        print(\n",
    "            f\"- {r['method']}: {r['speedup_x']:.2f}x ({r['improvement_pct']:+.1f}%), \"\n",
    "            f\"{r['relevance']}\"\n",
    "        )\n",
    "\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"save_outputs:\", CONFIG[\"save_outputs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Environment and data checks\n",
    "\n",
    "Notes:\n",
    "- This notebook expects a RAPIDS-capable environment (Linux/WSL2 + NVIDIA GPU).\n",
    "- CSV export is optional and disabled by default (`CONFIG[\"save_outputs\"] = False`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardware + package checks\n",
    "\n",
    "\n",
    "def run(cmd: list[str]) -> tuple[int, str, str]:\n",
    "    p = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    return p.returncode, p.stdout, p.stderr\n",
    "\n",
    "\n",
    "code, out, err = run([\"nvidia-smi\"])\n",
    "print(out if code == 0 else err)\n",
    "\n",
    "pkgs = [\n",
    "    \"cudf\",\n",
    "    \"cuml\",\n",
    "    \"cugraph\",\n",
    "    \"nx_cugraph\",\n",
    "    \"cuopt\",\n",
    "    \"cupy\",\n",
    "    \"rmm\",\n",
    "    \"networkx\",\n",
    "    \"scipy\",\n",
    "    \"sklearn\",\n",
    "    \"polars\",\n",
    "    \"pandas\",\n",
    "]\n",
    "rows = []\n",
    "for p in pkgs:\n",
    "    spec = importlib.util.find_spec(p)\n",
    "    ver = None\n",
    "    if spec is not None:\n",
    "        try:\n",
    "            mod = __import__(p)\n",
    "            ver = getattr(mod, \"__version__\", None)\n",
    "        except Exception:\n",
    "            ver = \"import_error\"\n",
    "    rows.append({\"package\": p, \"available\": spec is not None, \"version\": ver})\n",
    "display(pd.DataFrame(rows))\n",
    "\n",
    "# 10GB VRAM-safe RMM pool for RTX 3080 style cards\n",
    "try:\n",
    "    import cupy as cp\n",
    "    import rmm\n",
    "\n",
    "    rmm.reinitialize(pool_allocator=True, managed_memory=False, initial_pool_size=6 * 1024**3)\n",
    "\n",
    "    alloc = None\n",
    "    try:\n",
    "        from rmm.allocators.cupy import rmm_cupy_allocator\n",
    "\n",
    "        alloc = rmm_cupy_allocator\n",
    "    except Exception:\n",
    "        alloc = getattr(rmm, \"rmm_cupy_allocator\", None)\n",
    "\n",
    "    if alloc is not None:\n",
    "        cp.cuda.set_allocator(alloc)\n",
    "        print(\"RMM configured with CuPy allocator\")\n",
    "    else:\n",
    "        print(\"RMM configured, but CuPy allocator binding not found\")\n",
    "except Exception as exc:\n",
    "    print(\"RMM setup skipped:\", repr(exc))\n",
    "\n",
    "for p in [TRAIN, TEST, TRAIN_FE, TEST_FE]:\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing required file: {p}\")\n",
    "\n",
    "summary = []\n",
    "for p in [TRAIN, TEST, TRAIN_FE, TEST_FE]:\n",
    "    d = pd.read_parquet(p, columns=[\"id\", \"default_flag\"])\n",
    "    summary.append(\n",
    "        {\n",
    "            \"file\": str(p.relative_to(ROOT)),\n",
    "            \"rows\": int(len(d)),\n",
    "            \"default_rate\": float(d[\"default_flag\"].mean()),\n",
    "        }\n",
    "    )\n",
    "display(pd.DataFrame(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 1) cuDF benchmark (paired consistency checks)\n",
    "\n",
    "Compared modes:\n",
    "- `pandas_cpu`\n",
    "- `pandas_cudf` via `python -m cudf.pandas`\n",
    "- `polars_cpu`\n",
    "- `polars_cudf` via `pl.GPUEngine`\n",
    "\n",
    "Benchmark quality checks:\n",
    "- Row-count parity against `pandas_cpu`\n",
    "- Checksum relative error tolerance (`CONFIG[\"consistency_rel_tol\"]`)\n",
    "- Dedicated CPU-vs-GPU chart per method in this same section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP = OUT / \"tmp_scripts\"\n",
    "TMP.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pandas_script = textwrap.dedent(r\"\"\"\n",
    "import json, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = sys.argv[1]\n",
    "repeats = int(sys.argv[2])\n",
    "warmup = int(sys.argv[3])\n",
    "cols = [\"id\",\"issue_d\",\"loan_amnt\",\"int_rate\",\"annual_inc\",\"term\",\"grade\",\"purpose\",\"default_flag\"]\n",
    "\n",
    "def run_once():\n",
    "    df = pd.read_parquet(path, columns=cols)\n",
    "    df[\"int_rate\"] = pd.to_numeric(df[\"int_rate\"].astype(str).str.rstrip(\"%\"), errors=\"coerce\")\n",
    "    df[\"term_m\"] = pd.to_numeric(df[\"term\"].astype(str).str.extract(r\"(\\d+)\")[0], errors=\"coerce\")\n",
    "    df[\"issue_d\"] = pd.to_datetime(df[\"issue_d\"], errors=\"coerce\")\n",
    "    df[\"issue_year\"] = df[\"issue_d\"].dt.year.astype(\"Int64\")\n",
    "\n",
    "    f = df[(df[\"loan_amnt\"] >= 5000) & (df[\"annual_inc\"] > 20000) & (df[\"term_m\"].isin([36, 60]))]\n",
    "    a = f.groupby([\"grade\", \"issue_year\"], dropna=False).agg(\n",
    "        loans=(\"id\", \"count\"), funded=(\"loan_amnt\", \"sum\"), dr=(\"default_flag\", \"mean\")\n",
    "    ).reset_index()\n",
    "    b = f.groupby(\"purpose\", dropna=False).agg(\n",
    "        p_loans=(\"id\", \"count\"), p_dr=(\"default_flag\", \"mean\")\n",
    "    ).reset_index()\n",
    "    g = f[[\"grade\", \"purpose\"]].drop_duplicates(\"grade\")\n",
    "    z = a.merge(g, on=\"grade\", how=\"left\").merge(b, on=\"purpose\", how=\"left\")\n",
    "    z[\"checksum_col\"] = z[\"dr\"].fillna(0.0) * z[\"funded\"].fillna(0.0)\n",
    "    z = z.sort_values([\"issue_year\", \"grade\"]).head(5000)\n",
    "    return z\n",
    "\n",
    "t = []\n",
    "out = None\n",
    "for i in range(repeats + warmup):\n",
    "    s = time.perf_counter()\n",
    "    out = run_once()\n",
    "    dt = time.perf_counter() - s\n",
    "    if i >= warmup:\n",
    "        t.append(dt)\n",
    "\n",
    "arr = np.asarray(t, dtype=np.float64)\n",
    "q1, q3 = np.percentile(arr, [25, 75])\n",
    "print(json.dumps({\n",
    "    \"median_seconds\": float(np.median(arr)),\n",
    "    \"mean_seconds\": float(np.mean(arr)),\n",
    "    \"std_seconds\": float(np.std(arr)),\n",
    "    \"iqr_seconds\": float(q3 - q1),\n",
    "    \"rows_out\": int(len(out)),\n",
    "    \"checksum\": float(out[\"checksum_col\"].sum()),\n",
    "}))\n",
    "\"\"\").strip()\n",
    "\n",
    "polars_script = textwrap.dedent(r\"\"\"\n",
    "import json, sys, time\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "path = sys.argv[1]\n",
    "repeats = int(sys.argv[2])\n",
    "warmup = int(sys.argv[3])\n",
    "mode = sys.argv[4]\n",
    "\n",
    "def run_once(mode):\n",
    "    lf = pl.scan_parquet(path).select([\n",
    "        \"id\", \"issue_d\", \"loan_amnt\", \"int_rate\", \"annual_inc\", \"term\", \"grade\", \"purpose\", \"default_flag\"\n",
    "    ])\n",
    "    lf = lf.with_columns([\n",
    "        pl.col(\"int_rate\").cast(pl.Utf8).str.replace(\"%\", \"\", literal=True).cast(pl.Float64, strict=False),\n",
    "        pl.col(\"term\").cast(pl.Utf8).str.extract(r\"(\\d+)\", group_index=1).cast(pl.Int32, strict=False).alias(\"term_m\"),\n",
    "        pl.col(\"issue_d\").cast(pl.Date, strict=False),\n",
    "    ]).with_columns(pl.col(\"issue_d\").dt.year().alias(\"issue_year\"))\n",
    "\n",
    "    f = lf.filter((pl.col(\"loan_amnt\") >= 5000) & (pl.col(\"annual_inc\") > 20000) & (pl.col(\"term_m\").is_in([36, 60])))\n",
    "    a = f.group_by([\"grade\", \"issue_year\"]).agg([\n",
    "        pl.len().alias(\"loans\"),\n",
    "        pl.sum(\"loan_amnt\").alias(\"funded\"),\n",
    "        pl.mean(\"default_flag\").alias(\"dr\"),\n",
    "    ])\n",
    "    b = f.group_by(\"purpose\").agg([\n",
    "        pl.len().alias(\"p_loans\"),\n",
    "        pl.mean(\"default_flag\").alias(\"p_dr\"),\n",
    "    ])\n",
    "    g = f.select([\"grade\", \"purpose\"]).unique(subset=[\"grade\"], keep=\"first\")\n",
    "\n",
    "    z = (\n",
    "        a.join(g, on=\"grade\", how=\"left\")\n",
    "         .join(b, on=\"purpose\", how=\"left\")\n",
    "         .with_columns((pl.col(\"dr\").fill_null(0.0) * pl.col(\"funded\").fill_null(0.0)).alias(\"checksum_col\"))\n",
    "         .sort([\"issue_year\", \"grade\"])\n",
    "         .limit(5000)\n",
    "    )\n",
    "\n",
    "    if mode == \"gpu\":\n",
    "        if not hasattr(pl, \"GPUEngine\"):\n",
    "            raise RuntimeError(\"Polars GPUEngine is not available\")\n",
    "        out = z.collect(engine=pl.GPUEngine(raise_on_fail=True))\n",
    "    else:\n",
    "        out = z.collect()\n",
    "    return out\n",
    "\n",
    "t = []\n",
    "out = None\n",
    "for i in range(repeats + warmup):\n",
    "    s = time.perf_counter()\n",
    "    out = run_once(mode)\n",
    "    dt = time.perf_counter() - s\n",
    "    if i >= warmup:\n",
    "        t.append(dt)\n",
    "\n",
    "arr = np.asarray(t, dtype=np.float64)\n",
    "q1, q3 = np.percentile(arr, [25, 75])\n",
    "print(json.dumps({\n",
    "    \"median_seconds\": float(np.median(arr)),\n",
    "    \"mean_seconds\": float(np.mean(arr)),\n",
    "    \"std_seconds\": float(np.std(arr)),\n",
    "    \"iqr_seconds\": float(q3 - q1),\n",
    "    \"rows_out\": int(out.height),\n",
    "    \"checksum\": float(out[\"checksum_col\"].sum()),\n",
    "}))\n",
    "\"\"\").strip()\n",
    "\n",
    "(TMP / \"bench_pandas.py\").write_text(pandas_script + \"\\n\", encoding=\"utf-8\")\n",
    "(TMP / \"bench_polars.py\").write_text(polars_script + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def run_json(cmd: list[str]) -> dict[str, Any]:\n",
    "    p = subprocess.run(cmd, cwd=str(ROOT), capture_output=True, text=True)\n",
    "    res: dict[str, Any] = {\n",
    "        \"command\": \" \".join(cmd),\n",
    "        \"status\": \"ok\" if p.returncode == 0 else \"error\",\n",
    "        \"returncode\": p.returncode,\n",
    "        \"stderr_tail\": p.stderr[-800:],\n",
    "    }\n",
    "    if p.returncode == 0:\n",
    "        try:\n",
    "            payload = json.loads(p.stdout.strip().splitlines()[-1])\n",
    "            res.update(payload)\n",
    "        except Exception as exc:\n",
    "            res[\"status\"] = \"error\"\n",
    "            res[\"parse_error\"] = repr(exc)\n",
    "    return res\n",
    "\n",
    "\n",
    "R = int(CONFIG[\"cudf_repeats\"])\n",
    "W = int(CONFIG[\"cudf_warmup\"])\n",
    "exe = sys.executable\n",
    "\n",
    "plan: list[tuple[str, list[str]]] = [\n",
    "    (\"pandas_cpu\", [exe, str(TMP / \"bench_pandas.py\"), str(TRAIN), str(R), str(W)]),\n",
    "    (\"polars_cpu\", [exe, str(TMP / \"bench_polars.py\"), str(TRAIN), str(R), str(W), \"cpu\"]),\n",
    "]\n",
    "\n",
    "has_cudf = importlib.util.find_spec(\"cudf\") is not None\n",
    "if has_cudf:\n",
    "    plan.append(\n",
    "        (\n",
    "            \"pandas_cudf\",\n",
    "            [exe, \"-m\", \"cudf.pandas\", str(TMP / \"bench_pandas.py\"), str(TRAIN), str(R), str(W)],\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping pandas_cudf: cudf not available\")\n",
    "\n",
    "if has_cudf and hasattr(pl, \"GPUEngine\"):\n",
    "    plan.append(\n",
    "        (\"polars_cudf\", [exe, str(TMP / \"bench_polars.py\"), str(TRAIN), str(R), str(W), \"gpu\"])\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping polars_cudf: cudf and/or pl.GPUEngine not available\")\n",
    "\n",
    "rows = []\n",
    "for mode, cmd in plan:\n",
    "    x = run_json(cmd)\n",
    "    x[\"mode\"] = mode\n",
    "    rows.append(x)\n",
    "\n",
    "cudf_df = pd.DataFrame(rows)\n",
    "\n",
    "ok = cudf_df[cudf_df[\"status\"] == \"ok\"]\n",
    "base = ok.loc[ok[\"mode\"] == \"pandas_cpu\", \"median_seconds\"]\n",
    "if len(base) == 1:\n",
    "    b = float(base.iloc[0])\n",
    "    cudf_df[\"speedup_vs_pandas_cpu\"] = np.where(\n",
    "        cudf_df[\"status\"] == \"ok\",\n",
    "        b / cudf_df[\"median_seconds\"],\n",
    "        np.nan,\n",
    "    )\n",
    "\n",
    "base_rows = ok.loc[ok[\"mode\"] == \"pandas_cpu\", \"rows_out\"]\n",
    "base_checksum = ok.loc[ok[\"mode\"] == \"pandas_cpu\", \"checksum\"]\n",
    "if len(base_rows) == 1 and len(base_checksum) == 1:\n",
    "    br = int(base_rows.iloc[0])\n",
    "    bc = float(base_checksum.iloc[0])\n",
    "    cudf_df[\"rows_match_cpu\"] = np.where(\n",
    "        cudf_df[\"status\"] == \"ok\", cudf_df[\"rows_out\"] == br, np.nan\n",
    "    )\n",
    "    cudf_df[\"checksum_rel_err_cpu\"] = np.where(\n",
    "        cudf_df[\"status\"] == \"ok\",\n",
    "        np.abs(cudf_df[\"checksum\"] - bc) / max(abs(bc), 1e-12),\n",
    "        np.nan,\n",
    "    )\n",
    "    cudf_df[\"consistency_pass\"] = np.where(\n",
    "        cudf_df[\"status\"] == \"ok\",\n",
    "        (cudf_df[\"rows_match_cpu\"] == True)\n",
    "        & (cudf_df[\"checksum_rel_err_cpu\"] <= CONFIG[\"consistency_rel_tol\"]),\n",
    "        np.nan,\n",
    "    )\n",
    "\n",
    "display(cudf_df.sort_values(\"mode\"))\n",
    "maybe_save(cudf_df, \"cudf_polars_benchmark.csv\")\n",
    "\n",
    "# Direct CPU vs GPU view for cuDF section\n",
    "cudf_pair_rows: list[dict[str, Any]] = []\n",
    "for method, cpu_mode, gpu_mode in [\n",
    "    (\"pandas_query_pipeline\", \"pandas_cpu\", \"pandas_cudf\"),\n",
    "    (\"polars_query_pipeline\", \"polars_cpu\", \"polars_cudf\"),\n",
    "]:\n",
    "    cpu = cudf_df[(cudf_df[\"mode\"] == cpu_mode) & (cudf_df[\"status\"] == \"ok\")]\n",
    "    gpu = cudf_df[(cudf_df[\"mode\"] == gpu_mode) & (cudf_df[\"status\"] == \"ok\")]\n",
    "    if len(cpu) == 1 and len(gpu) == 1:\n",
    "        cudf_pair_rows.append(\n",
    "            {\n",
    "                \"section\": \"cudf\",\n",
    "                \"method\": method,\n",
    "                \"cpu_backend\": cpu_mode,\n",
    "                \"gpu_backend\": gpu_mode,\n",
    "                \"cpu_seconds\": float(cpu.iloc[0][\"median_seconds\"]),\n",
    "                \"gpu_seconds\": float(gpu.iloc[0][\"median_seconds\"]),\n",
    "                \"speedup_x\": float(cpu.iloc[0][\"median_seconds\"])\n",
    "                / max(float(gpu.iloc[0][\"median_seconds\"]), 1e-12),\n",
    "                \"quality_pass\": bool(gpu.iloc[0].get(\"consistency_pass\", False)),\n",
    "                \"note\": f\"checksum_rel_err={gpu.iloc[0].get('checksum_rel_err_cpu', np.nan)}\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "cudf_direct_df = finalize_direct_df(pd.DataFrame(cudf_pair_rows), \"cudf\")\n",
    "if len(cudf_direct_df):\n",
    "    display(cudf_direct_df)\n",
    "    plot_method_pairs(cudf_direct_df, \"cuDF\")\n",
    "    print_section_conclusions(cudf_direct_df, \"cuDF\")\n",
    "    maybe_save(cudf_direct_df, \"direct_cpu_vs_gpu_cudf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 2) cuML benchmark (speed + quality parity)\n",
    "\n",
    "Compared models:\n",
    "- Logistic Regression (`sklearn` vs `cuml`)\n",
    "- Random Forest (`sklearn` vs `cuml`)\n",
    "- KMeans (`sklearn` vs `cuml`)\n",
    "\n",
    "Additional checks:\n",
    "- Metric deltas (`AUC`, `silhouette`) CPU vs GPU\n",
    "- Per-task tolerance gates\n",
    "- Dedicated CPU-vs-GPU chart per method in this same section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans as SKKMeans\n",
    "from sklearn.ensemble import RandomForestClassifier as SKRF\n",
    "from sklearn.linear_model import LogisticRegression as SKLR\n",
    "from sklearn.metrics import roc_auc_score, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(int(CONFIG[\"seed\"]))\n",
    "\n",
    "train = pd.read_parquet(TRAIN_FE)\n",
    "test = pd.read_parquet(TEST_FE)\n",
    "\n",
    "num = [\n",
    "    \"loan_amnt\",\n",
    "    \"int_rate\",\n",
    "    \"installment\",\n",
    "    \"annual_inc\",\n",
    "    \"dti\",\n",
    "    \"loan_to_income\",\n",
    "    \"installment_burden\",\n",
    "    \"rev_utilization\",\n",
    "    \"revol_bal_to_income\",\n",
    "    \"open_acc_ratio\",\n",
    "    \"fico_score\",\n",
    "    \"credit_age_years\",\n",
    "    \"emp_length_num\",\n",
    "    \"open_acc\",\n",
    "    \"total_acc\",\n",
    "    \"revol_bal\",\n",
    "    \"pub_rec\",\n",
    "    \"inq_last_6mths\",\n",
    "    \"mort_acc\",\n",
    "    \"delinq_severity\",\n",
    "    \"delinq_recency\",\n",
    "    \"il_ratio\",\n",
    "    \"high_util_pct\",\n",
    "    \"log_annual_inc\",\n",
    "    \"log_revol_bal\",\n",
    "    \"loan_to_income_sq\",\n",
    "    \"fico_x_dti\",\n",
    "]\n",
    "feat = [c for c in num if c in train.columns and c in test.columns]\n",
    "if not feat:\n",
    "    raise RuntimeError(\"No overlapping numeric features found for cuML benchmark\")\n",
    "\n",
    "train = train.sample(\n",
    "    n=min(int(CONFIG[\"cuml_train_sample\"]), len(train)), random_state=int(CONFIG[\"seed\"])\n",
    ").reset_index(drop=True)\n",
    "test = test.sample(\n",
    "    n=min(int(CONFIG[\"cuml_test_sample\"]), len(test)), random_state=int(CONFIG[\"seed\"])\n",
    ").reset_index(drop=True)\n",
    "\n",
    "Xtr = train[feat].apply(pd.to_numeric, errors=\"coerce\").fillna(0.0).astype(np.float32)\n",
    "Xte = test[feat].apply(pd.to_numeric, errors=\"coerce\").fillna(0.0).astype(np.float32)\n",
    "ytr = train[\"default_flag\"].astype(np.int32)\n",
    "yte = test[\"default_flag\"].astype(np.int32)\n",
    "\n",
    "sc = StandardScaler()\n",
    "Xtr_s = sc.fit_transform(Xtr).astype(np.float32)\n",
    "Xte_s = sc.transform(Xte).astype(np.float32)\n",
    "\n",
    "\n",
    "res: list[dict[str, Any]] = []\n",
    "\n",
    "\n",
    "def push_result(\n",
    "    task: str,\n",
    "    backend: str,\n",
    "    fit_times: list[float],\n",
    "    pred_times: list[float],\n",
    "    metric: str,\n",
    "    values: list[float],\n",
    ") -> None:\n",
    "    st_fit = stats_from(fit_times)\n",
    "    st_pred = stats_from(pred_times)\n",
    "    arr = np.asarray(values, dtype=np.float64)\n",
    "    res.append(\n",
    "        {\n",
    "            \"task\": task,\n",
    "            \"backend\": backend,\n",
    "            \"fit_seconds\": st_fit[\"median_seconds\"],\n",
    "            \"fit_iqr_seconds\": st_fit[\"iqr_seconds\"],\n",
    "            \"predict_seconds\": st_pred[\"median_seconds\"],\n",
    "            \"predict_iqr_seconds\": st_pred[\"iqr_seconds\"],\n",
    "            \"metric\": metric,\n",
    "            \"metric_value\": float(np.median(arr)) if arr.size else np.nan,\n",
    "            \"metric_std\": float(np.std(arr)) if arr.size else np.nan,\n",
    "            \"n_runs\": int(arr.size),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# CPU logistic regression\n",
    "fit_times: list[float] = []\n",
    "pred_times: list[float] = []\n",
    "metrics: list[float] = []\n",
    "for _ in range(int(CONFIG[\"cuml_repeats_light\"])):\n",
    "    s = time.perf_counter()\n",
    "    mdl = SKLR(max_iter=600, solver=\"lbfgs\")\n",
    "    mdl.fit(Xtr_s, ytr)\n",
    "    fit_times.append(time.perf_counter() - s)\n",
    "\n",
    "    s = time.perf_counter()\n",
    "    proba = mdl.predict_proba(Xte_s)[:, 1]\n",
    "    pred_times.append(time.perf_counter() - s)\n",
    "    metrics.append(float(roc_auc_score(yte, proba)))\n",
    "push_result(\"logistic_regression\", \"sklearn_cpu\", fit_times, pred_times, \"auc\", metrics)\n",
    "\n",
    "\n",
    "# CPU random forest\n",
    "fit_times = []\n",
    "pred_times = []\n",
    "metrics = []\n",
    "for _ in range(int(CONFIG[\"cuml_repeats_heavy\"])):\n",
    "    s = time.perf_counter()\n",
    "    mdl = SKRF(n_estimators=250, max_depth=12, random_state=int(CONFIG[\"seed\"]), n_jobs=-1)\n",
    "    mdl.fit(Xtr, ytr)\n",
    "    fit_times.append(time.perf_counter() - s)\n",
    "\n",
    "    s = time.perf_counter()\n",
    "    proba = mdl.predict_proba(Xte)[:, 1]\n",
    "    pred_times.append(time.perf_counter() - s)\n",
    "    metrics.append(float(roc_auc_score(yte, proba)))\n",
    "push_result(\"random_forest\", \"sklearn_cpu\", fit_times, pred_times, \"auc\", metrics)\n",
    "\n",
    "\n",
    "# CPU KMeans\n",
    "Xk = Xtr_s[: min(150_000, len(Xtr_s))]\n",
    "fit_times = []\n",
    "pred_times = []\n",
    "metrics = []\n",
    "for _ in range(int(CONFIG[\"cuml_repeats_light\"])):\n",
    "    s = time.perf_counter()\n",
    "    labels = SKKMeans(n_clusters=7, n_init=10, random_state=int(CONFIG[\"seed\"])).fit_predict(Xk)\n",
    "    fit_times.append(time.perf_counter() - s)\n",
    "    pred_times.append(0.0)\n",
    "    n_sil = min(30_000, len(Xk))\n",
    "    metrics.append(float(silhouette_score(Xk[:n_sil], labels[:n_sil])))\n",
    "push_result(\"kmeans\", \"sklearn_cpu\", fit_times, pred_times, \"silhouette\", metrics)\n",
    "\n",
    "\n",
    "# GPU block\n",
    "if all(importlib.util.find_spec(p) is not None for p in [\"cuml\", \"cudf\", \"cupy\"]):\n",
    "    try:\n",
    "        import cudf\n",
    "        import cupy as cp\n",
    "        from cuml.cluster import KMeans as CUKMeans\n",
    "        from cuml.ensemble import RandomForestClassifier as CURF\n",
    "        from cuml.linear_model import LogisticRegression as CULR\n",
    "\n",
    "        def sync() -> None:\n",
    "            cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "        def as_numpy(x: Any) -> np.ndarray:\n",
    "            if isinstance(x, np.ndarray):\n",
    "                return x\n",
    "            if isinstance(x, cp.ndarray):\n",
    "                return cp.asnumpy(x)\n",
    "            if hasattr(x, \"to_numpy\"):\n",
    "                return x.to_numpy()\n",
    "            if hasattr(x, \"values_host\"):\n",
    "                return x.values_host\n",
    "            return np.asarray(x)\n",
    "\n",
    "        Xtrg_s = cudf.DataFrame(Xtr_s)\n",
    "        Xteg_s = cudf.DataFrame(Xte_s)\n",
    "        ytrg = cudf.Series(ytr.to_numpy())\n",
    "\n",
    "        # GPU logistic regression\n",
    "        fit_times = []\n",
    "        pred_times = []\n",
    "        metrics = []\n",
    "        for _ in range(int(CONFIG[\"cuml_repeats_light\"])):\n",
    "            s = time.perf_counter()\n",
    "            mdl = CULR(max_iter=600, linesearch_max_iter=100, output_type=\"numpy\")\n",
    "            mdl.fit(Xtrg_s, ytrg)\n",
    "            sync()\n",
    "            fit_times.append(time.perf_counter() - s)\n",
    "\n",
    "            s = time.perf_counter()\n",
    "            proba = mdl.predict_proba(Xteg_s)\n",
    "            sync()\n",
    "            pred_times.append(time.perf_counter() - s)\n",
    "\n",
    "            proba = as_numpy(proba)\n",
    "            proba = proba[:, 1] if proba.ndim == 2 else proba\n",
    "            metrics.append(float(roc_auc_score(yte, proba)))\n",
    "        push_result(\"logistic_regression\", \"cuml_gpu\", fit_times, pred_times, \"auc\", metrics)\n",
    "\n",
    "        # GPU random forest\n",
    "        Xtrg = cudf.DataFrame(Xtr)\n",
    "        Xteg = cudf.DataFrame(Xte)\n",
    "\n",
    "        fit_times = []\n",
    "        pred_times = []\n",
    "        metrics = []\n",
    "        for _ in range(int(CONFIG[\"cuml_repeats_heavy\"])):\n",
    "            s = time.perf_counter()\n",
    "            mdl = CURF(\n",
    "                n_estimators=250,\n",
    "                max_depth=12,\n",
    "                random_state=int(CONFIG[\"seed\"]),\n",
    "                output_type=\"numpy\",\n",
    "            )\n",
    "            mdl.fit(Xtrg, ytrg)\n",
    "            sync()\n",
    "            fit_times.append(time.perf_counter() - s)\n",
    "\n",
    "            s = time.perf_counter()\n",
    "            proba = mdl.predict_proba(Xteg)\n",
    "            sync()\n",
    "            pred_times.append(time.perf_counter() - s)\n",
    "\n",
    "            proba = as_numpy(proba)\n",
    "            proba = proba[:, 1] if proba.ndim == 2 else proba\n",
    "            metrics.append(float(roc_auc_score(yte, proba)))\n",
    "        push_result(\"random_forest\", \"cuml_gpu\", fit_times, pred_times, \"auc\", metrics)\n",
    "\n",
    "        # GPU KMeans\n",
    "        Xkg = cudf.DataFrame(Xk)\n",
    "        fit_times = []\n",
    "        pred_times = []\n",
    "        metrics = []\n",
    "        for _ in range(int(CONFIG[\"cuml_repeats_light\"])):\n",
    "            s = time.perf_counter()\n",
    "            labels = CUKMeans(\n",
    "                n_clusters=7, n_init=10, random_state=int(CONFIG[\"seed\"]), output_type=\"numpy\"\n",
    "            ).fit_predict(Xkg)\n",
    "            sync()\n",
    "            fit_times.append(time.perf_counter() - s)\n",
    "            pred_times.append(0.0)\n",
    "\n",
    "            labels = as_numpy(labels)\n",
    "            n_sil = min(30_000, len(Xk))\n",
    "            metrics.append(float(silhouette_score(Xk[:n_sil], labels[:n_sil])))\n",
    "        push_result(\"kmeans\", \"cuml_gpu\", fit_times, pred_times, \"silhouette\", metrics)\n",
    "\n",
    "    except Exception as exc:\n",
    "        print(\"cuML GPU block failed:\", repr(exc))\n",
    "        traceback.print_exc(limit=2)\n",
    "else:\n",
    "    print(\"cuML/cuDF/cuPy not available -> CPU baseline only\")\n",
    "\n",
    "\n",
    "cuml_df = pd.DataFrame(res)\n",
    "for t in cuml_df[\"task\"].unique():\n",
    "    cpu = cuml_df[(cuml_df[\"task\"] == t) & (cuml_df[\"backend\"] == \"sklearn_cpu\")]\n",
    "    if len(cpu) == 1:\n",
    "        b = float(cpu.iloc[0][\"fit_seconds\"])\n",
    "        mask = cuml_df[\"task\"] == t\n",
    "        cuml_df.loc[mask, \"fit_speedup_vs_cpu\"] = np.where(\n",
    "            cuml_df.loc[mask, \"backend\"] == \"sklearn_cpu\",\n",
    "            np.nan,\n",
    "            b / cuml_df.loc[mask, \"fit_seconds\"],\n",
    "        )\n",
    "\n",
    "\n",
    "tols = {\n",
    "    \"logistic_regression\": 0.010,\n",
    "    \"random_forest\": 0.025,\n",
    "    \"kmeans\": 0.040,\n",
    "}\n",
    "qrows = []\n",
    "for task in [\"logistic_regression\", \"random_forest\", \"kmeans\"]:\n",
    "    cpu = cuml_df[(cuml_df[\"task\"] == task) & (cuml_df[\"backend\"] == \"sklearn_cpu\")]\n",
    "    gpu = cuml_df[(cuml_df[\"task\"] == task) & (cuml_df[\"backend\"] == \"cuml_gpu\")]\n",
    "    if len(cpu) == 1 and len(gpu) == 1:\n",
    "        cpu_m = float(cpu.iloc[0][\"metric_value\"])\n",
    "        gpu_m = float(gpu.iloc[0][\"metric_value\"])\n",
    "        abs_diff = abs(cpu_m - gpu_m)\n",
    "        qrows.append(\n",
    "            {\n",
    "                \"task\": task,\n",
    "                \"metric\": cpu.iloc[0][\"metric\"],\n",
    "                \"cpu_metric\": cpu_m,\n",
    "                \"gpu_metric\": gpu_m,\n",
    "                \"abs_diff\": abs_diff,\n",
    "                \"rel_diff\": rel_err(cpu_m, gpu_m),\n",
    "                \"tolerance\": tols.get(task, 0.05),\n",
    "                \"quality_pass\": abs_diff <= tols.get(task, 0.05),\n",
    "            }\n",
    "        )\n",
    "\n",
    "cuml_quality_df = pd.DataFrame(qrows)\n",
    "\n",
    "display(cuml_df.sort_values([\"task\", \"backend\"]))\n",
    "if len(cuml_quality_df):\n",
    "    display(cuml_quality_df.sort_values(\"task\"))\n",
    "\n",
    "maybe_save(cuml_df, \"cuml_benchmark.csv\")\n",
    "if len(cuml_quality_df):\n",
    "    maybe_save(cuml_quality_df, \"cuml_quality_checks.csv\")\n",
    "\n",
    "# Direct CPU vs GPU view for cuML section\n",
    "cuml_pair_rows: list[dict[str, Any]] = []\n",
    "for task in sorted(cuml_df[\"task\"].dropna().unique()):\n",
    "    cpu = cuml_df[(cuml_df[\"task\"] == task) & (cuml_df[\"backend\"] == \"sklearn_cpu\")]\n",
    "    gpu = cuml_df[(cuml_df[\"task\"] == task) & (cuml_df[\"backend\"] == \"cuml_gpu\")]\n",
    "    if len(cpu) == 1 and len(gpu) == 1:\n",
    "        qpass = True\n",
    "        note = \"\"\n",
    "        if len(cuml_quality_df):\n",
    "            q = cuml_quality_df[cuml_quality_df[\"task\"] == task]\n",
    "            if len(q) == 1:\n",
    "                qpass = bool(q.iloc[0].get(\"quality_pass\", True))\n",
    "                note = f\"{q.iloc[0].get('metric', '')} abs_diff={q.iloc[0].get('abs_diff', np.nan)}\"\n",
    "        cpu_s = float(cpu.iloc[0][\"fit_seconds\"])\n",
    "        gpu_s = float(gpu.iloc[0][\"fit_seconds\"])\n",
    "        cuml_pair_rows.append(\n",
    "            {\n",
    "                \"section\": \"cuml\",\n",
    "                \"method\": str(task),\n",
    "                \"cpu_backend\": \"sklearn_cpu\",\n",
    "                \"gpu_backend\": \"cuml_gpu\",\n",
    "                \"cpu_seconds\": cpu_s,\n",
    "                \"gpu_seconds\": gpu_s,\n",
    "                \"speedup_x\": cpu_s / max(gpu_s, 1e-12),\n",
    "                \"quality_pass\": qpass,\n",
    "                \"note\": note,\n",
    "            }\n",
    "        )\n",
    "\n",
    "cuml_direct_df = finalize_direct_df(pd.DataFrame(cuml_pair_rows), \"cuml\")\n",
    "if len(cuml_direct_df):\n",
    "    display(cuml_direct_df)\n",
    "    plot_method_pairs(cuml_direct_df, \"cuML\")\n",
    "    print_section_conclusions(cuml_direct_df, \"cuML\")\n",
    "    maybe_save(cuml_direct_df, \"direct_cpu_vs_gpu_cuml.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 3) cuGraph benchmark (native + networkx backend dispatch)\n",
    "\n",
    "Graph is built from loan-to-attribute bipartite links (`grade`, `purpose`, `sub_grade`, `verification_status`).\n",
    "\n",
    "Compared paths:\n",
    "- Native NetworkX CPU\n",
    "- Native cuGraph GPU\n",
    "- NetworkX dispatch with `backend=\"cugraph\"` (if `nx-cugraph` is available)\n",
    "\n",
    "Additional checks:\n",
    "- Connected components parity\n",
    "- PageRank sum sanity (near 1.0)\n",
    "- Convergence tracking for cuGraph PageRank\n",
    "- Dedicated CPU-vs-GPU chart per method in this same section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "np.random.seed(int(CONFIG[\"seed\"]))\n",
    "\n",
    "if hasattr(nx, \"config\") and hasattr(nx.config, \"warnings_to_ignore\"):\n",
    "    try:\n",
    "        nx.config.warnings_to_ignore.add(\"cache\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "g = (\n",
    "    pd.read_parquet(TRAIN, columns=[\"id\", \"grade\", \"purpose\", \"sub_grade\", \"verification_status\"])\n",
    "    .dropna(subset=[\"id\"])\n",
    "    .copy()\n",
    ")\n",
    "g = g.sample(n=min(int(CONFIG[\"cugraph_sample_rows\"]), len(g)), random_state=int(CONFIG[\"seed\"]))\n",
    "g[\"id\"] = pd.to_numeric(g[\"id\"], errors=\"coerce\")\n",
    "g = g.dropna(subset=[\"id\"])\n",
    "g[\"id\"] = g[\"id\"].astype(np.int64)\n",
    "\n",
    "for col in [\"grade\", \"purpose\", \"sub_grade\", \"verification_status\"]:\n",
    "    g[col] = g[col].fillna(\"unknown\").astype(str)\n",
    "\n",
    "g[\"loan\"] = \"L_\" + g[\"id\"].astype(str)\n",
    "\n",
    "edges = pd.concat(\n",
    "    [\n",
    "        g[[\"loan\", \"grade\"]]\n",
    "        .rename(columns={\"loan\": \"src\", \"grade\": \"dst\"})\n",
    "        .assign(dst=lambda x: \"G_\" + x[\"dst\"]),\n",
    "        g[[\"loan\", \"purpose\"]]\n",
    "        .rename(columns={\"loan\": \"src\", \"purpose\": \"dst\"})\n",
    "        .assign(dst=lambda x: \"P_\" + x[\"dst\"]),\n",
    "        g[[\"loan\", \"sub_grade\"]]\n",
    "        .rename(columns={\"loan\": \"src\", \"sub_grade\": \"dst\"})\n",
    "        .assign(dst=lambda x: \"SG_\" + x[\"dst\"]),\n",
    "        g[[\"loan\", \"verification_status\"]]\n",
    "        .rename(columns={\"loan\": \"src\", \"verification_status\": \"dst\"})\n",
    "        .assign(dst=lambda x: \"V_\" + x[\"dst\"]),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "nodes = pd.Index(pd.concat([edges[\"src\"], edges[\"dst\"]], ignore_index=True).unique())\n",
    "node2id = pd.Series(np.arange(len(nodes), dtype=np.int64), index=nodes)\n",
    "\n",
    "E = pd.DataFrame(\n",
    "    {\n",
    "        \"src\": edges[\"src\"].map(node2id).astype(np.int32),\n",
    "        \"dst\": edges[\"dst\"].map(node2id).astype(np.int32),\n",
    "    }\n",
    ")\n",
    "\n",
    "R = int(CONFIG[\"cugraph_repeats\"])\n",
    "cres: list[dict[str, Any]] = []\n",
    "\n",
    "\n",
    "def add_row(\n",
    "    task: str, backend: str, times: list[float], metric: str, metric_value: float, **extra: Any\n",
    ") -> None:\n",
    "    st = stats_from(times)\n",
    "    row: dict[str, Any] = {\n",
    "        \"task\": task,\n",
    "        \"backend\": backend,\n",
    "        \"seconds\": st[\"median_seconds\"],\n",
    "        \"seconds_iqr\": st[\"iqr_seconds\"],\n",
    "        \"metric\": metric,\n",
    "        \"metric_value\": float(metric_value),\n",
    "    }\n",
    "    row.update(extra)\n",
    "    cres.append(row)\n",
    "\n",
    "\n",
    "# NetworkX CPU baseline\n",
    "build_times: list[float] = []\n",
    "G_cpu = None\n",
    "for _ in range(R):\n",
    "    s = time.perf_counter()\n",
    "    G_cpu = nx.from_pandas_edgelist(E, source=\"src\", target=\"dst\", create_using=nx.Graph())\n",
    "    build_times.append(time.perf_counter() - s)\n",
    "\n",
    "cc_times: list[float] = []\n",
    "cc_val = None\n",
    "for _ in range(R):\n",
    "    s = time.perf_counter()\n",
    "    cc_val = nx.number_connected_components(G_cpu)\n",
    "    cc_times.append(time.perf_counter() - s)\n",
    "\n",
    "pr_times: list[float] = []\n",
    "pr_sum = None\n",
    "for _ in range(R):\n",
    "    s = time.perf_counter()\n",
    "    pr = nx.pagerank(G_cpu, alpha=0.85, max_iter=200, tol=1e-6)\n",
    "    pr_times.append(time.perf_counter() - s)\n",
    "    pr_sum = float(sum(pr.values()))\n",
    "\n",
    "add_row(\"graph_build\", \"networkx_cpu\", build_times, \"nodes\", float(G_cpu.number_of_nodes()))\n",
    "add_row(\"connected_components\", \"networkx_cpu\", cc_times, \"n_components\", float(cc_val))\n",
    "add_row(\"pagerank\", \"networkx_cpu\", pr_times, \"sum_pagerank\", float(pr_sum), converged_rate=1.0)\n",
    "\n",
    "\n",
    "# Native cuGraph\n",
    "if all(importlib.util.find_spec(p) is not None for p in [\"cugraph\", \"cudf\", \"cupy\"]):\n",
    "    try:\n",
    "        import cudf\n",
    "        import cugraph\n",
    "        import cupy as cp\n",
    "\n",
    "        def sync() -> None:\n",
    "            cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "        Eg = cudf.DataFrame(E)\n",
    "\n",
    "        build_times = []\n",
    "        G_gpu = None\n",
    "        for _ in range(R):\n",
    "            s = time.perf_counter()\n",
    "            G_gpu = cugraph.Graph(directed=False)\n",
    "            G_gpu.from_cudf_edgelist(\n",
    "                Eg, source=\"src\", destination=\"dst\", renumber=False, store_transposed=True\n",
    "            )\n",
    "            sync()\n",
    "            build_times.append(time.perf_counter() - s)\n",
    "\n",
    "        cc_times = []\n",
    "        ncc = None\n",
    "        for _ in range(R):\n",
    "            s = time.perf_counter()\n",
    "            ccg = cugraph.connected_components(G_gpu)\n",
    "            sync()\n",
    "            cc_times.append(time.perf_counter() - s)\n",
    "            lcol = \"labels\" if \"labels\" in ccg.columns else ccg.columns[-1]\n",
    "            ncc = int(ccg[lcol].nunique())\n",
    "\n",
    "        pr_times = []\n",
    "        pr_sum = None\n",
    "        converged_flags: list[bool] = []\n",
    "        for _ in range(R):\n",
    "            s = time.perf_counter()\n",
    "            out = cugraph.pagerank(\n",
    "                G_gpu,\n",
    "                alpha=0.85,\n",
    "                max_iter=200,\n",
    "                tol=1e-6,\n",
    "                fail_on_nonconvergence=False,\n",
    "            )\n",
    "            sync()\n",
    "            pr_times.append(time.perf_counter() - s)\n",
    "\n",
    "            if isinstance(out, tuple):\n",
    "                prg, converged = out\n",
    "                converged_flags.append(bool(converged))\n",
    "            else:\n",
    "                prg = out\n",
    "                converged_flags.append(True)\n",
    "            pr_sum = float(prg[\"pagerank\"].sum())\n",
    "\n",
    "        add_row(\n",
    "            \"graph_build\", \"cugraph_gpu\", build_times, \"nodes\", float(G_gpu.number_of_vertices())\n",
    "        )\n",
    "        add_row(\"connected_components\", \"cugraph_gpu\", cc_times, \"n_components\", float(ncc))\n",
    "        add_row(\n",
    "            \"pagerank\",\n",
    "            \"cugraph_gpu\",\n",
    "            pr_times,\n",
    "            \"sum_pagerank\",\n",
    "            float(pr_sum),\n",
    "            converged_rate=float(np.mean(converged_flags)),\n",
    "        )\n",
    "\n",
    "    except Exception as exc:\n",
    "        print(\"cuGraph GPU block failed:\", repr(exc))\n",
    "        traceback.print_exc(limit=2)\n",
    "else:\n",
    "    print(\"cugraph/cudf/cupy not available -> CPU only\")\n",
    "\n",
    "\n",
    "# NetworkX backend dispatch (nx-cugraph)\n",
    "if importlib.util.find_spec(\"nx_cugraph\") is not None:\n",
    "    try:\n",
    "        cc_times = []\n",
    "        cc_val_backend = None\n",
    "        for _ in range(R):\n",
    "            s = time.perf_counter()\n",
    "            cc_val_backend = sum(1 for _ in nx.connected_components(G_cpu, backend=\"cugraph\"))\n",
    "            cc_times.append(time.perf_counter() - s)\n",
    "\n",
    "        pr_times = []\n",
    "        pr_sum_backend = None\n",
    "        for _ in range(R):\n",
    "            s = time.perf_counter()\n",
    "            pr_backend = nx.pagerank(G_cpu, alpha=0.85, max_iter=200, tol=1e-6, backend=\"cugraph\")\n",
    "            pr_times.append(time.perf_counter() - s)\n",
    "            pr_sum_backend = float(sum(pr_backend.values()))\n",
    "\n",
    "        add_row(\n",
    "            \"connected_components\",\n",
    "            \"networkx_cugraph_backend\",\n",
    "            cc_times,\n",
    "            \"n_components\",\n",
    "            float(cc_val_backend),\n",
    "        )\n",
    "        add_row(\n",
    "            \"pagerank\",\n",
    "            \"networkx_cugraph_backend\",\n",
    "            pr_times,\n",
    "            \"sum_pagerank\",\n",
    "            float(pr_sum_backend),\n",
    "            converged_rate=1.0,\n",
    "        )\n",
    "    except Exception as exc:\n",
    "        print(\"nx-cugraph backend block failed:\", repr(exc))\n",
    "        traceback.print_exc(limit=2)\n",
    "else:\n",
    "    print(\"nx_cugraph not available -> skipping NetworkX backend dispatch\")\n",
    "\n",
    "\n",
    "cugraph_df = pd.DataFrame(cres)\n",
    "for t in cugraph_df[\"task\"].unique():\n",
    "    cpu = cugraph_df[(cugraph_df[\"task\"] == t) & (cugraph_df[\"backend\"] == \"networkx_cpu\")]\n",
    "    if len(cpu) == 1:\n",
    "        b = float(cpu.iloc[0][\"seconds\"])\n",
    "        mask = cugraph_df[\"task\"] == t\n",
    "        cugraph_df.loc[mask, \"speedup_vs_cpu\"] = np.where(\n",
    "            cugraph_df.loc[mask, \"backend\"] == \"networkx_cpu\",\n",
    "            np.nan,\n",
    "            b / cugraph_df.loc[mask, \"seconds\"],\n",
    "        )\n",
    "\n",
    "\n",
    "qrows = []\n",
    "cpu_cc = cugraph_df[\n",
    "    (cugraph_df[\"task\"] == \"connected_components\") & (cugraph_df[\"backend\"] == \"networkx_cpu\")\n",
    "]\n",
    "if len(cpu_cc) == 1:\n",
    "    cc_base = float(cpu_cc.iloc[0][\"metric_value\"])\n",
    "    for _, r in cugraph_df[cugraph_df[\"task\"] == \"connected_components\"].iterrows():\n",
    "        if r[\"backend\"] == \"networkx_cpu\":\n",
    "            continue\n",
    "        qrows.append(\n",
    "            {\n",
    "                \"task\": \"connected_components\",\n",
    "                \"backend\": r[\"backend\"],\n",
    "                \"cpu_metric\": cc_base,\n",
    "                \"other_metric\": float(r[\"metric_value\"]),\n",
    "                \"abs_diff\": abs(cc_base - float(r[\"metric_value\"])),\n",
    "                \"quality_pass\": abs(cc_base - float(r[\"metric_value\"])) <= 0.0,\n",
    "            }\n",
    "        )\n",
    "\n",
    "for _, r in cugraph_df[cugraph_df[\"task\"] == \"pagerank\"].iterrows():\n",
    "    qrows.append(\n",
    "        {\n",
    "            \"task\": \"pagerank\",\n",
    "            \"backend\": r[\"backend\"],\n",
    "            \"cpu_metric\": 1.0,\n",
    "            \"other_metric\": float(r[\"metric_value\"]),\n",
    "            \"abs_diff\": abs(1.0 - float(r[\"metric_value\"])),\n",
    "            \"quality_pass\": abs(1.0 - float(r[\"metric_value\"])) <= 0.02,\n",
    "        }\n",
    "    )\n",
    "\n",
    "cugraph_quality_df = pd.DataFrame(qrows)\n",
    "\n",
    "display(cugraph_df.sort_values([\"task\", \"backend\"]))\n",
    "if len(cugraph_quality_df):\n",
    "    display(cugraph_quality_df.sort_values([\"task\", \"backend\"]))\n",
    "\n",
    "maybe_save(cugraph_df, \"cugraph_benchmark.csv\")\n",
    "if len(cugraph_quality_df):\n",
    "    maybe_save(cugraph_quality_df, \"cugraph_quality_checks.csv\")\n",
    "\n",
    "# Direct CPU vs GPU view for cuGraph section\n",
    "cugraph_pair_rows: list[dict[str, Any]] = []\n",
    "for task in sorted(cugraph_df[\"task\"].dropna().unique()):\n",
    "    cpu = cugraph_df[(cugraph_df[\"task\"] == task) & (cugraph_df[\"backend\"] == \"networkx_cpu\")]\n",
    "    gpu = cugraph_df[(cugraph_df[\"task\"] == task) & (cugraph_df[\"backend\"] == \"cugraph_gpu\")]\n",
    "    if len(cpu) == 1 and len(gpu) == 1:\n",
    "        qpass = True\n",
    "        note = \"\"\n",
    "        if len(cugraph_quality_df):\n",
    "            q = cugraph_quality_df[\n",
    "                (cugraph_quality_df[\"task\"] == task)\n",
    "                & (cugraph_quality_df[\"backend\"] == \"cugraph_gpu\")\n",
    "            ]\n",
    "            if len(q) == 1:\n",
    "                qpass = bool(q.iloc[0].get(\"quality_pass\", True))\n",
    "                note = f\"metric_abs_diff={q.iloc[0].get('abs_diff', np.nan)}\"\n",
    "        if task == \"pagerank\" and \"converged_rate\" in gpu.columns:\n",
    "            note = (\n",
    "                note + \" \" + f\"converged_rate={gpu.iloc[0].get('converged_rate', np.nan)}\"\n",
    "            ).strip()\n",
    "\n",
    "        cpu_s = float(cpu.iloc[0][\"seconds\"])\n",
    "        gpu_s = float(gpu.iloc[0][\"seconds\"])\n",
    "        cugraph_pair_rows.append(\n",
    "            {\n",
    "                \"section\": \"cugraph\",\n",
    "                \"method\": str(task),\n",
    "                \"cpu_backend\": \"networkx_cpu\",\n",
    "                \"gpu_backend\": \"cugraph_gpu\",\n",
    "                \"cpu_seconds\": cpu_s,\n",
    "                \"gpu_seconds\": gpu_s,\n",
    "                \"speedup_x\": cpu_s / max(gpu_s, 1e-12),\n",
    "                \"quality_pass\": qpass,\n",
    "                \"note\": note,\n",
    "            }\n",
    "        )\n",
    "\n",
    "cugraph_direct_df = finalize_direct_df(pd.DataFrame(cugraph_pair_rows), \"cugraph\")\n",
    "if len(cugraph_direct_df):\n",
    "    display(cugraph_direct_df)\n",
    "    plot_method_pairs(cugraph_direct_df, \"cuGraph\")\n",
    "    print_section_conclusions(cugraph_direct_df, \"cuGraph\")\n",
    "    maybe_save(cugraph_direct_df, \"direct_cpu_vs_gpu_cugraph.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 4) cuOpt benchmark (LP) + API smoke test\n",
    "\n",
    "Formulation:\n",
    "- Continuous LP portfolio selection with budget, risk, and concentration constraints.\n",
    "- CPU baseline: `scipy.optimize.linprog(method=\"highs\")`\n",
    "- GPU path: cuOpt LP via `linear_programming.DataModel` + `Solve`\n",
    "\n",
    "Also included:\n",
    "- Small `Problem` API smoke test (`addVariable`, `addConstraint`, `setObjective`, `solve`)\n",
    "- Dedicated CPU-vs-GPU chart for LP in this same section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import Bounds, LinearConstraint, linprog, milp\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "np.random.seed(int(CONFIG[\"seed\"]))\n",
    "\n",
    "train_grade = pd.read_parquet(TRAIN, columns=[\"grade\", \"default_flag\"]).dropna(subset=[\"grade\"])\n",
    "grade_pd = train_grade.groupby(\"grade\")[\"default_flag\"].mean()\n",
    "\n",
    "df = (\n",
    "    pd.read_parquet(TEST, columns=[\"loan_amnt\", \"int_rate\", \"grade\", \"purpose\", \"default_flag\"])\n",
    "    .dropna(subset=[\"loan_amnt\", \"int_rate\", \"grade\"])\n",
    "    .copy()\n",
    ")\n",
    "df = df.sample(\n",
    "    n=min(int(CONFIG[\"cuopt_sample_rows\"]), len(df)), random_state=int(CONFIG[\"seed\"])\n",
    ").reset_index(drop=True)\n",
    "\n",
    "df[\"loan_amnt\"] = pd.to_numeric(df[\"loan_amnt\"], errors=\"coerce\").fillna(0.0)\n",
    "df[\"int_rate\"] = pd.to_numeric(df[\"int_rate\"].astype(str).str.rstrip(\"%\"), errors=\"coerce\").fillna(\n",
    "    0.0\n",
    ")\n",
    "df[\"pd\"] = df[\"grade\"].map(grade_pd).fillna(float(grade_pd.mean())).clip(0.001, 0.99)\n",
    "\n",
    "loan = df[\"loan_amnt\"].to_numpy(np.float64)\n",
    "ir = (df[\"int_rate\"] / 100.0).to_numpy(np.float64)\n",
    "pd_proxy = df[\"pd\"].to_numpy(np.float64)\n",
    "obj = loan * (ir - 0.45 * pd_proxy)\n",
    "\n",
    "budget = float(loan.sum() * 0.20)\n",
    "purpose_vals = df[\"purpose\"].astype(str).to_numpy()\n",
    "rows = [loan, loan * pd_proxy]\n",
    "rhs = [budget, 0.10 * budget]\n",
    "for p in df[\"purpose\"].astype(str).value_counts().head(2).index.tolist():\n",
    "    rows.append(np.where(purpose_vals == p, loan, 0.0))\n",
    "    rhs.append(0.35 * budget)\n",
    "\n",
    "A = np.vstack(rows).astype(np.float64)\n",
    "b = np.array(rhs, dtype=np.float64)\n",
    "\n",
    "opt_res: list[dict[str, Any]] = []\n",
    "\n",
    "\n",
    "# CPU LP (repeat)\n",
    "lp_times: list[float] = []\n",
    "lp_objs: list[float] = []\n",
    "lp_status: list[int] = []\n",
    "for _ in range(int(CONFIG[\"cuopt_repeats\"])):\n",
    "    s = time.perf_counter()\n",
    "    lp_cpu = linprog(c=-obj, A_ub=A, b_ub=b, bounds=(0, 1), method=\"highs\")\n",
    "    lp_times.append(time.perf_counter() - s)\n",
    "    lp_status.append(int(lp_cpu.status))\n",
    "    lp_objs.append(float(-lp_cpu.fun) if lp_cpu.success else np.nan)\n",
    "\n",
    "st = stats_from(lp_times)\n",
    "opt_res.append(\n",
    "    {\n",
    "        \"task\": \"portfolio_lp\",\n",
    "        \"backend\": \"scipy_highs_cpu\",\n",
    "        \"seconds\": st[\"median_seconds\"],\n",
    "        \"seconds_iqr\": st[\"iqr_seconds\"],\n",
    "        \"status\": str(lp_status[-1]),\n",
    "        \"objective\": float(np.nanmedian(np.asarray(lp_objs, dtype=np.float64))),\n",
    "        \"n_variables\": int(len(obj)),\n",
    "        \"n_runs\": int(len(lp_times)),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# CPU MILP reference (single-run, smaller N)\n",
    "n_milp = min(3000, len(obj))\n",
    "Ac = A[:, :n_milp]\n",
    "cc = -obj[:n_milp]\n",
    "lc = LinearConstraint(Ac, -np.inf * np.ones(Ac.shape[0]), b)\n",
    "bb = Bounds(lb=np.zeros(n_milp), ub=np.ones(n_milp))\n",
    "ig = np.ones(n_milp, dtype=int)\n",
    "\n",
    "s = time.perf_counter()\n",
    "mi = milp(c=cc, integrality=ig, bounds=bb, constraints=lc, options={\"time_limit\": 120})\n",
    "t_mi = time.perf_counter() - s\n",
    "\n",
    "opt_res.append(\n",
    "    {\n",
    "        \"task\": \"portfolio_milp_reference\",\n",
    "        \"backend\": \"scipy_milp_cpu\",\n",
    "        \"seconds\": float(t_mi),\n",
    "        \"seconds_iqr\": np.nan,\n",
    "        \"status\": str(mi.status),\n",
    "        \"objective\": float(-mi.fun) if mi.success else np.nan,\n",
    "        \"n_variables\": int(n_milp),\n",
    "        \"n_runs\": 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# cuOpt LP via DataModel + Solve\n",
    "if importlib.util.find_spec(\"cuopt\") is not None:\n",
    "    try:\n",
    "        from cuopt import linear_programming as lp\n",
    "\n",
    "        gpu_times: list[float] = []\n",
    "        gpu_obj: list[float] = []\n",
    "        gpu_reason: list[str] = []\n",
    "\n",
    "        A_csr = csr_matrix(A)\n",
    "        row_types = np.array([\"L\"] * A.shape[0])\n",
    "        lb = np.zeros(A.shape[1], dtype=np.float64)\n",
    "        ub = np.ones(A.shape[1], dtype=np.float64)\n",
    "\n",
    "        for _ in range(int(CONFIG[\"cuopt_repeats\"])):\n",
    "            dm = lp.DataModel()\n",
    "            dm.set_csr_constraint_matrix(\n",
    "                A_csr.data.astype(np.float64),\n",
    "                A_csr.indices.astype(np.int32),\n",
    "                A_csr.indptr.astype(np.int32),\n",
    "            )\n",
    "            dm.set_constraint_bounds(b)\n",
    "            dm.set_row_types(row_types)\n",
    "            dm.set_objective_coefficients(obj.astype(np.float64))\n",
    "            dm.set_maximize(True)\n",
    "            dm.set_variable_lower_bounds(lb)\n",
    "            dm.set_variable_upper_bounds(ub)\n",
    "\n",
    "            settings = lp.SolverSettings()\n",
    "            try:\n",
    "                settings.set_parameter(\"log_to_console\", False)\n",
    "            except Exception:\n",
    "                pass\n",
    "            settings.set_parameter(\"time_limit\", 120)\n",
    "\n",
    "            s = time.perf_counter()\n",
    "            sol = lp.Solve(dm, settings)\n",
    "            gpu_times.append(time.perf_counter() - s)\n",
    "\n",
    "            reason = str(sol.get_termination_reason())\n",
    "            gpu_reason.append(reason)\n",
    "            if \"Optimal\" in reason:\n",
    "                gpu_obj.append(float(sol.get_primal_objective()))\n",
    "            else:\n",
    "                gpu_obj.append(np.nan)\n",
    "\n",
    "        st_gpu = stats_from(gpu_times)\n",
    "        opt_res.append(\n",
    "            {\n",
    "                \"task\": \"portfolio_lp\",\n",
    "                \"backend\": \"cuopt_gpu\",\n",
    "                \"seconds\": st_gpu[\"median_seconds\"],\n",
    "                \"seconds_iqr\": st_gpu[\"iqr_seconds\"],\n",
    "                \"status\": gpu_reason[-1],\n",
    "                \"objective\": float(np.nanmedian(np.asarray(gpu_obj, dtype=np.float64))),\n",
    "                \"n_variables\": int(len(obj)),\n",
    "                \"n_runs\": int(len(gpu_times)),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Problem API smoke test (new API path)\n",
    "        smoke_status = \"error\"\n",
    "        smoke_obj = np.nan\n",
    "        smoke_t0 = time.perf_counter()\n",
    "        try:\n",
    "            from cuopt.linear_programming.problem import CONTINUOUS, MAXIMIZE, Problem\n",
    "\n",
    "            p = Problem(\"api_smoke\")\n",
    "            x = p.addVariable(lb=0.0, ub=10.0, vtype=CONTINUOUS, name=\"x\")\n",
    "            y = p.addVariable(lb=0.0, ub=10.0, vtype=CONTINUOUS, name=\"y\")\n",
    "            p.addConstraint(x + y <= 10.0)\n",
    "            p.addConstraint(x - y >= 0.0)\n",
    "            p.setObjective(x + y, sense=MAXIMIZE)\n",
    "            p.solve()\n",
    "            smoke_status = str(getattr(p.Status, \"name\", p.Status))\n",
    "            smoke_obj = float(p.ObjValue)\n",
    "        except Exception as exc:\n",
    "            smoke_status = f\"error: {exc}\"\n",
    "        smoke_t = time.perf_counter() - smoke_t0\n",
    "\n",
    "        opt_res.append(\n",
    "            {\n",
    "                \"task\": \"api_smoke_problem_class\",\n",
    "                \"backend\": \"cuopt_gpu\",\n",
    "                \"seconds\": float(smoke_t),\n",
    "                \"seconds_iqr\": np.nan,\n",
    "                \"status\": smoke_status,\n",
    "                \"objective\": smoke_obj,\n",
    "                \"n_variables\": 2,\n",
    "                \"n_runs\": 1,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    except Exception as exc:\n",
    "        opt_res.append(\n",
    "            {\n",
    "                \"task\": \"portfolio_lp\",\n",
    "                \"backend\": \"cuopt_gpu\",\n",
    "                \"seconds\": np.nan,\n",
    "                \"seconds_iqr\": np.nan,\n",
    "                \"status\": f\"error: {exc}\",\n",
    "                \"objective\": np.nan,\n",
    "                \"n_variables\": int(len(obj)),\n",
    "                \"n_runs\": 0,\n",
    "            }\n",
    "        )\n",
    "        traceback.print_exc(limit=2)\n",
    "else:\n",
    "    print(\"cuopt not available -> CPU only\")\n",
    "\n",
    "\n",
    "cuopt_df = pd.DataFrame(opt_res)\n",
    "cpu = cuopt_df[(cuopt_df[\"task\"] == \"portfolio_lp\") & (cuopt_df[\"backend\"] == \"scipy_highs_cpu\")]\n",
    "if len(cpu) == 1:\n",
    "    btime = float(cpu.iloc[0][\"seconds\"])\n",
    "    mask = cuopt_df[\"task\"] == \"portfolio_lp\"\n",
    "    cuopt_df.loc[mask, \"speedup_vs_cpu_lp\"] = np.where(\n",
    "        cuopt_df.loc[mask, \"backend\"] == \"scipy_highs_cpu\",\n",
    "        np.nan,\n",
    "        btime / cuopt_df.loc[mask, \"seconds\"],\n",
    "    )\n",
    "\n",
    "qrows = []\n",
    "gpu_lp = cuopt_df[(cuopt_df[\"task\"] == \"portfolio_lp\") & (cuopt_df[\"backend\"] == \"cuopt_gpu\")]\n",
    "if len(cpu) == 1 and len(gpu_lp) == 1:\n",
    "    cpu_obj = float(cpu.iloc[0][\"objective\"])\n",
    "    gpu_obj = float(gpu_lp.iloc[0][\"objective\"])\n",
    "    ok = np.isfinite(cpu_obj) and np.isfinite(gpu_obj)\n",
    "    qrows.append(\n",
    "        {\n",
    "            \"check\": \"lp_objective_parity\",\n",
    "            \"cpu_objective\": cpu_obj,\n",
    "            \"gpu_objective\": gpu_obj,\n",
    "            \"rel_diff\": rel_err(cpu_obj, gpu_obj) if ok else np.nan,\n",
    "            \"tolerance\": 1e-4,\n",
    "            \"quality_pass\": bool(ok and rel_err(cpu_obj, gpu_obj) <= 1e-4),\n",
    "        }\n",
    "    )\n",
    "\n",
    "smoke = cuopt_df[cuopt_df[\"task\"] == \"api_smoke_problem_class\"]\n",
    "if len(smoke) == 1:\n",
    "    st = str(smoke.iloc[0][\"status\"])\n",
    "    objv = float(smoke.iloc[0][\"objective\"]) if pd.notna(smoke.iloc[0][\"objective\"]) else np.nan\n",
    "    qrows.append(\n",
    "        {\n",
    "            \"check\": \"problem_api_smoke\",\n",
    "            \"cpu_objective\": 10.0,\n",
    "            \"gpu_objective\": objv,\n",
    "            \"rel_diff\": rel_err(10.0, objv) if np.isfinite(objv) else np.nan,\n",
    "            \"tolerance\": 1e-6,\n",
    "            \"quality_pass\": (\"Optimal\" in st) and np.isfinite(objv) and abs(objv - 10.0) <= 1e-6,\n",
    "        }\n",
    "    )\n",
    "\n",
    "cuopt_quality_df = pd.DataFrame(qrows)\n",
    "\n",
    "display(cuopt_df.sort_values([\"task\", \"backend\"]))\n",
    "if len(cuopt_quality_df):\n",
    "    display(cuopt_quality_df)\n",
    "\n",
    "maybe_save(cuopt_df, \"cuopt_benchmark.csv\")\n",
    "if len(cuopt_quality_df):\n",
    "    maybe_save(cuopt_quality_df, \"cuopt_quality_checks.csv\")\n",
    "\n",
    "# Direct CPU vs GPU view for cuOpt section\n",
    "cuopt_pair_rows: list[dict[str, Any]] = []\n",
    "cpu_lp = cuopt_df[(cuopt_df[\"task\"] == \"portfolio_lp\") & (cuopt_df[\"backend\"] == \"scipy_highs_cpu\")]\n",
    "gpu_lp = cuopt_df[(cuopt_df[\"task\"] == \"portfolio_lp\") & (cuopt_df[\"backend\"] == \"cuopt_gpu\")]\n",
    "if len(cpu_lp) == 1 and len(gpu_lp) == 1:\n",
    "    qpass = True\n",
    "    note = \"\"\n",
    "    if len(cuopt_quality_df):\n",
    "        q = cuopt_quality_df[cuopt_quality_df[\"check\"] == \"lp_objective_parity\"]\n",
    "        if len(q) == 1:\n",
    "            qpass = bool(q.iloc[0].get(\"quality_pass\", True))\n",
    "            note = f\"lp_rel_diff={q.iloc[0].get('rel_diff', np.nan)}\"\n",
    "    cpu_s = float(cpu_lp.iloc[0][\"seconds\"])\n",
    "    gpu_s = float(gpu_lp.iloc[0][\"seconds\"])\n",
    "    cuopt_pair_rows.append(\n",
    "        {\n",
    "            \"section\": \"cuopt\",\n",
    "            \"method\": \"portfolio_lp\",\n",
    "            \"cpu_backend\": \"scipy_highs_cpu\",\n",
    "            \"gpu_backend\": \"cuopt_gpu\",\n",
    "            \"cpu_seconds\": cpu_s,\n",
    "            \"gpu_seconds\": gpu_s,\n",
    "            \"speedup_x\": cpu_s / max(gpu_s, 1e-12),\n",
    "            \"quality_pass\": qpass,\n",
    "            \"note\": note,\n",
    "        }\n",
    "    )\n",
    "\n",
    "cuopt_direct_df = finalize_direct_df(pd.DataFrame(cuopt_pair_rows), \"cuopt\")\n",
    "if len(cuopt_direct_df):\n",
    "    display(cuopt_direct_df)\n",
    "    plot_method_pairs(cuopt_direct_df, \"cuOpt\")\n",
    "    print_section_conclusions(cuopt_direct_df, \"cuOpt\")\n",
    "    maybe_save(cuopt_direct_df, \"direct_cpu_vs_gpu_cuopt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidated summary + quality gates\n",
    "parts = []\n",
    "for name in [\"cudf_df\", \"cuml_df\", \"cugraph_df\", \"cuopt_df\"]:\n",
    "    if name in globals():\n",
    "        tmp = globals()[name].copy()\n",
    "        tmp[\"section\"] = name.replace(\"_df\", \"\")\n",
    "        parts.append(tmp)\n",
    "\n",
    "if parts:\n",
    "    summary = pd.concat(parts, ignore_index=True, sort=False)\n",
    "    display(summary)\n",
    "\n",
    "    speed_cols = [\n",
    "        c\n",
    "        for c in [\n",
    "            \"speedup_vs_pandas_cpu\",\n",
    "            \"fit_speedup_vs_cpu\",\n",
    "            \"speedup_vs_cpu\",\n",
    "            \"speedup_vs_cpu_lp\",\n",
    "        ]\n",
    "        if c in summary.columns\n",
    "    ]\n",
    "    if speed_cols:\n",
    "        top = summary[[\"section\", \"task\", \"backend\", *speed_cols]].copy()\n",
    "        display(top)\n",
    "\n",
    "    maybe_save(summary, \"benchmark_summary_all_sections.csv\")\n",
    "\n",
    "\n",
    "checks = []\n",
    "for name in [\"cuml_quality_df\", \"cugraph_quality_df\", \"cuopt_quality_df\"]:\n",
    "    if name in globals() and isinstance(globals()[name], pd.DataFrame) and len(globals()[name]):\n",
    "        tmp = globals()[name].copy()\n",
    "        tmp[\"section\"] = name.replace(\"_quality_df\", \"\")\n",
    "        checks.append(tmp)\n",
    "\n",
    "if checks:\n",
    "    quality = pd.concat(checks, ignore_index=True, sort=False)\n",
    "    display(quality)\n",
    "\n",
    "    if \"quality_pass\" in quality.columns:\n",
    "        failed = quality[quality[\"quality_pass\"] == False]\n",
    "        if len(failed):\n",
    "            print(\"Quality checks with failures:\", len(failed))\n",
    "            display(failed)\n",
    "        else:\n",
    "            print(\"All available quality checks passed.\")\n",
    "\n",
    "    maybe_save(quality, \"benchmark_quality_checks_all_sections.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 5) Direct CPU vs GPU comparison view\n",
    "\n",
    "This section normalizes all sections into direct CPU-vs-GPU pairs:\n",
    "- `cpu_seconds` vs `gpu_seconds`\n",
    "- `speedup_x = cpu_seconds / gpu_seconds`\n",
    "- `% improvement`\n",
    "- quality gate status\n",
    "- relevance conclusion per method\n",
    "- section-level summary across all methods\n",
    "\n",
    "Note: per-method charts are shown inside each library section (cuDF, cuML, cuGraph, cuOpt).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct paired comparisons (CPU vs GPU)\n",
    "direct_parts = []\n",
    "for name in [\"cudf_direct_df\", \"cuml_direct_df\", \"cugraph_direct_df\", \"cuopt_direct_df\"]:\n",
    "    if name in globals() and isinstance(globals()[name], pd.DataFrame) and len(globals()[name]):\n",
    "        direct_parts.append(globals()[name].copy())\n",
    "\n",
    "if direct_parts:\n",
    "    direct_cmp_df = (\n",
    "        pd.concat(direct_parts, ignore_index=True, sort=False)\n",
    "        .sort_values([\"section\", \"method\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    display(direct_cmp_df)\n",
    "    maybe_save(direct_cmp_df, \"direct_cpu_vs_gpu_comparison.csv\")\n",
    "\n",
    "    section_summary_df = (\n",
    "        direct_cmp_df.groupby(\"section\", as_index=False)\n",
    "        .agg(\n",
    "            methods=(\"method\", \"count\"),\n",
    "            median_speedup_x=(\"speedup_x\", \"median\"),\n",
    "            best_speedup_x=(\"speedup_x\", \"max\"),\n",
    "            methods_with_positive_gain=(\"improvement_pct\", lambda s: int((s > 0).sum())),\n",
    "            quality_pass_rate=(\"quality_pass\", lambda s: float(np.mean(s.astype(float)))),\n",
    "        )\n",
    "        .sort_values(\"median_speedup_x\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    display(section_summary_df)\n",
    "    maybe_save(section_summary_df, \"direct_cpu_vs_gpu_section_summary.csv\")\n",
    "\n",
    "    print(\"Cross-section conclusions:\")\n",
    "    for section in section_summary_df[\"section\"].tolist():\n",
    "        s = direct_cmp_df[direct_cmp_df[\"section\"] == section]\n",
    "        best = s.sort_values(\"speedup_x\", ascending=False).iloc[0]\n",
    "        worst = s.sort_values(\"speedup_x\", ascending=True).iloc[0]\n",
    "        pass_rate = float(s[\"quality_pass\"].mean()) if len(s) else np.nan\n",
    "        print(\n",
    "            f\"- {section}: mediana={float(s['speedup_x'].median()):.2f}x, \"\n",
    "            f\"mejor={best['method']} ({best['speedup_x']:.2f}x), \"\n",
    "            f\"peor={worst['method']} ({worst['speedup_x']:.2f}x), \"\n",
    "            f\"quality_pass_rate={pass_rate:.2f}\"\n",
    "        )\n",
    "else:\n",
    "    print(\"No direct CPU/GPU pairs were available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 6) Rigor extension plan (using current project datasets)\n",
    "\n",
    "Below is a concrete test plan to make benchmarking more rigorous with existing project data (`train`, `test`, `train_fe`, `test_fe`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "rigor_plan_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"test_id\": \"R1_scale_curve_cudf_polars\",\n",
    "            \"section\": \"cudf\",\n",
    "            \"datasets\": \"train.parquet + test.parquet\",\n",
    "            \"cpu_vs_gpu\": \"pandas_cpu vs pandas_cudf; polars_cpu vs polars_cudf\",\n",
    "            \"protocol\": \"Run at 5%, 10%, 25%, 50%, 100% rows; repeats=5, warmup=1\",\n",
    "            \"acceptance_gate\": \"Speedup >= 1.3x in at least the largest two scales + consistency_pass\",\n",
    "            \"decision_value\": \"Find crossover point where GPU becomes materially beneficial\",\n",
    "        },\n",
    "        {\n",
    "            \"test_id\": \"R2_seed_stability_cuml\",\n",
    "            \"section\": \"cuml\",\n",
    "            \"datasets\": \"train_fe.parquet + test_fe.parquet\",\n",
    "            \"cpu_vs_gpu\": \"sklearn_cpu vs cuml_gpu (LR/RF/KMeans)\",\n",
    "            \"protocol\": \"Run with seeds [13, 42, 77, 101, 202]; collect fit time + metric each seed\",\n",
    "            \"acceptance_gate\": \"Median speedup > 1.2x and quality_pass in >= 80% of seeds\",\n",
    "            \"decision_value\": \"Check robustness of speedup and metric parity to randomness\",\n",
    "        },\n",
    "        {\n",
    "            \"test_id\": \"R3_oot_drift_robustness\",\n",
    "            \"section\": \"cuml/cudf\",\n",
    "            \"datasets\": \"train_fe (train), calibration, test (OOT)\",\n",
    "            \"cpu_vs_gpu\": \"same model pipeline CPU vs GPU per split\",\n",
    "            \"protocol\": \"Evaluate all splits independently and compare speedup + metric deltas\",\n",
    "            \"acceptance_gate\": \"No split with quality failure; speedup remains positive on OOT\",\n",
    "            \"decision_value\": \"Avoid promoting GPU path that only works on one distribution window\",\n",
    "        },\n",
    "        {\n",
    "            \"test_id\": \"R4_cugraph_convergence_grid\",\n",
    "            \"section\": \"cugraph\",\n",
    "            \"datasets\": \"train.parquet graph construction\",\n",
    "            \"cpu_vs_gpu\": \"networkx_cpu vs cugraph_gpu\",\n",
    "            \"protocol\": \"Grid on max_iter [40, 100, 200, 500] and tol [1e-4, 1e-5, 1e-6]\",\n",
    "            \"acceptance_gate\": \"converged_rate=1.0 and abs(sum_pagerank-1) <= 0.02\",\n",
    "            \"decision_value\": \"Guarantee stable graph metrics before claiming speedups\",\n",
    "        },\n",
    "        {\n",
    "            \"test_id\": \"R5_cuopt_scaling_and_parity\",\n",
    "            \"section\": \"cuopt\",\n",
    "            \"datasets\": \"test.parquet + grade PD map from train.parquet\",\n",
    "            \"cpu_vs_gpu\": \"scipy_highs_cpu vs cuopt_gpu\",\n",
    "            \"protocol\": \"n_variables grid: [3k, 6k, 12k, 18k]; repeats=5\",\n",
    "            \"acceptance_gate\": \"Objective relative diff <= 1e-4 at all scales; speedup > 1.0 at larger scales\",\n",
    "            \"decision_value\": \"Quantify at which optimization size GPU provides net operational value\",\n",
    "        },\n",
    "        {\n",
    "            \"test_id\": \"R6_resource_efficiency\",\n",
    "            \"section\": \"all\",\n",
    "            \"datasets\": \"same as each section\",\n",
    "            \"cpu_vs_gpu\": \"paired workloads\",\n",
    "            \"protocol\": \"Track wall time + peak GPU VRAM + peak CPU RSS\",\n",
    "            \"acceptance_gate\": \"Speedup gains are not offset by prohibitive memory pressure\",\n",
    "            \"decision_value\": \"Support infra sizing and cost/performance decisions\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(rigor_plan_df)\n",
    "maybe_save(rigor_plan_df, \"rigor_extension_plan.csv\")\n",
    "\n",
    "print(\"Recommended execution order: R1 -> R2 -> R4 -> R5 -> R3 -> R6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 7) Harder benchmarks with `loan_master`, `time_series`, `ead_dataset`\n",
    "\n",
    "This section inspects those master datasets and proposes harder, field-aware benchmarks with direct CPU-vs-GPU pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "master_paths = {\n",
    "    \"loan_master\": DATA / \"loan_master.parquet\",\n",
    "    \"time_series\": DATA / \"time_series.parquet\",\n",
    "    \"ead_dataset\": DATA / \"ead_dataset.parquet\",\n",
    "}\n",
    "\n",
    "master_schema_rows = []\n",
    "master_columns: dict[str, set[str]] = {}\n",
    "for name, path in master_paths.items():\n",
    "    if not path.exists():\n",
    "        master_schema_rows.append(\n",
    "            {\n",
    "                \"dataset\": name,\n",
    "                \"path\": str(path),\n",
    "                \"exists\": False,\n",
    "                \"rows\": np.nan,\n",
    "                \"n_columns\": np.nan,\n",
    "                \"row_groups\": np.nan,\n",
    "                \"sample_columns\": \"\",\n",
    "            }\n",
    "        )\n",
    "        master_columns[name] = set()\n",
    "        continue\n",
    "\n",
    "    pf = pq.ParquetFile(path)\n",
    "    cols = pf.schema.names\n",
    "    master_columns[name] = set(cols)\n",
    "    master_schema_rows.append(\n",
    "        {\n",
    "            \"dataset\": name,\n",
    "            \"path\": str(path.relative_to(ROOT)),\n",
    "            \"exists\": True,\n",
    "            \"rows\": int(pf.metadata.num_rows),\n",
    "            \"n_columns\": int(len(cols)),\n",
    "            \"row_groups\": int(pf.metadata.num_row_groups),\n",
    "            \"sample_columns\": \", \".join(cols[:14]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "master_schema_df = pd.DataFrame(master_schema_rows)\n",
    "display(master_schema_df)\n",
    "\n",
    "\n",
    "def field_check(dataset: str, fields: list[str]) -> tuple[str, str]:\n",
    "    available = master_columns.get(dataset, set())\n",
    "    missing = [f for f in fields if f not in available]\n",
    "    return f\"{len(fields) - len(missing)}/{len(fields)}\", \", \".join(missing[:8])\n",
    "\n",
    "\n",
    "hard_specs = [\n",
    "    {\n",
    "        \"benchmark_id\": \"H1_loan_master_risk_cube_window\",\n",
    "        \"dataset\": \"loan_master\",\n",
    "        \"library_focus\": \"cuDF / cudf.pandas / Polars GPU\",\n",
    "        \"cpu_method\": \"pandas / polars_cpu\",\n",
    "        \"gpu_method\": \"cudf.pandas / polars_cudf\",\n",
    "        \"key_fields\": [\n",
    "            \"issue_d\",\n",
    "            \"grade\",\n",
    "            \"purpose\",\n",
    "            \"home_ownership\",\n",
    "            \"verification_status\",\n",
    "            \"loan_amnt\",\n",
    "            \"default_flag\",\n",
    "            \"int_rate\",\n",
    "            \"dti\",\n",
    "        ],\n",
    "        \"workload\": \"Join-free risk cube + multi-key groupby + monthly rolling default rate + percentile aggregates\",\n",
    "        \"why_harder\": \"High-cardinality multi-dimensional aggregations with temporal windows\",\n",
    "    },\n",
    "    {\n",
    "        \"benchmark_id\": \"H2_ead_master_feature_factory\",\n",
    "        \"dataset\": \"ead_dataset\",\n",
    "        \"library_focus\": \"cuDF + cuML\",\n",
    "        \"cpu_method\": \"pandas + sklearn\",\n",
    "        \"gpu_method\": \"cudf + cuml\",\n",
    "        \"key_fields\": [\n",
    "            \"issue_d\",\n",
    "            \"grade\",\n",
    "            \"sub_grade\",\n",
    "            \"purpose\",\n",
    "            \"addr_state\",\n",
    "            \"annual_inc\",\n",
    "            \"dti\",\n",
    "            \"revol_util\",\n",
    "            \"total_acc\",\n",
    "            \"inq_last_6mths\",\n",
    "            \"default_flag\",\n",
    "        ],\n",
    "        \"workload\": \"Wide-table NA imputation + feature transforms + model fit (LR/RF) with timing split (prep vs fit)\",\n",
    "        \"why_harder\": \"120-column feature factory on mixed numeric/categorical data\",\n",
    "    },\n",
    "    {\n",
    "        \"benchmark_id\": \"H3_ead_loanmaster_join_stress\",\n",
    "        \"dataset\": \"ead_dataset + loan_master\",\n",
    "        \"library_focus\": \"cuDF\",\n",
    "        \"cpu_method\": \"pandas merge pipeline\",\n",
    "        \"gpu_method\": \"cudf merge pipeline\",\n",
    "        \"key_fields\": [\n",
    "            \"id\",\n",
    "            \"loan_amnt\",\n",
    "            \"grade\",\n",
    "            \"purpose\",\n",
    "            \"default_flag\",\n",
    "            \"int_rate_bucket\",\n",
    "            \"loan_to_income_sq\",\n",
    "        ],\n",
    "        \"workload\": \"Large join on id + dedupe + post-join risk bucket aggregations\",\n",
    "        \"why_harder\": \"Join pressure + post-join reshaping mirrors production-style ETL\",\n",
    "    },\n",
    "    {\n",
    "        \"benchmark_id\": \"H4_multi_layer_credit_graph\",\n",
    "        \"dataset\": \"ead_dataset\",\n",
    "        \"library_focus\": \"cuGraph / nx-cugraph\",\n",
    "        \"cpu_method\": \"networkx_cpu\",\n",
    "        \"gpu_method\": \"cugraph_gpu / networkx backend=cugraph\",\n",
    "        \"key_fields\": [\n",
    "            \"id\",\n",
    "            \"grade\",\n",
    "            \"sub_grade\",\n",
    "            \"purpose\",\n",
    "            \"home_ownership\",\n",
    "            \"verification_status\",\n",
    "            \"addr_state\",\n",
    "        ],\n",
    "        \"workload\": \"Multi-layer bipartite graph (loan->attributes) + pagerank + components + centrality\",\n",
    "        \"why_harder\": \"Bigger heterogeneous graph than current benchmark, stronger graph-memory stress\",\n",
    "    },\n",
    "    {\n",
    "        \"benchmark_id\": \"H5_multi_scenario_portfolio_lp\",\n",
    "        \"dataset\": \"ead_dataset + time_series\",\n",
    "        \"library_focus\": \"cuOpt\",\n",
    "        \"cpu_method\": \"scipy_highs_cpu\",\n",
    "        \"gpu_method\": \"cuopt_gpu\",\n",
    "        \"key_fields\": [\"loan_amnt\", \"int_rate\", \"grade\", \"purpose\", \"default_flag\", \"default_rate\"],\n",
    "        \"workload\": \"LP with scenario risk constraints from time-series quantiles (base/stress/severe)\",\n",
    "        \"why_harder\": \"Constraint matrix grows with scenarios, better stress-test for solver path\",\n",
    "    },\n",
    "]\n",
    "\n",
    "hard_rows = []\n",
    "for spec in hard_specs:\n",
    "    if \" + \" in spec[\"dataset\"]:\n",
    "        parts = [x.strip() for x in spec[\"dataset\"].split(\"+\")]\n",
    "        coverage_parts = []\n",
    "        missing_parts = []\n",
    "        for ds in parts:\n",
    "            cov, miss = field_check(ds, spec[\"key_fields\"])\n",
    "            coverage_parts.append(f\"{ds}:{cov}\")\n",
    "            if miss:\n",
    "                missing_parts.append(f\"{ds} missing [{miss}]\")\n",
    "        coverage = \" | \".join(coverage_parts)\n",
    "        missing_txt = \" ; \".join(missing_parts)\n",
    "    else:\n",
    "        coverage, missing_txt = field_check(spec[\"dataset\"], spec[\"key_fields\"])\n",
    "\n",
    "    row = dict(spec)\n",
    "    row[\"field_coverage\"] = coverage\n",
    "    row[\"missing_fields\"] = missing_txt\n",
    "    row[\"ready_now\"] = missing_txt == \"\"\n",
    "    hard_rows.append(row)\n",
    "\n",
    "hard_bench_df = pd.DataFrame(hard_rows)\n",
    "display(hard_bench_df)\n",
    "maybe_save(hard_bench_df, \"hard_benchmark_candidates_master_datasets.csv\")\n",
    "\n",
    "print(\"Recommended immediate additions:\")\n",
    "for _, r in hard_bench_df.iterrows():\n",
    "    readiness = \"ready\" if bool(r[\"ready_now\"]) else \"needs field adaptation\"\n",
    "    print(f\"- {r['benchmark_id']} ({r['library_focus']}): {readiness}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Result interpretation guide\n",
    "\n",
    "How to read this notebook:\n",
    "- Prefer direct paired CPU-vs-GPU table and one chart per method for decisions.\n",
    "- Use quality tables to validate parity before trusting speedups.\n",
    "- Prefer median speedup over single-run timings.\n",
    "- If a GPU path is slower, check sample size and kernel launch overhead; not every workload benefits from acceleration.\n",
    "- For cuGraph PageRank, verify convergence and `sum_pagerank ~ 1.0`.\n",
    "- For cuOpt LP, objective parity with SciPy is the primary correctness gate.\n",
    "\n",
    "By default this notebook does not export CSV artifacts. Enable `CONFIG[\"save_outputs\"] = True` only when you need persisted benchmark files.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
