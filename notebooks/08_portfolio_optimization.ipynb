{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Notebook 08: Portfolio Optimization — Conformal Predict-then-Optimize\n",
    "\n",
    "**Objective**: Use conformal prediction intervals from NB04 as **uncertainty sets** for robust\n",
    "portfolio optimization. This is the **central thesis contribution**: combining distribution-free\n",
    "coverage guarantees with mathematical optimization for credit risk.\n",
    "\n",
    "**Pipeline**:\n",
    "```\n",
    "CatBoost PD → Conformal [PD_low, PD_high] → Box Uncertainty Sets → Pyomo LP/MILP → HiGHS Solver\n",
    "```\n",
    "\n",
    "**Optimization Models**:\n",
    "1. **LP Continuous** — Fractional allocation (how much of each loan to fund)\n",
    "2. **MILP Binary** — Approve/reject decisions (binary)\n",
    "3. **Robust vs Non-Robust** — Use PD_high (worst-case) vs PD_point for risk constraints\n",
    "4. **Scenario Analysis** — Best-case, expected, worst-case expected loss\n",
    "5. **Sensitivity** — Risk tolerance, budget, concentration limits\n",
    "6. **Efficient Frontier** — Risk-return tradeoff curve\n",
    "7. **ECL Integration** — IFRS 9 expected credit loss optimization\n",
    "\n",
    "**Why Conformal Prediction for Optimization?**\n",
    "- Point PD estimates ignore uncertainty → fragile portfolios\n",
    "- Bootstrap intervals have no finite-sample guarantees\n",
    "- Bayesian intervals require distributional assumptions\n",
    "- **Conformal intervals are distribution-free with mathematical coverage guarantees**\n",
    "- Box uncertainty sets from CP intervals → tractable robust LP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Project imports\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyomo.environ as pyo\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "from pyomo.contrib.appsi.solvers import Highs\n",
    "\n",
    "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
    "from src.optimization.portfolio_model import (\n",
    "    build_binary_model,\n",
    "    build_portfolio_model,\n",
    "    solve_portfolio,\n",
    ")\n",
    "from src.optimization.robust_opt import (\n",
    "    build_box_uncertainty_set,\n",
    "    scenario_analysis,\n",
    "    worst_case_expected_loss,\n",
    ")\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=1.1)\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "logger.info(\"NB08 Portfolio Optimization initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data Loading & PD Predictions\n",
    "\n",
    "We need: PD predictions, conformal intervals, loan amounts, interest rates, and grade info.\n",
    "\n",
    "If NB03/NB04 artifacts are not available, we train a quick model inline as fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load existing artifacts from NB03/NB04\n",
    "try:\n",
    "    # Load conformal intervals\n",
    "    intervals_df = pd.read_parquet(DATA_DIR / \"conformal_intervals_mondrian.parquet\")\n",
    "    logger.info(f\"Loaded conformal intervals: {intervals_df.shape}\")\n",
    "    has_intervals = True\n",
    "except FileNotFoundError:\n",
    "    logger.warning(\n",
    "        \"conformal_intervals_mondrian.parquet not found — generating synthetic intervals\"\n",
    "    )\n",
    "    has_intervals = False\n",
    "\n",
    "# Load test data for portfolio candidates\n",
    "try:\n",
    "    df_test = pd.read_parquet(DATA_DIR / \"test_fe.parquet\")\n",
    "except FileNotFoundError:\n",
    "    df_test = pd.read_parquet(DATA_DIR / \"loan_master.parquet\")\n",
    "\n",
    "logger.info(f\"Portfolio candidates: {df_test.shape}\")\n",
    "\n",
    "# Use a manageable sample for optimization\n",
    "PORTFOLIO_SIZE = 5_000\n",
    "df_portfolio = df_test.sample(\n",
    "    n=min(PORTFOLIO_SIZE, len(df_test)), random_state=RANDOM_STATE\n",
    ").reset_index(drop=True)\n",
    "\n",
    "if has_intervals and len(intervals_df) >= len(df_portfolio):\n",
    "    # Map column names: conformal_intervals_mondrian.parquet uses y_pred/pd_low_90/pd_high_90\n",
    "    col_point = \"y_pred\" if \"y_pred\" in intervals_df.columns else \"pd_point\"\n",
    "    col_low = \"pd_low_90\" if \"pd_low_90\" in intervals_df.columns else \"pd_low\"\n",
    "    col_high = \"pd_high_90\" if \"pd_high_90\" in intervals_df.columns else \"pd_high\"\n",
    "\n",
    "    # Sample from intervals to match portfolio\n",
    "    intervals_sample = intervals_df.sample(n=PORTFOLIO_SIZE, random_state=RANDOM_STATE).reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    pd_point = intervals_sample[col_point].values\n",
    "    pd_low = intervals_sample[col_low].values\n",
    "    pd_high = intervals_sample[col_high].values\n",
    "    logger.info(f\"Using real conformal intervals (cols: {col_point}, {col_low}, {col_high})\")\n",
    "else:\n",
    "    # Generate from quick CatBoost model\n",
    "    from catboost import CatBoostClassifier\n",
    "\n",
    "    logger.info(\"Training quick CatBoost for PD predictions...\")\n",
    "\n",
    "    df_train = pd.read_parquet(DATA_DIR / \"train_fe.parquet\")\n",
    "    feature_config = pickle.load(open(DATA_DIR / \"feature_config.pkl\", \"rb\"))\n",
    "    features = feature_config[\"CATBOOST_FEATURES\"]\n",
    "    cat_features = feature_config[\"CATEGORICAL_FEATURES\"] + feature_config.get(\n",
    "        \"INTERACTION_FEATURES\", []\n",
    "    )\n",
    "    cat_features = [c for c in cat_features if c in features]\n",
    "\n",
    "    for col in cat_features:\n",
    "        df_train[col] = df_train[col].astype(str)\n",
    "        df_portfolio[col] = df_portfolio[col].astype(str)\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=300, depth=6, eval_metric=\"Logloss\", random_seed=42, verbose=0\n",
    "    )\n",
    "    model.fit(df_train[features], df_train[\"default_flag\"], cat_features=cat_features)\n",
    "    pd_point = model.predict_proba(df_portfolio[features])[:, 1]\n",
    "\n",
    "    # Simulate conformal intervals (symmetric around point, ~10% coverage width)\n",
    "    width = np.random.uniform(0.05, 0.20, len(pd_point))\n",
    "    pd_low = np.maximum(pd_point - width / 2, 0.001)\n",
    "    pd_high = np.minimum(pd_point + width / 2, 0.999)\n",
    "    logger.info(\"Generated PD predictions + simulated conformal intervals\")\n",
    "\n",
    "# Ensure portfolio data has needed columns\n",
    "loan_amounts = (\n",
    "    df_portfolio[\"loan_amnt\"].values\n",
    "    if \"loan_amnt\" in df_portfolio.columns\n",
    "    else np.random.uniform(5000, 35000, len(df_portfolio))\n",
    ")\n",
    "int_rates_pct = (\n",
    "    df_portfolio[\"int_rate\"].values\n",
    "    if \"int_rate\" in df_portfolio.columns\n",
    "    else np.random.uniform(5, 30, len(df_portfolio))\n",
    ")\n",
    "int_rates = int_rates_pct / 100  # Convert to decimal\n",
    "lgd = np.full(len(df_portfolio), 0.45)  # Assumed LGD\n",
    "grades = (\n",
    "    df_portfolio[\"grade\"].values\n",
    "    if \"grade\" in df_portfolio.columns\n",
    "    else np.full(len(df_portfolio), \"C\")\n",
    ")\n",
    "\n",
    "print(f\"Portfolio data prepared: {len(df_portfolio):,} loans\")\n",
    "print(f\"  Loan amounts: ${loan_amounts.mean():,.0f} avg (${loan_amounts.sum():,.0f} total)\")\n",
    "print(f\"  PD point: mean={pd_point.mean():.4f}, range=[{pd_point.min():.4f}, {pd_point.max():.4f}]\")\n",
    "print(f\"  PD interval: avg width={np.mean(pd_high - pd_low):.4f}\")\n",
    "print(f\"  Interest rate: mean={int_rates.mean() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Conformal Prediction → Uncertainty Sets\n",
    "\n",
    "Transform conformal prediction intervals $[\\hat{PD}_l, \\hat{PD}_h]$ into **box uncertainty sets**\n",
    "for robust optimization:\n",
    "\n",
    "$$\\mathcal{U} = \\{PD : PD_l \\leq PD \\leq PD_h, \\forall i \\in \\text{loans}\\}$$\n",
    "\n",
    "Key insight: Coverage guarantee from conformal prediction (e.g., 90%) translates directly to\n",
    "a probabilistic guarantee on the optimization solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build uncertainty set\n",
    "uset = build_box_uncertainty_set(pd_low, pd_high)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. PD interval widths\n",
    "axes[0].hist(pd_high - pd_low, bins=50, color=\"steelblue\", edgecolor=\"black\", alpha=0.7)\n",
    "axes[0].set_xlabel(\"Interval Width (PD_high - PD_low)\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].set_title(\"Distribution of Conformal PD Interval Widths\")\n",
    "\n",
    "# 2. PD point vs interval\n",
    "idx_sort = np.argsort(pd_point)[:200]  # Show 200 loans sorted by PD\n",
    "axes[1].fill_between(\n",
    "    range(len(idx_sort)),\n",
    "    pd_low[idx_sort],\n",
    "    pd_high[idx_sort],\n",
    "    alpha=0.3,\n",
    "    color=\"steelblue\",\n",
    "    label=\"90% CP interval\",\n",
    ")\n",
    "axes[1].plot(range(len(idx_sort)), pd_point[idx_sort], \"k-\", linewidth=0.5, label=\"Point PD\")\n",
    "axes[1].set_xlabel(\"Loan (sorted by PD)\")\n",
    "axes[1].set_ylabel(\"PD\")\n",
    "axes[1].set_title(\"Conformal PD Intervals (200 loans)\")\n",
    "axes[1].legend()\n",
    "\n",
    "# 3. Width by grade\n",
    "if \"grade\" in df_portfolio.columns:\n",
    "    width_by_grade = pd.DataFrame({\"grade\": grades, \"width\": pd_high - pd_low})\n",
    "    width_by_grade.groupby(\"grade\")[\"width\"].mean().sort_index().plot(\n",
    "        kind=\"bar\", ax=axes[2], color=\"coral\", edgecolor=\"black\"\n",
    "    )\n",
    "    axes[2].set_xlabel(\"Grade\")\n",
    "    axes[2].set_ylabel(\"Mean Interval Width\")\n",
    "    axes[2].set_title(\"Uncertainty by Grade (Higher = More Uncertain)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Box Uncertainty Set:\")\n",
    "print(f\"  Loans: {len(pd_point):,}\")\n",
    "print(f\"  Avg PD center: {uset['pd_center'].mean():.4f}\")\n",
    "print(f\"  Avg PD radius: {uset['pd_radius'].mean():.4f}\")\n",
    "print(f\"  Max interval width: {(pd_high - pd_low).max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. LP Portfolio Optimization (Continuous Allocation)\n",
    "\n",
    "**Objective**: Maximize net expected return (interest income minus expected loss)\n",
    "\n",
    "$$\\max_{x} \\sum_i x_i \\cdot L_i \\cdot (r_i - PD_i \\cdot LGD_i)$$\n",
    "\n",
    "**Subject to**:\n",
    "- Budget: $\\sum_i x_i \\cdot L_i \\leq B$\n",
    "- PD cap (robust): $\\frac{\\sum_i x_i \\cdot L_i \\cdot PD_i^{\\text{high}}}{\\sum_i x_i \\cdot L_i} \\leq \\bar{PD}$\n",
    "- Concentration: $\\frac{\\text{sector}_j}{\\text{total}} \\leq c_{\\max}$ per purpose\n",
    "- Individual: $0 \\leq x_i \\leq 1$\n",
    "\n",
    "Where $PD_i^{\\text{high}}$ is the **upper conformal bound** (robust) or $\\hat{PD}_i$ (non-robust)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build loan DataFrame for the model\n",
    "loans_df = pd.DataFrame(\n",
    "    {\n",
    "        \"loan_amnt\": loan_amounts,\n",
    "        \"purpose\": df_portfolio[\"purpose\"].values if \"purpose\" in df_portfolio.columns else \"other\",\n",
    "        \"grade\": grades,\n",
    "    }\n",
    ")\n",
    "\n",
    "BUDGET = 50_000_000  # $50M budget\n",
    "MAX_PD = 0.10  # 10% max portfolio PD\n",
    "MAX_CONCENTRATION = 0.35  # 35% max per purpose\n",
    "\n",
    "# Robust model (uses PD_high for PD constraint)\n",
    "print(\"Building Robust LP Model...\")\n",
    "t0 = time.time()\n",
    "model_robust = build_portfolio_model(\n",
    "    loans_df,\n",
    "    pd_point,\n",
    "    pd_low,\n",
    "    pd_high,\n",
    "    lgd,\n",
    "    int_rates,\n",
    "    total_budget=BUDGET,\n",
    "    max_concentration=MAX_CONCENTRATION,\n",
    "    max_portfolio_pd=MAX_PD,\n",
    "    robust=True,\n",
    ")\n",
    "sol_robust = solve_portfolio(model_robust)\n",
    "robust_time = time.time() - t0\n",
    "\n",
    "# Non-robust model (uses PD_point for PD constraint)\n",
    "print(\"\\nBuilding Non-Robust LP Model...\")\n",
    "t0 = time.time()\n",
    "model_nonrobust = build_portfolio_model(\n",
    "    loans_df,\n",
    "    pd_point,\n",
    "    pd_low,\n",
    "    pd_high,\n",
    "    lgd,\n",
    "    int_rates,\n",
    "    total_budget=BUDGET,\n",
    "    max_concentration=MAX_CONCENTRATION,\n",
    "    max_portfolio_pd=MAX_PD,\n",
    "    robust=False,\n",
    ")\n",
    "sol_nonrobust = solve_portfolio(model_nonrobust)\n",
    "nonrobust_time = time.time() - t0\n",
    "\n",
    "print(\"\\nResults Summary:\")\n",
    "print(f\"{'Metric':<30} {'Robust':>15} {'Non-Robust':>15}\")\n",
    "print(\"-\" * 62)\n",
    "print(\n",
    "    f\"{'Objective (net return)':.<30} ${sol_robust['objective_value']:>14,.0f} ${sol_nonrobust['objective_value']:>14,.0f}\"\n",
    ")\n",
    "print(f\"{'Loans funded':.<30} {sol_robust['n_funded']:>15} {sol_nonrobust['n_funded']:>15}\")\n",
    "print(\n",
    "    f\"{'Capital allocated':.<30} ${sol_robust['total_allocated']:>14,.0f} ${sol_nonrobust['total_allocated']:>14,.0f}\"\n",
    ")\n",
    "print(f\"{'Solve time (s)':.<30} {robust_time:>15.2f} {nonrobust_time:>15.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze allocation by grade\n",
    "alloc_robust = np.array([sol_robust[\"allocation\"][i] for i in range(len(df_portfolio))])\n",
    "alloc_nonrobust = np.array([sol_nonrobust[\"allocation\"][i] for i in range(len(df_portfolio))])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. Allocation by grade\n",
    "alloc_grade = pd.DataFrame(\n",
    "    {\n",
    "        \"grade\": grades,\n",
    "        \"robust\": alloc_robust * loan_amounts,\n",
    "        \"nonrobust\": alloc_nonrobust * loan_amounts,\n",
    "    }\n",
    ")\n",
    "grade_summary = alloc_grade.groupby(\"grade\")[[\"robust\", \"nonrobust\"]].sum() / 1e6\n",
    "grade_summary.sort_index().plot(\n",
    "    kind=\"bar\", ax=axes[0], color=[\"steelblue\", \"coral\"], edgecolor=\"black\"\n",
    ")\n",
    "axes[0].set_xlabel(\"Grade\")\n",
    "axes[0].set_ylabel(\"Allocation ($M)\")\n",
    "axes[0].set_title(\"Capital Allocation by Grade\")\n",
    "axes[0].legend([\"Robust\", \"Non-Robust\"])\n",
    "\n",
    "# 2. Allocation distribution\n",
    "axes[1].hist(\n",
    "    alloc_robust[alloc_robust > 0.01], bins=50, alpha=0.6, color=\"steelblue\", label=\"Robust\"\n",
    ")\n",
    "axes[1].hist(\n",
    "    alloc_nonrobust[alloc_nonrobust > 0.01], bins=50, alpha=0.6, color=\"coral\", label=\"Non-Robust\"\n",
    ")\n",
    "axes[1].set_xlabel(\"Allocation Fraction x_i\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "axes[1].set_title(\"Distribution of Non-Zero Allocations\")\n",
    "axes[1].legend()\n",
    "\n",
    "# 3. PD of funded loans\n",
    "funded_mask_r = alloc_robust > 0.01\n",
    "funded_mask_nr = alloc_nonrobust > 0.01\n",
    "data_to_plot = [pd_point[funded_mask_r], pd_point[funded_mask_nr], pd_point]\n",
    "axes[2].boxplot(data_to_plot, labels=[\"Robust\", \"Non-Robust\", \"All Loans\"])\n",
    "axes[2].set_ylabel(\"PD\")\n",
    "axes[2].set_title(\"PD of Funded Loans vs All Loans\")\n",
    "axes[2].yaxis.set_major_formatter(mticker.PercentFormatter(1.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Weighted portfolio PD\n",
    "wpd_robust = np.sum(alloc_robust * loan_amounts * pd_point) / (\n",
    "    np.sum(alloc_robust * loan_amounts) + 1e-6\n",
    ")\n",
    "wpd_nonrobust = np.sum(alloc_nonrobust * loan_amounts * pd_point) / (\n",
    "    np.sum(alloc_nonrobust * loan_amounts) + 1e-6\n",
    ")\n",
    "print(\"Weighted Portfolio PD:\")\n",
    "print(f\"  Robust:     {wpd_robust:.4f} ({wpd_robust * 100:.2f}%)\")\n",
    "print(f\"  Non-Robust: {wpd_nonrobust:.4f} ({wpd_nonrobust * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. MILP Binary Approval Model\n",
    "\n",
    "In practice, loans are either approved or rejected — no fractional allocation.\n",
    "The MILP model uses **binary decision variables**: $x_i \\in \\{0, 1\\}$.\n",
    "\n",
    "This is more realistic but harder to solve (NP-hard), though HiGHS handles it well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MILP model (binary approve/reject, robust PD constraint)\n",
    "print(\"Building MILP Binary Approval Model...\")\n",
    "t0 = time.time()\n",
    "model_milp = build_binary_model(\n",
    "    loans_df,\n",
    "    pd_point,\n",
    "    pd_high,\n",
    "    lgd,\n",
    "    int_rates,\n",
    "    total_budget=BUDGET,\n",
    "    max_portfolio_pd=MAX_PD,\n",
    ")\n",
    "sol_milp = solve_portfolio(model_milp)\n",
    "milp_time = time.time() - t0\n",
    "\n",
    "alloc_milp = np.array([sol_milp[\"allocation\"][i] for i in range(len(df_portfolio))])\n",
    "\n",
    "print(f\"\\nMILP Results ({milp_time:.2f}s):\")\n",
    "print(\n",
    "    f\"  Approved: {sol_milp['n_funded']}/{len(df_portfolio)} ({sol_milp['n_funded'] / len(df_portfolio) * 100:.1f}%)\"\n",
    ")\n",
    "print(f\"  Capital used: ${sol_milp['total_allocated']:,.0f} of ${BUDGET:,.0f}\")\n",
    "print(f\"  Net return: ${sol_milp['objective_value']:,.0f}\")\n",
    "\n",
    "# Compare LP vs MILP\n",
    "wpd_milp = np.sum(alloc_milp * loan_amounts * pd_point) / (np.sum(alloc_milp * loan_amounts) + 1e-6)\n",
    "print(f\"  Portfolio PD: {wpd_milp:.4f}\")\n",
    "print(f\"\\n{'Model':<20} {'Objective':>15} {'Funded':>10} {'Port PD':>10}\")\n",
    "print(\"-\" * 57)\n",
    "print(\n",
    "    f\"{'LP Robust':<20} ${sol_robust['objective_value']:>14,.0f} {sol_robust['n_funded']:>10} {wpd_robust:>10.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"{'LP Non-Robust':<20} ${sol_nonrobust['objective_value']:>14,.0f} {sol_nonrobust['n_funded']:>10} {wpd_nonrobust:>10.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"{'MILP Binary':<20} ${sol_milp['objective_value']:>14,.0f} {sol_milp['n_funded']:>10} {wpd_milp:>10.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Scenario Analysis — Best, Expected, Worst Case\n",
    "\n",
    "Using the conformal prediction intervals, we evaluate each portfolio under three scenarios:\n",
    "- **Best case**: All PDs at lower bound ($PD_l$)\n",
    "- **Expected**: All PDs at point estimate ($\\hat{PD}$)\n",
    "- **Worst case**: All PDs at upper bound ($PD_h$)\n",
    "\n",
    "The robust portfolio should have a smaller worst-case loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario analysis for all three models\n",
    "results = {}\n",
    "for name, alloc in [\n",
    "    (\"LP Robust\", alloc_robust),\n",
    "    (\"LP Non-Robust\", alloc_nonrobust),\n",
    "    (\"MILP Binary\", alloc_milp),\n",
    "]:\n",
    "    scenarios = scenario_analysis(alloc, loan_amounts, pd_low, pd_point, pd_high, lgd)\n",
    "    scenarios[\"model\"] = name\n",
    "    results[name] = scenarios\n",
    "\n",
    "scenario_df = pd.concat(results.values(), ignore_index=True)\n",
    "scenario_df = scenario_df[[\"model\", \"best_case\", \"expected\", \"worst_case\", \"range\"]]\n",
    "\n",
    "print(\"Scenario Analysis — Expected Loss Under Different PD Assumptions:\")\n",
    "print(\n",
    "    scenario_df.to_string(\n",
    "        index=False, float_format=lambda x: f\"${x:,.0f}\" if x > 100 else f\"{x:.0f}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "x_pos = np.arange(len(scenario_df))\n",
    "width = 0.25\n",
    "for i, scenario in enumerate([\"best_case\", \"expected\", \"worst_case\"]):\n",
    "    color = [\"#1a9850\", \"#fee08b\", \"#d73027\"][i]\n",
    "    axes[0].bar(\n",
    "        x_pos + i * width,\n",
    "        scenario_df[scenario] / 1e6,\n",
    "        width,\n",
    "        label=[\"Best Case\", \"Expected\", \"Worst Case\"][i],\n",
    "        color=color,\n",
    "        edgecolor=\"black\",\n",
    "    )\n",
    "axes[0].set_xticks(x_pos + width)\n",
    "axes[0].set_xticklabels(scenario_df[\"model\"])\n",
    "axes[0].set_ylabel(\"Expected Loss ($M)\")\n",
    "axes[0].set_title(\"Expected Loss by Scenario\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Robustness ratio: worst/expected\n",
    "for idx, row in scenario_df.iterrows():\n",
    "    ratio = row[\"worst_case\"] / row[\"expected\"] if row[\"expected\"] > 0 else 0\n",
    "    axes[1].bar(idx, ratio, color=\"teal\", edgecolor=\"black\")\n",
    "    axes[1].text(idx, ratio + 0.02, f\"{ratio:.2f}x\", ha=\"center\", fontsize=10)\n",
    "\n",
    "axes[1].set_xticks(range(len(scenario_df)))\n",
    "axes[1].set_xticklabels(scenario_df[\"model\"])\n",
    "axes[1].set_ylabel(\"Worst/Expected Loss Ratio\")\n",
    "axes[1].set_title(\"Robustness: How Much Worse Can It Get?\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Insight: Robustness vs Return\n",
    "- The robust portfolio protects tail loss by enforcing constraints with `PD_high` (conformal), but it usually sacrifices return and approval volume.\n",
    "- The gap between `worst_case` and `expected` is the most useful economic stability metric across formulations.\n",
    "- When conformal width is large, the robustness premium grows nonlinearly and can make deployment overly conservative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Sensitivity Analysis — Risk Tolerance\n",
    "\n",
    "How does the optimal portfolio change as we vary the **maximum portfolio PD** constraint?\n",
    "This traces out the risk-return tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary max_portfolio_pd\n",
    "pd_caps = [0.03, 0.05, 0.07, 0.10, 0.15, 0.20, 0.30]\n",
    "sensitivity_results = []\n",
    "\n",
    "for cap in pd_caps:\n",
    "    try:\n",
    "        model = build_portfolio_model(\n",
    "            loans_df,\n",
    "            pd_point,\n",
    "            pd_low,\n",
    "            pd_high,\n",
    "            lgd,\n",
    "            int_rates,\n",
    "            total_budget=BUDGET,\n",
    "            max_concentration=MAX_CONCENTRATION,\n",
    "            max_portfolio_pd=cap,\n",
    "            robust=True,\n",
    "        )\n",
    "        sol = solve_portfolio(model)\n",
    "        alloc = np.array([sol[\"allocation\"][i] for i in range(len(df_portfolio))])\n",
    "        wpd = np.sum(alloc * loan_amounts * pd_point) / (np.sum(alloc * loan_amounts) + 1e-6)\n",
    "        wc_loss = worst_case_expected_loss(alloc, loan_amounts, pd_high, lgd_point=lgd)\n",
    "\n",
    "        sensitivity_results.append(\n",
    "            {\n",
    "                \"max_pd_cap\": cap,\n",
    "                \"objective\": sol[\"objective_value\"],\n",
    "                \"n_funded\": sol[\"n_funded\"],\n",
    "                \"allocated\": sol[\"total_allocated\"],\n",
    "                \"actual_wpd\": wpd,\n",
    "                \"worst_case_loss\": wc_loss,\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Infeasible at max_pd={cap}: {e}\")\n",
    "        sensitivity_results.append(\n",
    "            {\n",
    "                \"max_pd_cap\": cap,\n",
    "                \"objective\": 0,\n",
    "                \"n_funded\": 0,\n",
    "                \"allocated\": 0,\n",
    "                \"actual_wpd\": 0,\n",
    "                \"worst_case_loss\": 0,\n",
    "            }\n",
    "        )\n",
    "\n",
    "sens_df = pd.DataFrame(sensitivity_results)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].plot(\n",
    "    sens_df[\"max_pd_cap\"] * 100,\n",
    "    sens_df[\"objective\"] / 1e6,\n",
    "    \"o-\",\n",
    "    color=\"steelblue\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    ")\n",
    "axes[0].set_xlabel(\"Max Portfolio PD Cap (%)\")\n",
    "axes[0].set_ylabel(\"Net Return ($M)\")\n",
    "axes[0].set_title(\"Return vs Risk Tolerance\")\n",
    "axes[0].xaxis.set_major_formatter(mticker.PercentFormatter(100))\n",
    "\n",
    "axes[1].plot(\n",
    "    sens_df[\"max_pd_cap\"] * 100, sens_df[\"n_funded\"], \"s-\", color=\"coral\", linewidth=2, markersize=8\n",
    ")\n",
    "axes[1].set_xlabel(\"Max Portfolio PD Cap (%)\")\n",
    "axes[1].set_ylabel(\"Loans Funded\")\n",
    "axes[1].set_title(\"Approvals vs Risk Tolerance\")\n",
    "\n",
    "axes[2].plot(\n",
    "    sens_df[\"actual_wpd\"] * 100,\n",
    "    sens_df[\"objective\"] / 1e6,\n",
    "    \"D-\",\n",
    "    color=\"teal\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    ")\n",
    "axes[2].set_xlabel(\"Actual Portfolio PD (%)\")\n",
    "axes[2].set_ylabel(\"Net Return ($M)\")\n",
    "axes[2].set_title(\"Risk-Return Tradeoff (Efficient Frontier)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Sensitivity to Risk Tolerance:\")\n",
    "print(\n",
    "    sens_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\" if abs(x) < 1 else f\"{x:,.0f}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Sensitivity Analysis — Budget Constraint\n",
    "\n",
    "How does the portfolio change with different capital budgets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary budget\n",
    "budgets = [10_000_000, 25_000_000, 50_000_000, 100_000_000, 200_000_000]\n",
    "budget_results = []\n",
    "\n",
    "for budget in budgets:\n",
    "    model = build_portfolio_model(\n",
    "        loans_df,\n",
    "        pd_point,\n",
    "        pd_low,\n",
    "        pd_high,\n",
    "        lgd,\n",
    "        int_rates,\n",
    "        total_budget=budget,\n",
    "        max_concentration=MAX_CONCENTRATION,\n",
    "        max_portfolio_pd=MAX_PD,\n",
    "        robust=True,\n",
    "    )\n",
    "    sol = solve_portfolio(model)\n",
    "    alloc = np.array([sol[\"allocation\"][i] for i in range(len(df_portfolio))])\n",
    "    wpd = np.sum(alloc * loan_amounts * pd_point) / (np.sum(alloc * loan_amounts) + 1e-6)\n",
    "\n",
    "    budget_results.append(\n",
    "        {\n",
    "            \"budget_M\": budget / 1e6,\n",
    "            \"objective\": sol[\"objective_value\"],\n",
    "            \"n_funded\": sol[\"n_funded\"],\n",
    "            \"allocated\": sol[\"total_allocated\"],\n",
    "            \"utilization\": sol[\"total_allocated\"] / budget * 100,\n",
    "            \"actual_wpd\": wpd,\n",
    "        }\n",
    "    )\n",
    "\n",
    "budget_df = pd.DataFrame(budget_results)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].bar(\n",
    "    budget_df[\"budget_M\"].astype(str),\n",
    "    budget_df[\"objective\"] / 1e6,\n",
    "    color=\"steelblue\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "axes[0].set_xlabel(\"Budget ($M)\")\n",
    "axes[0].set_ylabel(\"Net Return ($M)\")\n",
    "axes[0].set_title(\"Return vs Budget\")\n",
    "\n",
    "axes[1].bar(\n",
    "    budget_df[\"budget_M\"].astype(str), budget_df[\"utilization\"], color=\"coral\", edgecolor=\"black\"\n",
    ")\n",
    "axes[1].set_xlabel(\"Budget ($M)\")\n",
    "axes[1].set_ylabel(\"Budget Utilization (%)\")\n",
    "axes[1].set_title(\"Capital Utilization\")\n",
    "axes[1].axhline(y=100, color=\"black\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Budget Sensitivity:\")\n",
    "print(\n",
    "    budget_df.to_string(\n",
    "        index=False, float_format=lambda x: f\"{x:.1f}\" if abs(x) < 1000 else f\"{x:,.0f}\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. IFRS 9 ECL-Based Portfolio Optimization\n",
    "\n",
    "Instead of maximizing (Return - Expected Loss), we can directly **minimize ECL**\n",
    "subject to a minimum return constraint. This aligns with regulatory requirements.\n",
    "\n",
    "**ECL = PD × LGD × EAD**\n",
    "\n",
    "For Stage 1 loans: 12-month PD. For Stage 2+: lifetime PD.\n",
    "Using conformal intervals: worst-case ECL uses PD_high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECL minimization model\n",
    "def build_ecl_model(\n",
    "    loans_df,\n",
    "    pd_point,\n",
    "    pd_high,\n",
    "    lgd,\n",
    "    int_rates,\n",
    "    loan_amounts,\n",
    "    total_budget,\n",
    "    min_return_rate=0.05,\n",
    "    min_deploy_ratio=0.50,\n",
    "):\n",
    "    \"\"\"Minimize worst-case ECL subject to minimum return and deployment.\"\"\"\n",
    "    n = len(loans_df)\n",
    "    model = pyo.ConcreteModel(\"ECL_Minimization\")\n",
    "    model.I = pyo.RangeSet(0, n - 1)\n",
    "\n",
    "    model.pd_high = pyo.Param(model.I, initialize=dict(enumerate(pd_high)))\n",
    "    model.lgd = pyo.Param(model.I, initialize=dict(enumerate(lgd)))\n",
    "    model.loan_amnt = pyo.Param(model.I, initialize=dict(enumerate(loan_amounts)))\n",
    "    model.int_rate = pyo.Param(model.I, initialize=dict(enumerate(int_rates)))\n",
    "    model.pd_point = pyo.Param(model.I, initialize=dict(enumerate(pd_point)))\n",
    "\n",
    "    model.x = pyo.Var(model.I, domain=pyo.NonNegativeReals, bounds=(0, 1))\n",
    "\n",
    "    # Minimize worst-case ECL\n",
    "    def ecl_obj(m):\n",
    "        return sum(m.x[i] * m.loan_amnt[i] * m.pd_high[i] * m.lgd[i] for i in m.I)\n",
    "\n",
    "    model.obj = pyo.Objective(rule=ecl_obj, sense=pyo.minimize)\n",
    "\n",
    "    # Budget\n",
    "    def budget_rule(m):\n",
    "        return sum(m.x[i] * m.loan_amnt[i] for i in m.I) <= total_budget\n",
    "\n",
    "    model.budget = pyo.Constraint(rule=budget_rule)\n",
    "\n",
    "    # Minimum return\n",
    "    def return_rule(m):\n",
    "        return (\n",
    "            sum(m.x[i] * m.loan_amnt[i] * (m.int_rate[i] - m.pd_point[i] * m.lgd[i]) for i in m.I)\n",
    "            >= min_return_rate * total_budget\n",
    "        )\n",
    "\n",
    "    model.min_return = pyo.Constraint(rule=return_rule)\n",
    "\n",
    "    # Minimum deployment\n",
    "    def deploy_rule(m):\n",
    "        return sum(m.x[i] * m.loan_amnt[i] for i in m.I) >= min_deploy_ratio * total_budget\n",
    "\n",
    "    model.min_deploy = pyo.Constraint(rule=deploy_rule)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "solver = Highs()\n",
    "solver.config.time_limit = 60\n",
    "\n",
    "# Try progressively relaxed requirements until feasible\n",
    "search_grid = [\n",
    "    (0.03, 0.50),\n",
    "    (0.02, 0.50),\n",
    "    (0.01, 0.50),\n",
    "    (0.01, 0.30),\n",
    "    (0.00, 0.30),\n",
    "    (0.00, 0.10),\n",
    "]\n",
    "\n",
    "feasible = False\n",
    "alloc_ecl = np.zeros(len(df_portfolio))\n",
    "ecl_value = 0.0\n",
    "ecl_return = 0.0\n",
    "n_funded_ecl = 0\n",
    "chosen_constraints = None\n",
    "\n",
    "for min_ret, min_dep in search_grid:\n",
    "    ecl_model = build_ecl_model(\n",
    "        loans_df,\n",
    "        pd_point,\n",
    "        pd_high,\n",
    "        lgd,\n",
    "        int_rates,\n",
    "        loan_amounts,\n",
    "        total_budget=BUDGET,\n",
    "        min_return_rate=min_ret,\n",
    "        min_deploy_ratio=min_dep,\n",
    "    )\n",
    "    try:\n",
    "        _ = solver.solve(ecl_model)\n",
    "        alloc_candidate = np.array(\n",
    "            [pyo.value(ecl_model.x[i]) for i in range(len(df_portfolio))], dtype=float\n",
    "        )\n",
    "        ecl_candidate = float(pyo.value(ecl_model.obj))\n",
    "        ret_candidate = float(np.sum(alloc_candidate * loan_amounts * (int_rates - pd_point * lgd)))\n",
    "\n",
    "        alloc_ecl = alloc_candidate\n",
    "        ecl_value = ecl_candidate\n",
    "        ecl_return = ret_candidate\n",
    "        n_funded_ecl = int((alloc_ecl > 0.01).sum())\n",
    "        feasible = True\n",
    "        chosen_constraints = (min_ret, min_dep)\n",
    "        break\n",
    "    except RuntimeError:\n",
    "        continue\n",
    "\n",
    "print(\"ECL Minimization Results:\")\n",
    "if feasible:\n",
    "    print(\n",
    "        f\"  Feasible with min_return={chosen_constraints[0]:.1%}, min_deploy={chosen_constraints[1]:.0%}\"\n",
    "    )\n",
    "    print(f\"  Worst-case ECL: ${ecl_value:,.0f}\")\n",
    "    print(f\"  Net return: ${ecl_return:,.0f}\")\n",
    "    print(f\"  Loans funded: {n_funded_ecl}\")\n",
    "else:\n",
    "    print(\"  No feasible solution found in search grid; using zero-allocation fallback.\")\n",
    "\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"  {'Model':<20} {'Return':>15} {'Worst ECL':>15} {'Funded':>10}\")\n",
    "print(f\"  {'-' * 62}\")\n",
    "\n",
    "# Return and ECL for each model\n",
    "for name, alloc in [\n",
    "    (\"LP Robust\", alloc_robust),\n",
    "    (\"LP Non-Robust\", alloc_nonrobust),\n",
    "    (\"MILP Binary\", alloc_milp),\n",
    "    (\"ECL Minimized\", alloc_ecl),\n",
    "]:\n",
    "    ret = float(np.sum(alloc * loan_amounts * (int_rates - pd_point * lgd)))\n",
    "    ecl = float(worst_case_expected_loss(alloc, loan_amounts, pd_high, lgd_point=lgd))\n",
    "    nf = int((alloc > 0.01).sum())\n",
    "    print(f\"  {name:<20} ${ret:>14,.0f} ${ecl:>14,.0f} {nf:>10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Efficient Frontier — Risk-Return Tradeoff\n",
    "\n",
    "Trace the **efficient frontier**: for each level of risk (max PD), what is the maximum\n",
    "achievable return? Points below the frontier are suboptimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build efficient frontier by varying PD cap\n",
    "frontier_caps = np.arange(0.03, 0.30, 0.01)\n",
    "frontier = []\n",
    "\n",
    "for cap in frontier_caps:\n",
    "    try:\n",
    "        model = build_portfolio_model(\n",
    "            loans_df,\n",
    "            pd_point,\n",
    "            pd_low,\n",
    "            pd_high,\n",
    "            lgd,\n",
    "            int_rates,\n",
    "            total_budget=BUDGET,\n",
    "            max_concentration=0.5,  # Relaxed for frontier\n",
    "            max_portfolio_pd=cap,\n",
    "            robust=True,\n",
    "        )\n",
    "        sol = solve_portfolio(model)\n",
    "        alloc = np.array([sol[\"allocation\"][i] for i in range(len(df_portfolio))])\n",
    "        wpd = np.sum(alloc * loan_amounts * pd_point) / (np.sum(alloc * loan_amounts) + 1e-6)\n",
    "        wc_loss = worst_case_expected_loss(alloc, loan_amounts, pd_high, lgd_point=lgd)\n",
    "\n",
    "        frontier.append(\n",
    "            {\n",
    "                \"pd_cap\": cap,\n",
    "                \"return\": sol[\"objective_value\"],\n",
    "                \"risk_wpd\": wpd,\n",
    "                \"worst_loss\": wc_loss,\n",
    "                \"n_funded\": sol[\"n_funded\"],\n",
    "            }\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "frontier_df = pd.DataFrame(frontier)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Efficient frontier\n",
    "sc = ax.scatter(\n",
    "    frontier_df[\"risk_wpd\"] * 100,\n",
    "    frontier_df[\"return\"] / 1e6,\n",
    "    c=frontier_df[\"n_funded\"],\n",
    "    cmap=\"viridis\",\n",
    "    s=100,\n",
    "    edgecolors=\"black\",\n",
    "    zorder=5,\n",
    ")\n",
    "ax.plot(frontier_df[\"risk_wpd\"] * 100, frontier_df[\"return\"] / 1e6, \"--\", color=\"gray\", alpha=0.5)\n",
    "\n",
    "# Mark current operating point\n",
    "ax.scatter(\n",
    "    [wpd_robust * 100],\n",
    "    [sol_robust[\"objective_value\"] / 1e6],\n",
    "    marker=\"*\",\n",
    "    s=300,\n",
    "    color=\"red\",\n",
    "    zorder=10,\n",
    "    label=\"Robust LP (current)\",\n",
    ")\n",
    "ax.scatter(\n",
    "    [wpd_nonrobust * 100],\n",
    "    [sol_nonrobust[\"objective_value\"] / 1e6],\n",
    "    marker=\"^\",\n",
    "    s=200,\n",
    "    color=\"orange\",\n",
    "    zorder=10,\n",
    "    label=\"Non-Robust LP\",\n",
    ")\n",
    "\n",
    "plt.colorbar(sc, label=\"Loans Funded\")\n",
    "ax.set_xlabel(\"Portfolio PD (%)\")\n",
    "ax.set_ylabel(\"Net Return ($M)\")\n",
    "ax.set_title(\"Efficient Frontier — Risk-Return Tradeoff\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.xaxis.set_major_formatter(mticker.PercentFormatter(100))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Efficient Frontier (selected points):\")\n",
    "print(\n",
    "    frontier_df.to_string(\n",
    "        index=False, float_format=lambda x: f\"{x:.4f}\" if abs(x) < 1 else f\"{x:,.0f}\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Value of Conformal Prediction for Optimization\n",
    "\n",
    "Quantify the **value of uncertainty information** from conformal prediction:\n",
    "- How much does the robust solution differ from non-robust?\n",
    "- What is the **price of robustness** (return given up for safety)?\n",
    "- How often would the non-robust portfolio violate PD constraints under worst-case PDs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price of robustness\n",
    "price_of_robustness = sol_nonrobust[\"objective_value\"] - sol_robust[\"objective_value\"]\n",
    "price_pct = (\n",
    "    price_of_robustness / sol_nonrobust[\"objective_value\"] * 100\n",
    "    if sol_nonrobust[\"objective_value\"] > 0\n",
    "    else 0\n",
    ")\n",
    "\n",
    "# Constraint violation analysis\n",
    "# Under worst-case PDs, does the non-robust portfolio violate the PD constraint?\n",
    "wpd_nonrobust_worst = np.sum(alloc_nonrobust * loan_amounts * pd_high) / (\n",
    "    np.sum(alloc_nonrobust * loan_amounts) + 1e-6\n",
    ")\n",
    "wpd_robust_worst = np.sum(alloc_robust * loan_amounts * pd_high) / (\n",
    "    np.sum(alloc_robust * loan_amounts) + 1e-6\n",
    ")\n",
    "\n",
    "print(\"Value of Conformal Prediction for Optimization:\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"  Price of robustness: ${price_of_robustness:,.0f} ({price_pct:.1f}% of non-robust return)\")\n",
    "print(\"  This is the return given up for worst-case safety.\")\n",
    "print(\"\")\n",
    "print(\"  Under worst-case PDs (conformal upper bounds):\")\n",
    "print(f\"    Non-robust portfolio PD: {wpd_nonrobust_worst:.4f} ({wpd_nonrobust_worst * 100:.2f}%)\")\n",
    "print(f\"    Robust portfolio PD:     {wpd_robust_worst:.4f} ({wpd_robust_worst * 100:.2f}%)\")\n",
    "print(f\"    PD constraint (max):     {MAX_PD:.4f} ({MAX_PD * 100:.2f}%)\")\n",
    "print(\"\")\n",
    "if wpd_nonrobust_worst > MAX_PD:\n",
    "    print(\"  ⚠ Non-robust VIOLATES PD constraint under worst case!\")\n",
    "    print(f\"  ⚠ Violation: {(wpd_nonrobust_worst - MAX_PD) * 100:.2f}pp over limit\")\n",
    "else:\n",
    "    print(\"  Non-robust stays within PD constraint even under worst case.\")\n",
    "if wpd_robust_worst <= MAX_PD:\n",
    "    print(\"  Robust portfolio satisfies PD constraint under worst case.\")\n",
    "\n",
    "# ECL comparison\n",
    "ecl_robust_expected = worst_case_expected_loss(alloc_robust, loan_amounts, pd_point, lgd_point=lgd)\n",
    "ecl_robust_worst = worst_case_expected_loss(alloc_robust, loan_amounts, pd_high, lgd_point=lgd)\n",
    "ecl_nonrobust_expected = worst_case_expected_loss(\n",
    "    alloc_nonrobust, loan_amounts, pd_point, lgd_point=lgd\n",
    ")\n",
    "ecl_nonrobust_worst = worst_case_expected_loss(\n",
    "    alloc_nonrobust, loan_amounts, pd_high, lgd_point=lgd\n",
    ")\n",
    "\n",
    "print(\"\\n  ECL Comparison:\")\n",
    "print(f\"    {'':>25} {'Expected':>15} {'Worst Case':>15}\")\n",
    "print(f\"    {'Robust':>25} ${ecl_robust_expected:>14,.0f} ${ecl_robust_worst:>14,.0f}\")\n",
    "print(f\"    {'Non-Robust':>25} ${ecl_nonrobust_expected:>14,.0f} ${ecl_nonrobust_worst:>14,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Operational Conclusion for NB08\n",
    "- This notebook translates statistical uncertainty into decision constraints (predict-then-optimize).\n",
    "- The key result is not only expected return, but resilience under `PD_high` and constraint validity under stress.\n",
    "- Practical value depends critically on conformal interval efficiency (coverage plus width)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Summary & Save Artifacts\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Robust optimization with conformal intervals** produces safer portfolios at a modest return cost\n",
    "2. **LP vs MILP**: MILP (binary) is more realistic; LP (continuous) gives an upper bound on achievable return\n",
    "3. **Efficient frontier**: Clear risk-return tradeoff; tighter PD constraints reduce return but improve safety\n",
    "4. **Price of robustness**: The return sacrifice for worst-case safety (quantified above)\n",
    "5. **ECL minimization**: Alternative objective aligned with IFRS 9 regulatory requirements\n",
    "6. **Value of CP**: Non-robust portfolios may violate PD constraints under worst-case scenarios\n",
    "\n",
    "### Thesis Contribution\n",
    "This notebook demonstrates the complete **Conformal Predict-then-Optimize** pipeline:\n",
    "```\n",
    "CatBoost PD → MAPIE Conformal [PD_low, PD_high] → Box Uncertainty → Pyomo LP/MILP → HiGHS → Optimal Portfolio\n",
    "```\n",
    "The conformal prediction intervals provide **distribution-free, finite-sample coverage guarantees**\n",
    "that translate into **probabilistic guarantees on the optimization solution**.\n",
    "\n",
    "### Connection to Other Notebooks\n",
    "- **NB03 (PD)**: Point PD estimates → expected return/loss\n",
    "- **NB04 (Conformal)**: PD intervals → uncertainty sets for robust optimization\n",
    "- **NB06 (Survival)**: Lifetime PD → ECL term structure\n",
    "- **NB07 (Causal)**: CATE → rate optimization potential\n",
    "- **NB09 (Pipeline)**: Full end-to-end integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save portfolio optimization results\n",
    "portfolio_results = {\n",
    "    \"robust\": {\n",
    "        \"objective\": sol_robust[\"objective_value\"],\n",
    "        \"n_funded\": sol_robust[\"n_funded\"],\n",
    "        \"allocated\": sol_robust[\"total_allocated\"],\n",
    "        \"portfolio_pd\": float(wpd_robust),\n",
    "    },\n",
    "    \"nonrobust\": {\n",
    "        \"objective\": sol_nonrobust[\"objective_value\"],\n",
    "        \"n_funded\": sol_nonrobust[\"n_funded\"],\n",
    "        \"allocated\": sol_nonrobust[\"total_allocated\"],\n",
    "        \"portfolio_pd\": float(wpd_nonrobust),\n",
    "    },\n",
    "    \"milp\": {\n",
    "        \"objective\": sol_milp[\"objective_value\"],\n",
    "        \"n_funded\": sol_milp[\"n_funded\"],\n",
    "        \"allocated\": sol_milp[\"total_allocated\"],\n",
    "    },\n",
    "    \"ecl_minimized\": {\n",
    "        \"ecl\": float(ecl_value),\n",
    "        \"return\": float(ecl_return),\n",
    "        \"n_funded\": n_funded_ecl,\n",
    "    },\n",
    "    \"price_of_robustness\": float(price_of_robustness),\n",
    "    \"price_of_robustness_pct\": float(price_pct),\n",
    "    \"budget\": BUDGET,\n",
    "    \"max_pd\": MAX_PD,\n",
    "    \"portfolio_size\": len(df_portfolio),\n",
    "}\n",
    "\n",
    "with open(MODEL_DIR / \"portfolio_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(portfolio_results, f)\n",
    "\n",
    "# Save efficient frontier\n",
    "frontier_df.to_parquet(DATA_DIR / \"efficient_frontier.parquet\")\n",
    "\n",
    "# Save allocation\n",
    "alloc_df = pd.DataFrame(\n",
    "    {\n",
    "        \"loan_idx\": range(len(df_portfolio)),\n",
    "        \"alloc_robust\": alloc_robust,\n",
    "        \"alloc_nonrobust\": alloc_nonrobust,\n",
    "        \"alloc_milp\": alloc_milp,\n",
    "        \"alloc_ecl\": alloc_ecl,\n",
    "        \"pd_point\": pd_point,\n",
    "        \"pd_low\": pd_low,\n",
    "        \"pd_high\": pd_high,\n",
    "        \"loan_amnt\": loan_amounts,\n",
    "        \"int_rate\": int_rates,\n",
    "        \"grade\": grades,\n",
    "    }\n",
    ")\n",
    "alloc_df.to_parquet(DATA_DIR / \"portfolio_allocations.parquet\")\n",
    "\n",
    "print(\"Artifacts saved:\")\n",
    "print(f\"  Portfolio results: {MODEL_DIR / 'portfolio_results.pkl'}\")\n",
    "print(f\"  Efficient frontier: {DATA_DIR / 'efficient_frontier.parquet'}\")\n",
    "print(f\"  Allocations: {DATA_DIR / 'portfolio_allocations.parquet'}\")\n",
    "print(\"\\nNB08 Portfolio Optimization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Final Conclusions: Portfolio Optimization\n",
    "\n",
    "### Key Findings\n",
    "- Robust optimization protects against adverse PD realizations but can materially reduce return and deployment.\n",
    "- Non-robust solutions can over-allocate risk when uncertainty is ignored.\n",
    "- Feasibility and performance are highly sensitive to uncertainty-set quality.\n",
    "\n",
    "### Financial Risk Interpretation\n",
    "- The \"price of robustness\" is a direct economic measure of model uncertainty cost.\n",
    "- Overly conservative uncertainty sets can produce capital under-deployment.\n",
    "- Practical risk management requires balancing constraint safety and business throughput.\n",
    "\n",
    "### Contribution to End-to-End Pipeline\n",
    "- Converts model outputs into actionable allocation decisions under explicit constraints.\n",
    "- Demonstrates the operational impact of conformal uncertainty on lending strategy.\n",
    "- Closes the loop between predictive analytics and capital allocation policy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lending-club-risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
